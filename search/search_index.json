{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AIMNet2: Machine-Learned Interatomic Potential \u00b6 What is AIMNet2? \u00b6 AIMNet2 is a neural network potential for fast and accurate atomistic simulations. Built on PyTorch, it provides: Accurate predictions for neutral, charged, organic, and elemental-organic systems Fast inference on both CPU and GPU Integration with popular simulation packages (ASE, PySisyphus) Configurable long-range electrostatics (DSF, Ewald) for periodic systems AIMNet2 combines a graph neural network architecture with flexible long-range interactions, making it suitable for molecular dynamics, geometry optimization, and property prediction across diverse chemical systems. Key Features \u00b6 Accurate and Versatile : Handles neutral, charged, organic, and elemental-organic systems with consistent accuracy Flexible Interfaces : Calculator API for direct inference, plus ASE and PySisyphus integration for simulation workflows Configurable Long-Range : Choose between Simple, DSF, or Ewald methods for Coulomb interactions GPU Accelerated : CUDA support with optional compile_mode for ~5x MD speedup Periodic Boundary Conditions : Full support for bulk and surface systems Quick Start \u00b6 from aimnet.calculators import AIMNet2Calculator # Load model calc = AIMNet2Calculator(\"aimnet2\") # Run inference result = calc({ \"coord\": coords, # (N, 3) array in Angstrom \"numbers\": numbers, # (N,) atomic numbers \"charge\": 0.0, # molecular charge }, forces=True) # Access results energy = result[\"energy\"] # eV forces = result[\"forces\"] # eV/Angstrom charges = result[\"charges\"] # partial charges Available Models \u00b6 Model Elements Description aimnet2 H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I wB97M-D3 (default) aimnet2_b973c H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I B97-3c functional aimnet2_2025 H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I B97-3c + improved intermolecular aimnet2nse H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I Open-shell chemistry aimnet2pd H, B, C, N, O, F, Si, P, S, Cl, Se, Br, Pd, I Palladium-containing systems Each model has ensemble members (append _0 to _3). Ensemble averaging recommended for production. Installation \u00b6 Basic installation: pip install aimnet With optional features: # ASE integration pip install \"aimnet[ase]\" # PySisyphus integration pip install \"aimnet[pysis]\" # Training tools pip install \"aimnet[train]\" Requirements: Python 3.11 or 3.12. GPU support optional (PyTorch with CUDA). Documentation Guide \u00b6 Core Documentation \u00b6 Getting Started - Installation and first calculations Calculator API - Comprehensive reference for AIMNet2Calculator Model Format - Understanding model files and metadata Long Range - Coulomb and dispersion methods Workflows \u00b6 Training - Training custom models CLI Reference - Command-line tools API Reference \u00b6 Calculators - AIMNet2Calculator , AIMNet2ASE , AIMNet2Pysis Modules - Core neural network modules Data - Dataset and sampling utilities Config - Configuration utilities Common Use Cases \u00b6 Periodic Systems \u00b6 result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell_vectors, # (3, 3) in Angstrom }, forces=True, stress=True) Configuring Long-Range Methods \u00b6 # DSF for periodic systems calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # Ewald for high accuracy (accuracy parameter controls precision) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) ASE Integration \u00b6 from ase.io import read from aimnet.calculators import AIMNet2ASE atoms = read(\"structure.xyz\") atoms.calc = AIMNet2ASE(\"aimnet2\") energy = atoms.get_potential_energy() Support and Contributing \u00b6 Issues : GitHub Issues Discussions : GitHub Discussions Repository : github.com/isayevlab/aimnetcentral Citation \u00b6 If you use AIMNet2, please cite: @article{aimnet2, title={AIMNet2: A Neural Network Potential to Meet Your Neutral, Charged, Organic, and Elemental-Organic Needs}, author={Anstine, Dylan M and Zubatyuk, Roman and Isayev, Olexandr}, journal={Chemical Science}, volume={16}, pages={10228--10244}, year={2025}, doi={10.1039/D4SC08572H} } License \u00b6 See LICENSE for details.","title":"Home"},{"location":"#aimnet2-machine-learned-interatomic-potential","text":"","title":"AIMNet2: Machine-Learned Interatomic Potential"},{"location":"#what-is-aimnet2","text":"AIMNet2 is a neural network potential for fast and accurate atomistic simulations. Built on PyTorch, it provides: Accurate predictions for neutral, charged, organic, and elemental-organic systems Fast inference on both CPU and GPU Integration with popular simulation packages (ASE, PySisyphus) Configurable long-range electrostatics (DSF, Ewald) for periodic systems AIMNet2 combines a graph neural network architecture with flexible long-range interactions, making it suitable for molecular dynamics, geometry optimization, and property prediction across diverse chemical systems.","title":"What is AIMNet2?"},{"location":"#key-features","text":"Accurate and Versatile : Handles neutral, charged, organic, and elemental-organic systems with consistent accuracy Flexible Interfaces : Calculator API for direct inference, plus ASE and PySisyphus integration for simulation workflows Configurable Long-Range : Choose between Simple, DSF, or Ewald methods for Coulomb interactions GPU Accelerated : CUDA support with optional compile_mode for ~5x MD speedup Periodic Boundary Conditions : Full support for bulk and surface systems","title":"Key Features"},{"location":"#quick-start","text":"from aimnet.calculators import AIMNet2Calculator # Load model calc = AIMNet2Calculator(\"aimnet2\") # Run inference result = calc({ \"coord\": coords, # (N, 3) array in Angstrom \"numbers\": numbers, # (N,) atomic numbers \"charge\": 0.0, # molecular charge }, forces=True) # Access results energy = result[\"energy\"] # eV forces = result[\"forces\"] # eV/Angstrom charges = result[\"charges\"] # partial charges","title":"Quick Start"},{"location":"#available-models","text":"Model Elements Description aimnet2 H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I wB97M-D3 (default) aimnet2_b973c H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I B97-3c functional aimnet2_2025 H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I B97-3c + improved intermolecular aimnet2nse H, B, C, N, O, F, Si, P, S, Cl, As, Se, Br, I Open-shell chemistry aimnet2pd H, B, C, N, O, F, Si, P, S, Cl, Se, Br, Pd, I Palladium-containing systems Each model has ensemble members (append _0 to _3). Ensemble averaging recommended for production.","title":"Available Models"},{"location":"#installation","text":"Basic installation: pip install aimnet With optional features: # ASE integration pip install \"aimnet[ase]\" # PySisyphus integration pip install \"aimnet[pysis]\" # Training tools pip install \"aimnet[train]\" Requirements: Python 3.11 or 3.12. GPU support optional (PyTorch with CUDA).","title":"Installation"},{"location":"#documentation-guide","text":"","title":"Documentation Guide"},{"location":"#core-documentation","text":"Getting Started - Installation and first calculations Calculator API - Comprehensive reference for AIMNet2Calculator Model Format - Understanding model files and metadata Long Range - Coulomb and dispersion methods","title":"Core Documentation"},{"location":"#workflows","text":"Training - Training custom models CLI Reference - Command-line tools","title":"Workflows"},{"location":"#api-reference","text":"Calculators - AIMNet2Calculator , AIMNet2ASE , AIMNet2Pysis Modules - Core neural network modules Data - Dataset and sampling utilities Config - Configuration utilities","title":"API Reference"},{"location":"#common-use-cases","text":"","title":"Common Use Cases"},{"location":"#periodic-systems","text":"result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell_vectors, # (3, 3) in Angstrom }, forces=True, stress=True)","title":"Periodic Systems"},{"location":"#configuring-long-range-methods","text":"# DSF for periodic systems calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # Ewald for high accuracy (accuracy parameter controls precision) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8)","title":"Configuring Long-Range Methods"},{"location":"#ase-integration","text":"from ase.io import read from aimnet.calculators import AIMNet2ASE atoms = read(\"structure.xyz\") atoms.calc = AIMNet2ASE(\"aimnet2\") energy = atoms.get_potential_energy()","title":"ASE Integration"},{"location":"#support-and-contributing","text":"Issues : GitHub Issues Discussions : GitHub Discussions Repository : github.com/isayevlab/aimnetcentral","title":"Support and Contributing"},{"location":"#citation","text":"If you use AIMNet2, please cite: @article{aimnet2, title={AIMNet2: A Neural Network Potential to Meet Your Neutral, Charged, Organic, and Elemental-Organic Needs}, author={Anstine, Dylan M and Zubatyuk, Roman and Isayev, Olexandr}, journal={Chemical Science}, volume={16}, pages={10228--10244}, year={2025}, doi={10.1039/D4SC08572H} }","title":"Citation"},{"location":"#license","text":"See LICENSE for details.","title":"License"},{"location":"calculator/","text":"AIMNet2Calculator \u00b6 This document provides detailed documentation of the AIMNet2Calculator class behavior. Overview \u00b6 AIMNet2Calculator is a helper class for loading AIMNet2 models and performing inference. It handles: Model loading (from registry, file path, or nn.Module ) External long-range (LR) module setup (Coulomb, DFTD3) Neighbor list computation and management Input preprocessing and output postprocessing Batching and periodic boundary conditions (PBC) For LR module math and behavior, see long_range.md . Quick Start \u00b6 Basic Inference \u00b6 from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator(\"aimnet2\") result = calc({ \"coord\": coords, # (N, 3) \"numbers\": numbers, # (N,) \"charge\": 0.0, }) energy = result[\"energy\"] With Forces \u00b6 result = calc(data, forces=True) forces = result[\"forces\"] # (N, 3) Periodic Systems \u00b6 calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, # (3, 3) }, forces=True, stress=True) Changing Coulomb Methods \u00b6 # DSF (recommended for PBC) calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) # Ewald (high accuracy, currently limited to non-batched case) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) # Simple (all pairs) calc.set_lrcoulomb_method(\"simple\") Constructor \u00b6 AIMNet2Calculator( model: str | nn.Module = \"aimnet2\", nb_threshold: int = 120, needs_coulomb: bool | None = None, needs_dispersion: bool | None = None, device: str | None = None, compile_model: bool = False, compile_kwargs: dict | None = None, ) Parameters \u00b6 model \u00b6 Model to use for inference. Type Behavior str (registry name) Loads from model registry (e.g., \"aimnet2\" ), downloading if needed str (file path) Loads from .pt (v2) or .jpt (v1 legacy) file if the path exists torch.nn.Module Uses provided module directly For torch.nn.Module , metadata is read from model.metadata attribute if available (v2 models). nb_threshold \u00b6 Threshold for batching/flattening decisions. Default: 120 . The calculator uses two input modes: Fully connected (mode 0) : 3D batched input for coordinates (num_mols, num_atoms, 3) with all-pairs interactions (dense O(N\u00b2)). Fast on GPU for small systems. Flattened + neighbor lists (mode 1) : 2D input for coordinates (num_atoms, 3) with mol_idx and neighbor lists (sparse O(N)). Used for large systems, CPU execution, and periodic systems. Condition Behavior Complexity N > nb_threshold If input is mode 0 (3D), flatten to mode 1 (2D with mol_idx ) O(N) linear device == \"cpu\" If input is mode 0 (3D), always flatten to mode 1 O(N) linear N < nb_threshold and CUDA Keep mode 0 (3D) O(N\u00b2) fully connected This affects memory usage and performance for batched inference. The mode=0 path uses a fully connected graph (all-pairs interactions), which scales as O(N\u00b2) but is fast for GPU. The mode=1 path uses neighbor lists, which scale linearly with system size. Fully connected mode is not used for periodic systems; PBC inputs always go through neighbor lists. needs_coulomb \u00b6 Whether to attach external Coulomb module. Value Behavior None (default) Determined from model metadata True Force external Coulomb (overrides metadata) False No external Coulomb (overrides metadata) Only affects v2 format models. Legacy JIT models have embedded Coulomb. If you override this flag on a model without Coulomb metadata, ensure it is compatible with the expected subtraction for short range Coulomb contribution (see coulomb_mode in model metadata). needs_dispersion \u00b6 Whether to attach external DFTD3 module. Value Behavior None (default) Determined from model metadata True Force external DFTD3 (overrides metadata) False No external DFTD3 (overrides metadata) Only affects new-format models. Raises ValueError if needs_dispersion=True but d3_params are missing in metadata. device \u00b6 Device to run the model on. Value Behavior None (default) Auto-detect: uses CUDA if available, else CPU \"cuda\" Force CUDA device \"cpu\" Force CPU device \"cuda:N\" Specific CUDA device (e.g., \"cuda:1\" ) compile_model \u00b6 Whether to compile the model with torch.compile() for faster inference. Value Behavior False (default) No compilation True Compile model with torch.compile() Compilation adds overhead on first call but speeds up subsequent calls. Useful for MD trajectories, geometry optimizations, or repeated evaluations. compile_kwargs \u00b6 Additional keyword arguments to pass to torch.compile() . Default is None . # Example: use reduce-overhead mode for lower latency calc = AIMNet2Calculator(\"aimnet2\", compile_model=True, compile_kwargs={\"mode\": \"reduce-overhead\"}) See torch.compile documentation for available options. Metadata Resolution \u00b6 Priority: explicit flags > model metadata > no external modules Model Source Metadata Source File path ( .pt / .jpt ) Loaded from file nn.Module model.metadata attribute No metadata + no flags No external LR modules Properties \u00b6 device \u00b6 Device string (e.g., \"cuda\" , \"cpu\" , \"cuda:1\" ). Set via constructor parameter or auto-detected. cutoff \u00b6 Short-range model cutoff in \u00c5ngstr\u00f6ms. Typically 5.0 \u00c5. cutoff_lr \u00b6 Primary long-range cutoff reference. Used for backward compatibility with legacy models. coulomb_cutoff \u00b6 Coulomb-specific cutoff distance. Tracked separately from the DFTD3 cutoff. Method Value \"simple\" inf (all pairs) \"dsf\" Configured cutoff (default 15.0 \u00c5) \"ewald\" None (Ewald manages its own real-space cutoff internally) dftd3_cutoff \u00b6 DFTD3-specific cutoff distance. Default: 15.0 \u00c5. Neighbor list behavior: The calculator keeps Coulomb and DFTD3 cutoffs independent. Long-range neighbor lists are: Shared when both cutoffs are finite and within 20% of each other Separate when both cutoffs are finite and differ by more than 20% All pairs for \"simple\" Coulomb (effectively no cutoff) Ignored by Ewald , which builds its own real-space/reciprocal sums Data dictionary keys: LR modules prefer their specific suffix, falling back to _lr : LRCoulomb : Tries nbmat_coulomb first, falls back to nbmat_lr DFTD3/D3TS : Tries nbmat_dftd3 first, falls back to nbmat_lr When neighbor lists are shared, all keys point to the same array. Modifying cutoffs: set_lr_cutoff(cutoff) : Updates both Coulomb and DFTD3 cutoffs set_lrcoulomb_method(method, cutoff) : Updates Coulomb cutoff only set_dftd3_cutoff(cutoff) : Updates DFTD3 cutoff only has_external_coulomb \u00b6 True if external LRCoulomb module is attached. False for legacy models with embedded Coulomb. has_external_dftd3 \u00b6 True if external DFTD3 module is attached. False for legacy models or D3TS models. coulomb_method \u00b6 Current Coulomb method: \"simple\" , \"dsf\" , \"ewald\" , or None . Returns None for: Legacy models with embedded Coulomb Models without Coulomb Note on Ewald: Ewald summation uses its own internal real-space cutoff based on accuracy requirements. When Ewald is selected, coulomb_cutoff is None and does not contribute to neighbor list computation. Methods \u00b6 eval(data, forces=False, stress=False, hessian=False) \u00b6 Main inference method. Also callable via calculator(data, ...) . Parameters: Parameter Type Default Description data dict required Input data dictionary forces bool False Compute atomic forces stress bool False Compute stress tensor (requires cell ) hessian bool False Compute Hessian matrix Returns: Dictionary with computed outputs. Example: calc = AIMNet2Calculator(\"aimnet2\") result = calc.eval({ \"coord\": coords, # (N, 3) or (B, N, 3) \"numbers\": numbers, # (N,) or (B, N) \"charge\": charge, # (1,) or (B,) }, forces=True) energy = result[\"energy\"] forces = result[\"forces\"] charges = result[\"charges\"] set_lrcoulomb_method(method, cutoff=15.0, dsf_alpha=0.2, ewald_accuracy=1e-8) \u00b6 Set the long-range Coulomb method. Parameters: Parameter Type Default Description method str required \"simple\" , \"dsf\" , or \"ewald\" cutoff float 15.0 Cutoff for DSF method (\u00c5). Not used for Ewald. dsf_alpha float 0.2 Alpha parameter for DSF method ewald_accuracy float 1e-8 Target accuracy for Ewald summation Behavior: Method Description Coulomb cutoff \"simple\" Direct Coulomb sum (all pairs) inf \"dsf\" Damped shifted force Configured cutoff \"ewald\" Ewald summation Computed from accuracy Ewald Accuracy Parameter: For Ewald summation, the ewald_accuracy parameter controls the real-space and reciprocal-space cutoffs. The cutoffs are computed automatically based on system geometry: [ \\eta = \\frac{(V^2 / N)^{1/6}}{\\sqrt{2\\pi}} ] [ r_{\\text{cutoff}} = \\sqrt{-2 \\ln \\varepsilon} \\cdot \\eta ] [ k_{\\text{cutoff}} = \\frac{\\sqrt{-2 \\ln \\varepsilon}}{\\eta} ] Where (\\varepsilon) is the accuracy parameter, (V) is the cell volume, and (N) is the number of atoms. Lower accuracy values (e.g., 1e-10 ) give higher precision but require more computation. Notes: Updates external LRCoulomb module if present Automatically updates neighbor lists Issues warning for legacy models (no effect) Auto-switches to \"dsf\" when PBC is detected with \"simple\" method (see PBC notes below) Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0, dsf_alpha=0.20) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-6) set_lr_cutoff(cutoff) \u00b6 Set the unified long-range cutoff for all LR modules. Parameters: Parameter Type Description cutoff float Cutoff distance (\u00c5) for LR neighbor lists Notes: Updates both Coulomb and DFTD3 cutoffs Ewald method ignores this cutoff (uses its own internal cutoff) Automatically rebuilds neighbor lists Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_lr_cutoff(20.0) # Updates both Coulomb and DFTD3 cutoffs set_dftd3_cutoff(cutoff=None, smoothing_fraction=None) \u00b6 Set DFTD3 cutoff and smoothing. Parameters: | Parameter | Type | Default | Description | | -------------------- | ------ | ------- | ----------- | ------------------------------------------ | | cutoff | float | None | 15.0 | Cutoff distance (\u00c5) | | smoothing_fraction | float | None | 0.2 | Fraction of cutoff used as smoothing width | Notes: Only updates smoothing parameters for external DFTD3 modules Always updates neighbor list cutoffs used by the calculator For legacy models with embedded DFTD3, the embedded module\u2019s smoothing parameters do not change, but the neighbor list cutoff provided by the calculator can still change dispersion behavior Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_dftd3_cutoff(cutoff=20.0, smoothing_fraction=0.25) # smoothing from 15A to 20A Input Format \u00b6 Required Keys \u00b6 Key Type Shape Description coord float32 (N, 3) or (B, N, 3) Atomic coordinates (\u00c5) numbers int64 (N,) or (B, N) Atomic numbers charge float32 (1,) or (B,) Molecular charge(s) Optional Keys \u00b6 Key Type Shape Description mult float32 (B,) Multiplicity mol_idx int64 (N,) Molecule index per atom cell float32 (3, 3) or (B, 3, 3) Unit cell vectors nbmat int64 (N, max_nb) Pre-computed neighbor matrix nbmat_lr int64 (N, max_nb) Long-range neighbor matrix nb_pad_mask bool (N, max_nb) Optional padding mask for nbmat nb_pad_mask_lr bool (N, max_nb) Optional padding mask for nbmat_lr shifts float32 (N, max_nb, 3) PBC shifts for neighbors shifts_lr float32 (N, max_nb, 3) PBC shifts for LR neighbors Input Conversion \u00b6 The calculator automatically converts: NumPy arrays \u2192 PyTorch tensors Python lists \u2192 PyTorch tensors Scalar tensors \u2192 Shape (1,) All tensors \u2192 Correct dtype and device Any keys not listed in required/optional tables are ignored during input conversion. Output Format \u00b6 Key Shape Description energy (1,) or (B,) Total energy per molecule charges (N,) or (B, N) Atomic partial charges forces (N, 3) or (B, N, 3) Atomic forces (if requested) stress (3, 3) or (B, 3, 3) Stress tensor (if requested) hessian (N, 3, N, 3) Hessian matrix (if requested) Notes: forces requires forces=True in eval() stress requires stress=True and cell in input hessian requires hessian=True , only for single molecules Batching and Neighbor Modes \u00b6 The calculator chooses between dense and sparse execution based on system size and device. The goal is to keep small GPU workloads fast while keeping large or CPU workloads linear in memory. Dense Mode (O(N\u00b2)) \u00b6 When : N < nb_threshold and CUDA is available Input : 3D batched (B, N, 3) Behavior : No neighbor list; the model uses a fully connected graph Tradeoff : Fast on GPU for small molecules, but quadratic memory Sparse Mode (O(N)) \u00b6 When : N > nb_threshold or CPU execution Input : Flattened 2D (N_total, 3) with mol_idx Behavior : Adaptive neighbor lists limit interactions to within cutoff Tradeoff : Linear memory with a small overhead for neighbor list construction Mode 2: Batched Sparse (manual) \u00b6 Input : 3D batched (B, N, 3) plus 3D neighbor matrix (B, N, max_nb) Note : Supported by the model, but not selected automatically. Use this mode by supplying a 3D nbmat explicitly. Choosing the Right Mode \u00b6 The calculator automatically selects between two execution modes: Mode 0 (Dense, O(N\u00b2) fully connected): Every atom interacts with every other atom in an all-to-all manner. No neighbor list is constructed. This mode is only used for batches of small molecules with the same number of atoms on GPU . Specifically: Input must be 3D batched coordinates (B, N, 3) N \u2264 nb_threshold (default 120 atoms per molecule) CUDA device available No periodic boundary conditions In this case, the O(N\u00b2) fully connected approach is more efficient than constructing neighbor lists. Mode 1 (Sparse, O(N) with neighbor lists): Uses adaptive neighbor lists to limit interactions to atoms within cutoff distance. This mode is used in all other cases: Periodic boundary conditions (required for periodic images) CPU execution Large systems (N > nb_threshold) Variable-sized molecules Key Takeaways: PBC always requires neighbor lists (Mode 1) CPU always uses neighbor lists (Mode 1) Small batched molecules on GPU use fully connected (Mode 0) Large systems use neighbor lists (Mode 1) Flattening Logic \u00b6 For 3D batched inputs, AIMNet2Calculator decides whether to flatten based on nb_threshold : # nb_threshold default is 120 if device == \"cpu\" or max_atoms > nb_threshold: # FLATTEN -> Mode 1 (Sparse) # Computes neighbor list else: # KEEP 3D -> Mode 0 (Dense) # Implicit all-pairs Periodic Boundary Conditions (PBC) \u00b6 Input Requirements \u00b6 data = { \"coord\": coords, \"numbers\": numbers, \"charge\": charge, \"cell\": cell, # (3, 3) or (num_systems, 3, 3) } Behavior \u00b6 Coordinates wrapped into unit cell via move_coord_to_cell() Neighbor lists include periodic image shifts Coulomb method auto-switches to \"dsf\" if \"simple\" (with warning). For legacy JIT models the embedded Coulomb method cannot be changed at runtime; the warning indicates that only the calculator\u2019s external setting was updated. Multiple molecules with PBC: raises NotImplementedError Coulomb Method for PBC \u00b6 Initial Method Action \"simple\" Auto-switch to \"dsf\" with warning \"dsf\" / \"ewald\" No change Neighbor List Management \u00b6 Adaptive Neighbor Lists \u00b6 The calculator uses AdaptiveNeighborList for automatic buffer management in Mode 1 : Initial sizing : Based on density estimate and cutoff Overflow handling : Increases buffer by 1.5x and retries Underutilization : Shrinks if utilization < 2/3 of target (hysteresis) Minimum buffer : 16 neighbors Memory alignment : Rounded to multiples of 16 Neighbor List Format and Padding \u00b6 Neighbor lists are stored as integer matrices nbmat with shape (N_total, max_neighbors) . Each row contains neighbor indices for a single atom. Rows are padded with a dummy index (typically N_total ) when an atom has fewer neighbors than max_neighbors . The buffer grows on overflow (\u00d71.5) and shrinks when utilization drops well below target, which helps performance remain stable as density changes. Module Suffix Fallback \u00b6 LR modules prefer their specific neighbor list key, with fallback to _lr : LRCoulomb (simple/dsf) : Tries nbmat_coulomb , falls back to nbmat_lr DFTD3/D3TS : Tries nbmat_dftd3 , falls back to nbmat_lr Note: Ewald uses its own internal neighbor list and ignores calculator cutoffs. Device Handling \u00b6 Automatic Selection \u00b6 device = \"cuda\" if torch.cuda.is_available() else \"cpu\" Placement \u00b6 Component Device Model self.device External LRCoulomb self.device External DFTD3 self.device Input tensors Converted to self.device Output tensors Remain on self.device External LR Module Configuration \u00b6 LRCoulomb Setup \u00b6 When needs_coulomb=True : LRCoulomb( key_in=\"charges\", key_out=\"energy\", method=\"simple\", # Default, changeable via set_lrcoulomb_method() rc=metadata.get(\"coulomb_sr_rc\", 4.6), envelope=metadata.get(\"coulomb_sr_envelope\", \"exp\"), subtract_sr=not sr_embedded, # Based on coulomb_mode ) DFTD3 Setup \u00b6 When needs_dispersion=True and d3_params available: DFTD3( s8=d3_params[\"s8\"], a1=d3_params[\"a1\"], a2=d3_params[\"a2\"], s6=d3_params.get(\"s6\", 1.0), ) How LR Modules Are Attached \u00b6 External LR modules are attached based on model metadata unless overridden by constructor flags: If needs_coulomb=True , an external LRCoulomb is created. If coulomb_mode=\"sr_embedded\" , the model already subtracts SR Coulomb internally and the external module adds full Coulomb on top. If needs_dispersion=True and d3_params are present, an external DFTD3 is created. If d3_params are missing, initialization raises ValueError . Explicit needs_coulomb / needs_dispersion flags override metadata. Cutoff Handling for LR Modules \u00b6 Coulomb : set_lrcoulomb_method() selects the method and updates the Coulomb cutoff ( inf for \"simple\" , finite for \"dsf\" , None for \"ewald\" ). DFTD3 : set_dftd3_cutoff() updates the DFTD3 cutoff and smoothing window. Unified control : set_lr_cutoff() sets both Coulomb and DFTD3 cutoffs to the same value. Ewald : Uses its own internal neighbor list; calculator cutoffs do not apply. Default Values \u00b6 LR Module Defaults \u00b6 Parameter Default Description set_lrcoulomb_method(..., cutoff=15.0) 15.0 Default LR cutoff for DSF (\u00c5) set_lrcoulomb_method(..., ewald_accuracy=1e-8) 1e-8 Default accuracy for Ewald summation set_dftd3_cutoff(..., smoothing_fraction=0.2) 0.2 DFTD3 smoothing width as fraction of cutoff Coulomb Defaults \u00b6 Parameter Default Description coulomb_sr_rc 4.6 \u00c5 Short-range Coulomb cutoff coulomb_sr_envelope \"exp\" Envelope function ( \"exp\" or \"cosine\" ) SR Coulomb Cutoff Constraint \u00b6 coulomb_sr_rc must be \u2264 model cutoff The short-range Coulomb cutoff defines the distance within which SR Coulomb interactions are computed by the embedded SRCoulomb module. This cutoff must be less than or equal to the model's short-range cutoff because: SRCoulomb uses the same neighbor list as the neural network Atom pairs beyond the model cutoff are not visible to SRCoulomb Typical configuration: coulomb_sr_rc=4.6 \u00c5 with model cutoff=5.0 \u00c5 The envelope function ( \"exp\" or \"cosine\" ) determines how the SR interaction smoothly decays to zero at the cutoff boundary. Legacy Model Compatibility \u00b6 Legacy JIT models ( .jpt ) have different behavior: Feature Legacy New Format Coulomb Embedded in model External module DFTD3/D3BJ Embedded in model External module set_lrcoulomb_method() Warning, no effect Updates method set_lr_cutoff() No effect on embedded modules Updates cutoff_lr for all LR modules set_dftd3_cutoff() No effect on embedded modules Updates smoothing for external DFTD3 has_external_coulomb False True (if applicable) Error Handling \u00b6 Common Errors \u00b6 Condition Error Invalid model type TypeError Missing required input key KeyError Hessian with multiple molecules NotImplementedError PBC with multiple molecules NotImplementedError Invalid Coulomb method ValueError needs_dispersion=True without d3_params ValueError Warnings \u00b6 Condition Warning set_lrcoulomb_method() on legacy model Warns, no effect PBC with \"simple\" Coulomb Auto-switches to \"dsf\" Complete Example \u00b6 import torch from aimnet.calculators import AIMNet2Calculator # Create calculator calc = AIMNet2Calculator(\"aimnet2\") # Check configuration print(f\"Device: {calc.device}\") print(f\"Cutoff: {calc.cutoff}\") print(f\"Has external Coulomb: {calc.has_external_coulomb}\") print(f\"Coulomb method: {calc.coulomb_method}\") # Configure for PBC calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0) # Prepare input data = { \"coord\": torch.randn(20, 3), \"numbers\": torch.randint(1, 10, (20,)), \"charge\": torch.tensor([0.0]), } # Run inference result = calc.eval(data, forces=True) print(f\"Energy: {result['energy']}\") print(f\"Forces shape: {result['forces'].shape}\") print(f\"Charges shape: {result['charges'].shape}\") Performance Tips \u00b6 Hardware Acceleration \u00b6 Use GPU for best performance: # Automatically uses CUDA if available calc = AIMNet2Calculator(\"aimnet2\") print(calc.device) # \"cuda\" or \"cpu\" GPU provides 10-50x speedup over CPU for typical workloads. Compile Mode \u00b6 Use compile_model=True for additional speedup: # Basic compilation calc = AIMNet2Calculator(\"aimnet2\", compile_model=True) # With custom compile options calc = AIMNet2Calculator( \"aimnet2\", compile_model=True, compile_kwargs={\"mode\": \"reduce-overhead\"} ) Characteristics: First call will be slow (compilation overhead) Subsequent calls are faster Works with both periodic and non-periodic systems When to use: Long MD trajectories Geometry optimization with many steps Repeated evaluation on same system size When not to use: Single evaluations (compilation overhead outweighs benefit) Varying system sizes (may trigger recompilation) Memory Management \u00b6 Tune nb_threshold for your workload: # Conservative (less memory, earlier sparse mode) calc = AIMNet2Calculator(\"aimnet2\", nb_threshold=80) # Aggressive (more memory, faster on GPU) calc = AIMNet2Calculator(\"aimnet2\", nb_threshold=150) For large systems on GPU: Lower nb_threshold to use sparse mode Reduces memory footprint Enables processing larger molecules For many small molecules: Higher nb_threshold to use dense mode longer Maximizes GPU parallelism Faster overall throughput Pre-compute Neighbor Lists \u00b6 Avoid recomputation by caching: # First call: computes neighbor lists result1 = calc(data, forces=True) # If geometry unchanged, reuse same data dict # Calculator caches neighbor lists internally result2 = calc(data, forces=False) # Reuses cached lists For custom workflows, provide nbmat explicitly: # Compute once nbmat, _, shifts = compute_neighbor_list(coords, cutoff=5.0) # Use many times for _ in range(1000): result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"nbmat\": nbmat, \"shifts\": shifts, }, forces=True) Coulomb Method Selection \u00b6 Choose method for your system: System Type Method Parameter Notes Small non-PBC \"simple\" N/A All pairs, exact Large non-PBC \"dsf\" cutoff=12-15 \u00c5 O(N) scaling PBC systems \"dsf\" cutoff=12-15 \u00c5 Recommended High-accuracy PBC \"ewald\" accuracy=1e-8 Research-grade # Fast for non-PBC calc.set_lrcoulomb_method(\"simple\") # Efficient for PBC calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # High-accuracy for research calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) Multi-threading (CPU) \u00b6 Set thread count for CPU execution: import torch torch.set_num_threads(4) # Use 4 CPU cores calc = AIMNet2Calculator(\"aimnet2\") # Will use CPU","title":"Calculator"},{"location":"calculator/#aimnet2calculator","text":"This document provides detailed documentation of the AIMNet2Calculator class behavior.","title":"AIMNet2Calculator"},{"location":"calculator/#overview","text":"AIMNet2Calculator is a helper class for loading AIMNet2 models and performing inference. It handles: Model loading (from registry, file path, or nn.Module ) External long-range (LR) module setup (Coulomb, DFTD3) Neighbor list computation and management Input preprocessing and output postprocessing Batching and periodic boundary conditions (PBC) For LR module math and behavior, see long_range.md .","title":"Overview"},{"location":"calculator/#quick-start","text":"","title":"Quick Start"},{"location":"calculator/#basic-inference","text":"from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator(\"aimnet2\") result = calc({ \"coord\": coords, # (N, 3) \"numbers\": numbers, # (N,) \"charge\": 0.0, }) energy = result[\"energy\"]","title":"Basic Inference"},{"location":"calculator/#with-forces","text":"result = calc(data, forces=True) forces = result[\"forces\"] # (N, 3)","title":"With Forces"},{"location":"calculator/#periodic-systems","text":"calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, # (3, 3) }, forces=True, stress=True)","title":"Periodic Systems"},{"location":"calculator/#changing-coulomb-methods","text":"# DSF (recommended for PBC) calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) # Ewald (high accuracy, currently limited to non-batched case) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) # Simple (all pairs) calc.set_lrcoulomb_method(\"simple\")","title":"Changing Coulomb Methods"},{"location":"calculator/#constructor","text":"AIMNet2Calculator( model: str | nn.Module = \"aimnet2\", nb_threshold: int = 120, needs_coulomb: bool | None = None, needs_dispersion: bool | None = None, device: str | None = None, compile_model: bool = False, compile_kwargs: dict | None = None, )","title":"Constructor"},{"location":"calculator/#parameters","text":"","title":"Parameters"},{"location":"calculator/#model","text":"Model to use for inference. Type Behavior str (registry name) Loads from model registry (e.g., \"aimnet2\" ), downloading if needed str (file path) Loads from .pt (v2) or .jpt (v1 legacy) file if the path exists torch.nn.Module Uses provided module directly For torch.nn.Module , metadata is read from model.metadata attribute if available (v2 models).","title":"model"},{"location":"calculator/#nb_threshold","text":"Threshold for batching/flattening decisions. Default: 120 . The calculator uses two input modes: Fully connected (mode 0) : 3D batched input for coordinates (num_mols, num_atoms, 3) with all-pairs interactions (dense O(N\u00b2)). Fast on GPU for small systems. Flattened + neighbor lists (mode 1) : 2D input for coordinates (num_atoms, 3) with mol_idx and neighbor lists (sparse O(N)). Used for large systems, CPU execution, and periodic systems. Condition Behavior Complexity N > nb_threshold If input is mode 0 (3D), flatten to mode 1 (2D with mol_idx ) O(N) linear device == \"cpu\" If input is mode 0 (3D), always flatten to mode 1 O(N) linear N < nb_threshold and CUDA Keep mode 0 (3D) O(N\u00b2) fully connected This affects memory usage and performance for batched inference. The mode=0 path uses a fully connected graph (all-pairs interactions), which scales as O(N\u00b2) but is fast for GPU. The mode=1 path uses neighbor lists, which scale linearly with system size. Fully connected mode is not used for periodic systems; PBC inputs always go through neighbor lists.","title":"nb_threshold"},{"location":"calculator/#needs_coulomb","text":"Whether to attach external Coulomb module. Value Behavior None (default) Determined from model metadata True Force external Coulomb (overrides metadata) False No external Coulomb (overrides metadata) Only affects v2 format models. Legacy JIT models have embedded Coulomb. If you override this flag on a model without Coulomb metadata, ensure it is compatible with the expected subtraction for short range Coulomb contribution (see coulomb_mode in model metadata).","title":"needs_coulomb"},{"location":"calculator/#needs_dispersion","text":"Whether to attach external DFTD3 module. Value Behavior None (default) Determined from model metadata True Force external DFTD3 (overrides metadata) False No external DFTD3 (overrides metadata) Only affects new-format models. Raises ValueError if needs_dispersion=True but d3_params are missing in metadata.","title":"needs_dispersion"},{"location":"calculator/#device","text":"Device to run the model on. Value Behavior None (default) Auto-detect: uses CUDA if available, else CPU \"cuda\" Force CUDA device \"cpu\" Force CPU device \"cuda:N\" Specific CUDA device (e.g., \"cuda:1\" )","title":"device"},{"location":"calculator/#compile_model","text":"Whether to compile the model with torch.compile() for faster inference. Value Behavior False (default) No compilation True Compile model with torch.compile() Compilation adds overhead on first call but speeds up subsequent calls. Useful for MD trajectories, geometry optimizations, or repeated evaluations.","title":"compile_model"},{"location":"calculator/#compile_kwargs","text":"Additional keyword arguments to pass to torch.compile() . Default is None . # Example: use reduce-overhead mode for lower latency calc = AIMNet2Calculator(\"aimnet2\", compile_model=True, compile_kwargs={\"mode\": \"reduce-overhead\"}) See torch.compile documentation for available options.","title":"compile_kwargs"},{"location":"calculator/#metadata-resolution","text":"Priority: explicit flags > model metadata > no external modules Model Source Metadata Source File path ( .pt / .jpt ) Loaded from file nn.Module model.metadata attribute No metadata + no flags No external LR modules","title":"Metadata Resolution"},{"location":"calculator/#properties","text":"","title":"Properties"},{"location":"calculator/#device_1","text":"Device string (e.g., \"cuda\" , \"cpu\" , \"cuda:1\" ). Set via constructor parameter or auto-detected.","title":"device"},{"location":"calculator/#cutoff","text":"Short-range model cutoff in \u00c5ngstr\u00f6ms. Typically 5.0 \u00c5.","title":"cutoff"},{"location":"calculator/#cutoff_lr","text":"Primary long-range cutoff reference. Used for backward compatibility with legacy models.","title":"cutoff_lr"},{"location":"calculator/#coulomb_cutoff","text":"Coulomb-specific cutoff distance. Tracked separately from the DFTD3 cutoff. Method Value \"simple\" inf (all pairs) \"dsf\" Configured cutoff (default 15.0 \u00c5) \"ewald\" None (Ewald manages its own real-space cutoff internally)","title":"coulomb_cutoff"},{"location":"calculator/#dftd3_cutoff","text":"DFTD3-specific cutoff distance. Default: 15.0 \u00c5. Neighbor list behavior: The calculator keeps Coulomb and DFTD3 cutoffs independent. Long-range neighbor lists are: Shared when both cutoffs are finite and within 20% of each other Separate when both cutoffs are finite and differ by more than 20% All pairs for \"simple\" Coulomb (effectively no cutoff) Ignored by Ewald , which builds its own real-space/reciprocal sums Data dictionary keys: LR modules prefer their specific suffix, falling back to _lr : LRCoulomb : Tries nbmat_coulomb first, falls back to nbmat_lr DFTD3/D3TS : Tries nbmat_dftd3 first, falls back to nbmat_lr When neighbor lists are shared, all keys point to the same array. Modifying cutoffs: set_lr_cutoff(cutoff) : Updates both Coulomb and DFTD3 cutoffs set_lrcoulomb_method(method, cutoff) : Updates Coulomb cutoff only set_dftd3_cutoff(cutoff) : Updates DFTD3 cutoff only","title":"dftd3_cutoff"},{"location":"calculator/#has_external_coulomb","text":"True if external LRCoulomb module is attached. False for legacy models with embedded Coulomb.","title":"has_external_coulomb"},{"location":"calculator/#has_external_dftd3","text":"True if external DFTD3 module is attached. False for legacy models or D3TS models.","title":"has_external_dftd3"},{"location":"calculator/#coulomb_method","text":"Current Coulomb method: \"simple\" , \"dsf\" , \"ewald\" , or None . Returns None for: Legacy models with embedded Coulomb Models without Coulomb Note on Ewald: Ewald summation uses its own internal real-space cutoff based on accuracy requirements. When Ewald is selected, coulomb_cutoff is None and does not contribute to neighbor list computation.","title":"coulomb_method"},{"location":"calculator/#methods","text":"","title":"Methods"},{"location":"calculator/#evaldata-forcesfalse-stressfalse-hessianfalse","text":"Main inference method. Also callable via calculator(data, ...) . Parameters: Parameter Type Default Description data dict required Input data dictionary forces bool False Compute atomic forces stress bool False Compute stress tensor (requires cell ) hessian bool False Compute Hessian matrix Returns: Dictionary with computed outputs. Example: calc = AIMNet2Calculator(\"aimnet2\") result = calc.eval({ \"coord\": coords, # (N, 3) or (B, N, 3) \"numbers\": numbers, # (N,) or (B, N) \"charge\": charge, # (1,) or (B,) }, forces=True) energy = result[\"energy\"] forces = result[\"forces\"] charges = result[\"charges\"]","title":"eval(data, forces=False, stress=False, hessian=False)"},{"location":"calculator/#set_lrcoulomb_methodmethod-cutoff150-dsf_alpha02-ewald_accuracy1e-8","text":"Set the long-range Coulomb method. Parameters: Parameter Type Default Description method str required \"simple\" , \"dsf\" , or \"ewald\" cutoff float 15.0 Cutoff for DSF method (\u00c5). Not used for Ewald. dsf_alpha float 0.2 Alpha parameter for DSF method ewald_accuracy float 1e-8 Target accuracy for Ewald summation Behavior: Method Description Coulomb cutoff \"simple\" Direct Coulomb sum (all pairs) inf \"dsf\" Damped shifted force Configured cutoff \"ewald\" Ewald summation Computed from accuracy Ewald Accuracy Parameter: For Ewald summation, the ewald_accuracy parameter controls the real-space and reciprocal-space cutoffs. The cutoffs are computed automatically based on system geometry: [ \\eta = \\frac{(V^2 / N)^{1/6}}{\\sqrt{2\\pi}} ] [ r_{\\text{cutoff}} = \\sqrt{-2 \\ln \\varepsilon} \\cdot \\eta ] [ k_{\\text{cutoff}} = \\frac{\\sqrt{-2 \\ln \\varepsilon}}{\\eta} ] Where (\\varepsilon) is the accuracy parameter, (V) is the cell volume, and (N) is the number of atoms. Lower accuracy values (e.g., 1e-10 ) give higher precision but require more computation. Notes: Updates external LRCoulomb module if present Automatically updates neighbor lists Issues warning for legacy models (no effect) Auto-switches to \"dsf\" when PBC is detected with \"simple\" method (see PBC notes below) Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0, dsf_alpha=0.20) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-6)","title":"set_lrcoulomb_method(method, cutoff=15.0, dsf_alpha=0.2, ewald_accuracy=1e-8)"},{"location":"calculator/#set_lr_cutoffcutoff","text":"Set the unified long-range cutoff for all LR modules. Parameters: Parameter Type Description cutoff float Cutoff distance (\u00c5) for LR neighbor lists Notes: Updates both Coulomb and DFTD3 cutoffs Ewald method ignores this cutoff (uses its own internal cutoff) Automatically rebuilds neighbor lists Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_lr_cutoff(20.0) # Updates both Coulomb and DFTD3 cutoffs","title":"set_lr_cutoff(cutoff)"},{"location":"calculator/#set_dftd3_cutoffcutoffnone-smoothing_fractionnone","text":"Set DFTD3 cutoff and smoothing. Parameters: | Parameter | Type | Default | Description | | -------------------- | ------ | ------- | ----------- | ------------------------------------------ | | cutoff | float | None | 15.0 | Cutoff distance (\u00c5) | | smoothing_fraction | float | None | 0.2 | Fraction of cutoff used as smoothing width | Notes: Only updates smoothing parameters for external DFTD3 modules Always updates neighbor list cutoffs used by the calculator For legacy models with embedded DFTD3, the embedded module\u2019s smoothing parameters do not change, but the neighbor list cutoff provided by the calculator can still change dispersion behavior Example: calc = AIMNet2Calculator(\"aimnet2\") calc.set_dftd3_cutoff(cutoff=20.0, smoothing_fraction=0.25) # smoothing from 15A to 20A","title":"set_dftd3_cutoff(cutoff=None, smoothing_fraction=None)"},{"location":"calculator/#input-format","text":"","title":"Input Format"},{"location":"calculator/#required-keys","text":"Key Type Shape Description coord float32 (N, 3) or (B, N, 3) Atomic coordinates (\u00c5) numbers int64 (N,) or (B, N) Atomic numbers charge float32 (1,) or (B,) Molecular charge(s)","title":"Required Keys"},{"location":"calculator/#optional-keys","text":"Key Type Shape Description mult float32 (B,) Multiplicity mol_idx int64 (N,) Molecule index per atom cell float32 (3, 3) or (B, 3, 3) Unit cell vectors nbmat int64 (N, max_nb) Pre-computed neighbor matrix nbmat_lr int64 (N, max_nb) Long-range neighbor matrix nb_pad_mask bool (N, max_nb) Optional padding mask for nbmat nb_pad_mask_lr bool (N, max_nb) Optional padding mask for nbmat_lr shifts float32 (N, max_nb, 3) PBC shifts for neighbors shifts_lr float32 (N, max_nb, 3) PBC shifts for LR neighbors","title":"Optional Keys"},{"location":"calculator/#input-conversion","text":"The calculator automatically converts: NumPy arrays \u2192 PyTorch tensors Python lists \u2192 PyTorch tensors Scalar tensors \u2192 Shape (1,) All tensors \u2192 Correct dtype and device Any keys not listed in required/optional tables are ignored during input conversion.","title":"Input Conversion"},{"location":"calculator/#output-format","text":"Key Shape Description energy (1,) or (B,) Total energy per molecule charges (N,) or (B, N) Atomic partial charges forces (N, 3) or (B, N, 3) Atomic forces (if requested) stress (3, 3) or (B, 3, 3) Stress tensor (if requested) hessian (N, 3, N, 3) Hessian matrix (if requested) Notes: forces requires forces=True in eval() stress requires stress=True and cell in input hessian requires hessian=True , only for single molecules","title":"Output Format"},{"location":"calculator/#batching-and-neighbor-modes","text":"The calculator chooses between dense and sparse execution based on system size and device. The goal is to keep small GPU workloads fast while keeping large or CPU workloads linear in memory.","title":"Batching and Neighbor Modes"},{"location":"calculator/#dense-mode-on2","text":"When : N < nb_threshold and CUDA is available Input : 3D batched (B, N, 3) Behavior : No neighbor list; the model uses a fully connected graph Tradeoff : Fast on GPU for small molecules, but quadratic memory","title":"Dense Mode (O(N\u00b2))"},{"location":"calculator/#sparse-mode-on","text":"When : N > nb_threshold or CPU execution Input : Flattened 2D (N_total, 3) with mol_idx Behavior : Adaptive neighbor lists limit interactions to within cutoff Tradeoff : Linear memory with a small overhead for neighbor list construction","title":"Sparse Mode (O(N))"},{"location":"calculator/#mode-2-batched-sparse-manual","text":"Input : 3D batched (B, N, 3) plus 3D neighbor matrix (B, N, max_nb) Note : Supported by the model, but not selected automatically. Use this mode by supplying a 3D nbmat explicitly.","title":"Mode 2: Batched Sparse (manual)"},{"location":"calculator/#choosing-the-right-mode","text":"The calculator automatically selects between two execution modes: Mode 0 (Dense, O(N\u00b2) fully connected): Every atom interacts with every other atom in an all-to-all manner. No neighbor list is constructed. This mode is only used for batches of small molecules with the same number of atoms on GPU . Specifically: Input must be 3D batched coordinates (B, N, 3) N \u2264 nb_threshold (default 120 atoms per molecule) CUDA device available No periodic boundary conditions In this case, the O(N\u00b2) fully connected approach is more efficient than constructing neighbor lists. Mode 1 (Sparse, O(N) with neighbor lists): Uses adaptive neighbor lists to limit interactions to atoms within cutoff distance. This mode is used in all other cases: Periodic boundary conditions (required for periodic images) CPU execution Large systems (N > nb_threshold) Variable-sized molecules Key Takeaways: PBC always requires neighbor lists (Mode 1) CPU always uses neighbor lists (Mode 1) Small batched molecules on GPU use fully connected (Mode 0) Large systems use neighbor lists (Mode 1)","title":"Choosing the Right Mode"},{"location":"calculator/#flattening-logic","text":"For 3D batched inputs, AIMNet2Calculator decides whether to flatten based on nb_threshold : # nb_threshold default is 120 if device == \"cpu\" or max_atoms > nb_threshold: # FLATTEN -> Mode 1 (Sparse) # Computes neighbor list else: # KEEP 3D -> Mode 0 (Dense) # Implicit all-pairs","title":"Flattening Logic"},{"location":"calculator/#periodic-boundary-conditions-pbc","text":"","title":"Periodic Boundary Conditions (PBC)"},{"location":"calculator/#input-requirements","text":"data = { \"coord\": coords, \"numbers\": numbers, \"charge\": charge, \"cell\": cell, # (3, 3) or (num_systems, 3, 3) }","title":"Input Requirements"},{"location":"calculator/#behavior","text":"Coordinates wrapped into unit cell via move_coord_to_cell() Neighbor lists include periodic image shifts Coulomb method auto-switches to \"dsf\" if \"simple\" (with warning). For legacy JIT models the embedded Coulomb method cannot be changed at runtime; the warning indicates that only the calculator\u2019s external setting was updated. Multiple molecules with PBC: raises NotImplementedError","title":"Behavior"},{"location":"calculator/#coulomb-method-for-pbc","text":"Initial Method Action \"simple\" Auto-switch to \"dsf\" with warning \"dsf\" / \"ewald\" No change","title":"Coulomb Method for PBC"},{"location":"calculator/#neighbor-list-management","text":"","title":"Neighbor List Management"},{"location":"calculator/#adaptive-neighbor-lists","text":"The calculator uses AdaptiveNeighborList for automatic buffer management in Mode 1 : Initial sizing : Based on density estimate and cutoff Overflow handling : Increases buffer by 1.5x and retries Underutilization : Shrinks if utilization < 2/3 of target (hysteresis) Minimum buffer : 16 neighbors Memory alignment : Rounded to multiples of 16","title":"Adaptive Neighbor Lists"},{"location":"calculator/#neighbor-list-format-and-padding","text":"Neighbor lists are stored as integer matrices nbmat with shape (N_total, max_neighbors) . Each row contains neighbor indices for a single atom. Rows are padded with a dummy index (typically N_total ) when an atom has fewer neighbors than max_neighbors . The buffer grows on overflow (\u00d71.5) and shrinks when utilization drops well below target, which helps performance remain stable as density changes.","title":"Neighbor List Format and Padding"},{"location":"calculator/#module-suffix-fallback","text":"LR modules prefer their specific neighbor list key, with fallback to _lr : LRCoulomb (simple/dsf) : Tries nbmat_coulomb , falls back to nbmat_lr DFTD3/D3TS : Tries nbmat_dftd3 , falls back to nbmat_lr Note: Ewald uses its own internal neighbor list and ignores calculator cutoffs.","title":"Module Suffix Fallback"},{"location":"calculator/#device-handling","text":"","title":"Device Handling"},{"location":"calculator/#automatic-selection","text":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","title":"Automatic Selection"},{"location":"calculator/#placement","text":"Component Device Model self.device External LRCoulomb self.device External DFTD3 self.device Input tensors Converted to self.device Output tensors Remain on self.device","title":"Placement"},{"location":"calculator/#external-lr-module-configuration","text":"","title":"External LR Module Configuration"},{"location":"calculator/#lrcoulomb-setup","text":"When needs_coulomb=True : LRCoulomb( key_in=\"charges\", key_out=\"energy\", method=\"simple\", # Default, changeable via set_lrcoulomb_method() rc=metadata.get(\"coulomb_sr_rc\", 4.6), envelope=metadata.get(\"coulomb_sr_envelope\", \"exp\"), subtract_sr=not sr_embedded, # Based on coulomb_mode )","title":"LRCoulomb Setup"},{"location":"calculator/#dftd3-setup","text":"When needs_dispersion=True and d3_params available: DFTD3( s8=d3_params[\"s8\"], a1=d3_params[\"a1\"], a2=d3_params[\"a2\"], s6=d3_params.get(\"s6\", 1.0), )","title":"DFTD3 Setup"},{"location":"calculator/#how-lr-modules-are-attached","text":"External LR modules are attached based on model metadata unless overridden by constructor flags: If needs_coulomb=True , an external LRCoulomb is created. If coulomb_mode=\"sr_embedded\" , the model already subtracts SR Coulomb internally and the external module adds full Coulomb on top. If needs_dispersion=True and d3_params are present, an external DFTD3 is created. If d3_params are missing, initialization raises ValueError . Explicit needs_coulomb / needs_dispersion flags override metadata.","title":"How LR Modules Are Attached"},{"location":"calculator/#cutoff-handling-for-lr-modules","text":"Coulomb : set_lrcoulomb_method() selects the method and updates the Coulomb cutoff ( inf for \"simple\" , finite for \"dsf\" , None for \"ewald\" ). DFTD3 : set_dftd3_cutoff() updates the DFTD3 cutoff and smoothing window. Unified control : set_lr_cutoff() sets both Coulomb and DFTD3 cutoffs to the same value. Ewald : Uses its own internal neighbor list; calculator cutoffs do not apply.","title":"Cutoff Handling for LR Modules"},{"location":"calculator/#default-values","text":"","title":"Default Values"},{"location":"calculator/#lr-module-defaults","text":"Parameter Default Description set_lrcoulomb_method(..., cutoff=15.0) 15.0 Default LR cutoff for DSF (\u00c5) set_lrcoulomb_method(..., ewald_accuracy=1e-8) 1e-8 Default accuracy for Ewald summation set_dftd3_cutoff(..., smoothing_fraction=0.2) 0.2 DFTD3 smoothing width as fraction of cutoff","title":"LR Module Defaults"},{"location":"calculator/#coulomb-defaults","text":"Parameter Default Description coulomb_sr_rc 4.6 \u00c5 Short-range Coulomb cutoff coulomb_sr_envelope \"exp\" Envelope function ( \"exp\" or \"cosine\" )","title":"Coulomb Defaults"},{"location":"calculator/#sr-coulomb-cutoff-constraint","text":"coulomb_sr_rc must be \u2264 model cutoff The short-range Coulomb cutoff defines the distance within which SR Coulomb interactions are computed by the embedded SRCoulomb module. This cutoff must be less than or equal to the model's short-range cutoff because: SRCoulomb uses the same neighbor list as the neural network Atom pairs beyond the model cutoff are not visible to SRCoulomb Typical configuration: coulomb_sr_rc=4.6 \u00c5 with model cutoff=5.0 \u00c5 The envelope function ( \"exp\" or \"cosine\" ) determines how the SR interaction smoothly decays to zero at the cutoff boundary.","title":"SR Coulomb Cutoff Constraint"},{"location":"calculator/#legacy-model-compatibility","text":"Legacy JIT models ( .jpt ) have different behavior: Feature Legacy New Format Coulomb Embedded in model External module DFTD3/D3BJ Embedded in model External module set_lrcoulomb_method() Warning, no effect Updates method set_lr_cutoff() No effect on embedded modules Updates cutoff_lr for all LR modules set_dftd3_cutoff() No effect on embedded modules Updates smoothing for external DFTD3 has_external_coulomb False True (if applicable)","title":"Legacy Model Compatibility"},{"location":"calculator/#error-handling","text":"","title":"Error Handling"},{"location":"calculator/#common-errors","text":"Condition Error Invalid model type TypeError Missing required input key KeyError Hessian with multiple molecules NotImplementedError PBC with multiple molecules NotImplementedError Invalid Coulomb method ValueError needs_dispersion=True without d3_params ValueError","title":"Common Errors"},{"location":"calculator/#warnings","text":"Condition Warning set_lrcoulomb_method() on legacy model Warns, no effect PBC with \"simple\" Coulomb Auto-switches to \"dsf\"","title":"Warnings"},{"location":"calculator/#complete-example","text":"import torch from aimnet.calculators import AIMNet2Calculator # Create calculator calc = AIMNet2Calculator(\"aimnet2\") # Check configuration print(f\"Device: {calc.device}\") print(f\"Cutoff: {calc.cutoff}\") print(f\"Has external Coulomb: {calc.has_external_coulomb}\") print(f\"Coulomb method: {calc.coulomb_method}\") # Configure for PBC calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0) # Prepare input data = { \"coord\": torch.randn(20, 3), \"numbers\": torch.randint(1, 10, (20,)), \"charge\": torch.tensor([0.0]), } # Run inference result = calc.eval(data, forces=True) print(f\"Energy: {result['energy']}\") print(f\"Forces shape: {result['forces'].shape}\") print(f\"Charges shape: {result['charges'].shape}\")","title":"Complete Example"},{"location":"calculator/#performance-tips","text":"","title":"Performance Tips"},{"location":"calculator/#hardware-acceleration","text":"Use GPU for best performance: # Automatically uses CUDA if available calc = AIMNet2Calculator(\"aimnet2\") print(calc.device) # \"cuda\" or \"cpu\" GPU provides 10-50x speedup over CPU for typical workloads.","title":"Hardware Acceleration"},{"location":"calculator/#compile-mode","text":"Use compile_model=True for additional speedup: # Basic compilation calc = AIMNet2Calculator(\"aimnet2\", compile_model=True) # With custom compile options calc = AIMNet2Calculator( \"aimnet2\", compile_model=True, compile_kwargs={\"mode\": \"reduce-overhead\"} ) Characteristics: First call will be slow (compilation overhead) Subsequent calls are faster Works with both periodic and non-periodic systems When to use: Long MD trajectories Geometry optimization with many steps Repeated evaluation on same system size When not to use: Single evaluations (compilation overhead outweighs benefit) Varying system sizes (may trigger recompilation)","title":"Compile Mode"},{"location":"calculator/#memory-management","text":"Tune nb_threshold for your workload: # Conservative (less memory, earlier sparse mode) calc = AIMNet2Calculator(\"aimnet2\", nb_threshold=80) # Aggressive (more memory, faster on GPU) calc = AIMNet2Calculator(\"aimnet2\", nb_threshold=150) For large systems on GPU: Lower nb_threshold to use sparse mode Reduces memory footprint Enables processing larger molecules For many small molecules: Higher nb_threshold to use dense mode longer Maximizes GPU parallelism Faster overall throughput","title":"Memory Management"},{"location":"calculator/#pre-compute-neighbor-lists","text":"Avoid recomputation by caching: # First call: computes neighbor lists result1 = calc(data, forces=True) # If geometry unchanged, reuse same data dict # Calculator caches neighbor lists internally result2 = calc(data, forces=False) # Reuses cached lists For custom workflows, provide nbmat explicitly: # Compute once nbmat, _, shifts = compute_neighbor_list(coords, cutoff=5.0) # Use many times for _ in range(1000): result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"nbmat\": nbmat, \"shifts\": shifts, }, forces=True)","title":"Pre-compute Neighbor Lists"},{"location":"calculator/#coulomb-method-selection","text":"Choose method for your system: System Type Method Parameter Notes Small non-PBC \"simple\" N/A All pairs, exact Large non-PBC \"dsf\" cutoff=12-15 \u00c5 O(N) scaling PBC systems \"dsf\" cutoff=12-15 \u00c5 Recommended High-accuracy PBC \"ewald\" accuracy=1e-8 Research-grade # Fast for non-PBC calc.set_lrcoulomb_method(\"simple\") # Efficient for PBC calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # High-accuracy for research calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8)","title":"Coulomb Method Selection"},{"location":"calculator/#multi-threading-cpu","text":"Set thread count for CPU execution: import torch torch.set_num_threads(4) # Use 4 CPU cores calc = AIMNet2Calculator(\"aimnet2\") # Will use CPU","title":"Multi-threading (CPU)"},{"location":"cli/","text":"CLI Reference \u00b6 AIMNet2 provides command-line tools for training, model export, conversion, and data preprocessing. Installation \u00b6 CLI tools are available with the train extras: pip install \"aimnet[train] @ git+https://github.com/isayevlab/aimnetcentral.git\" Commands Overview \u00b6 Command Purpose Typical Use aimnet train Train a model Training from scratch aimnet export Export trained weights to inference format After training aimnet convert Convert legacy .jpt to new .pt format Migrating old models aimnet calc_sae Calculate self-atomic energies Before training aimnet train \u00b6 Train an AIMNet2 model from a configuration file. Basic Usage \u00b6 aimnet train --config config.yaml --model model.yaml Options \u00b6 aimnet train [OPTIONS] Option Type Description --config PATH Required Training configuration YAML file --model PATH Required Model architecture YAML file --resume PATH Optional Resume from checkpoint --device DEVICE Optional Device to use (cuda/cpu) Example Configuration \u00b6 Training requires two YAML files: config.yaml (training parameters): data: train: data/train.h5 val: data/val.h5 batch_size: 32 optimizer: lr: 0.001 weight_decay: 0.0 training: epochs: 100 checkpoint_dir: checkpoints/ log_interval: 10 model.yaml (architecture): class: aimnet.models.AIMNet2 kwargs: nfeature: 16 hidden: [[512, 380], [512, 380]] aev: rc_s: 5.0 nshifts_s: 16 outputs: energy_mlp: class: aimnet.modules.Output # ... output configuration Complete Example \u00b6 # Train with W&B logging aimnet train \\ --config experiments/train_config.yaml \\ --model models/aimnet2.yaml \\ --device cuda # Resume training aimnet train \\ --config experiments/train_config.yaml \\ --model models/aimnet2.yaml \\ --resume checkpoints/last.pt See train.md for detailed training documentation. aimnet export \u00b6 Export trained model weights to inference format (.pt). Basic Usage \u00b6 aimnet export weights.pt output.pt --model model.yaml --sae sae.yaml Options \u00b6 aimnet export INPUT OUTPUT [OPTIONS] Positional Arguments: Argument Description INPUT Path to trained weights (.pt checkpoint) OUTPUT Path for exported model (.pt file) Options: Option Description --model PATH Model architecture YAML (required) --sae PATH Self-atomic energies YAML (required) --needs-coulomb Force external Coulomb module --needs-dispersion Force external DFTD3 module Export Process \u00b6 The export process: Loads model architecture from YAML Strips LRCoulomb/DFTD3 modules Adds SRCoulomb if LRCoulomb was present Loads trained weights Bakes SAE into atomic_shift as float64 Masks unimplemented species Saves with metadata Examples \u00b6 Basic export: aimnet export \\ checkpoints/best.pt \\ models/aimnet2_production.pt \\ --model configs/aimnet2.yaml \\ --sae configs/sae.yaml Override auto-detection: # Force external Coulomb and DFTD3 aimnet export weights.pt model.pt \\ --model config.yaml \\ --sae sae.yaml \\ --needs-coulomb \\ --needs-dispersion Export without dispersion: # Model without DFTD3 correction aimnet export weights.pt model_no_d3.pt \\ --model config_no_d3.yaml \\ --sae sae.yaml aimnet convert \u00b6 Convert legacy .jpt (JIT) models to new .pt format. Basic Usage \u00b6 aimnet convert model.jpt config.yaml output.pt Options \u00b6 aimnet convert INPUT CONFIG OUTPUT Positional Arguments: Argument Description INPUT Legacy .jpt model file CONFIG Original model configuration YAML OUTPUT Output .pt model file Conversion Process \u00b6 Loads legacy JIT model Extracts weights from state dict Strips embedded LR modules Adds SRCoulomb if needed Converts atomic_shift to float64 Generates metadata Saves as v2 format Example \u00b6 # Convert legacy model aimnet convert \\ legacy/aimnet2_old.jpt \\ configs/aimnet2.yaml \\ models/aimnet2_new.pt # Verify conversion python -c \" from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator('models/aimnet2_new.pt') print(f'Cutoff: {calc.cutoff}') print(f'Has external Coulomb: {calc.has_external_coulomb}') \" See model_format.md for detailed migration guide. aimnet calc_sae \u00b6 Calculate self-atomic energies (SAE) from a dataset. Basic Usage \u00b6 aimnet calc_sae dataset.h5 output_sae.yaml Options \u00b6 aimnet calc_sae INPUT OUTPUT [OPTIONS] Positional Arguments: Argument Description INPUT HDF5 dataset with single-atom energies OUTPUT Output YAML file for SAE values Options: Option Description --elements LIST Comma-separated atomic numbers (e.g., \"1,6,7,8\") SAE Format \u00b6 Output YAML format: # Self-atomic energies in eV 1: -13.587 # Hydrogen 6: -1027.592 # Carbon 7: -1483.525 # Nitrogen 8: -2039.734 # Oxygen Example \u00b6 # Calculate SAE for H, C, N, O aimnet calc_sae \\ data/single_atoms.h5 \\ configs/sae.yaml \\ --elements \"1,6,7,8\" # Use in training aimnet train \\ --config train_config.yaml \\ --model model.yaml # SAE loaded from train_config Creating Single-Atom Dataset \u00b6 SAE calculation requires single-atom reference calculations: import h5py import numpy as np # Single-atom energies from reference calculations (e.g., DFT) sae_data = { 1: -13.587, # H atom energy 6: -1027.592, # C atom energy # ... more elements } # Create HDF5 dataset with h5py.File(\"single_atoms.h5\", \"w\") as f: for z, energy in sae_data.items(): grp = f.create_group(f\"atom_{z}\") grp[\"energy\"] = energy grp[\"numbers\"] = [z] Common Workflows \u00b6 Complete Training Workflow \u00b6 # 1. Calculate SAE aimnet calc_sae single_atoms.h5 sae.yaml # 2. Train model aimnet train \\ --config config.yaml \\ --model aimnet2.yaml # 3. Export best checkpoint aimnet export \\ checkpoints/best.pt \\ production_model.pt \\ --model aimnet2.yaml \\ --sae sae.yaml # 4. Validate python validate_model.py production_model.pt Legacy Migration Workflow \u00b6 # 1. Convert .jpt to .pt aimnet convert \\ old_model.jpt \\ original_config.yaml \\ new_model.pt # 2. Test equivalence python test_equivalence.py old_model.jpt new_model.pt # 3. Update inference code # Replace: calc = AIMNet2Calculator(\"old_model.jpt\") # With: calc = AIMNet2Calculator(\"new_model.pt\") Environment Variables \u00b6 Variable Description Default AIMNET_CACHE_DIR Model cache directory ~/.cache/aimnet/ CUDA_VISIBLE_DEVICES GPU device selection All available Exit Codes \u00b6 Code Meaning 0 Success 1 General error 2 Invalid arguments 3 File not found 4 Configuration error Getting Help \u00b6 # General help aimnet --help # Command-specific help aimnet train --help aimnet export --help aimnet convert --help aimnet calc_sae --help See Also \u00b6 Training Guide - Detailed training documentation Model Format - Model file specifications Calculator API - Python inference API","title":"CLI Reference"},{"location":"cli/#cli-reference","text":"AIMNet2 provides command-line tools for training, model export, conversion, and data preprocessing.","title":"CLI Reference"},{"location":"cli/#installation","text":"CLI tools are available with the train extras: pip install \"aimnet[train] @ git+https://github.com/isayevlab/aimnetcentral.git\"","title":"Installation"},{"location":"cli/#commands-overview","text":"Command Purpose Typical Use aimnet train Train a model Training from scratch aimnet export Export trained weights to inference format After training aimnet convert Convert legacy .jpt to new .pt format Migrating old models aimnet calc_sae Calculate self-atomic energies Before training","title":"Commands Overview"},{"location":"cli/#aimnet-train","text":"Train an AIMNet2 model from a configuration file.","title":"aimnet train"},{"location":"cli/#basic-usage","text":"aimnet train --config config.yaml --model model.yaml","title":"Basic Usage"},{"location":"cli/#options","text":"aimnet train [OPTIONS] Option Type Description --config PATH Required Training configuration YAML file --model PATH Required Model architecture YAML file --resume PATH Optional Resume from checkpoint --device DEVICE Optional Device to use (cuda/cpu)","title":"Options"},{"location":"cli/#example-configuration","text":"Training requires two YAML files: config.yaml (training parameters): data: train: data/train.h5 val: data/val.h5 batch_size: 32 optimizer: lr: 0.001 weight_decay: 0.0 training: epochs: 100 checkpoint_dir: checkpoints/ log_interval: 10 model.yaml (architecture): class: aimnet.models.AIMNet2 kwargs: nfeature: 16 hidden: [[512, 380], [512, 380]] aev: rc_s: 5.0 nshifts_s: 16 outputs: energy_mlp: class: aimnet.modules.Output # ... output configuration","title":"Example Configuration"},{"location":"cli/#complete-example","text":"# Train with W&B logging aimnet train \\ --config experiments/train_config.yaml \\ --model models/aimnet2.yaml \\ --device cuda # Resume training aimnet train \\ --config experiments/train_config.yaml \\ --model models/aimnet2.yaml \\ --resume checkpoints/last.pt See train.md for detailed training documentation.","title":"Complete Example"},{"location":"cli/#aimnet-export","text":"Export trained model weights to inference format (.pt).","title":"aimnet export"},{"location":"cli/#basic-usage_1","text":"aimnet export weights.pt output.pt --model model.yaml --sae sae.yaml","title":"Basic Usage"},{"location":"cli/#options_1","text":"aimnet export INPUT OUTPUT [OPTIONS] Positional Arguments: Argument Description INPUT Path to trained weights (.pt checkpoint) OUTPUT Path for exported model (.pt file) Options: Option Description --model PATH Model architecture YAML (required) --sae PATH Self-atomic energies YAML (required) --needs-coulomb Force external Coulomb module --needs-dispersion Force external DFTD3 module","title":"Options"},{"location":"cli/#export-process","text":"The export process: Loads model architecture from YAML Strips LRCoulomb/DFTD3 modules Adds SRCoulomb if LRCoulomb was present Loads trained weights Bakes SAE into atomic_shift as float64 Masks unimplemented species Saves with metadata","title":"Export Process"},{"location":"cli/#examples","text":"Basic export: aimnet export \\ checkpoints/best.pt \\ models/aimnet2_production.pt \\ --model configs/aimnet2.yaml \\ --sae configs/sae.yaml Override auto-detection: # Force external Coulomb and DFTD3 aimnet export weights.pt model.pt \\ --model config.yaml \\ --sae sae.yaml \\ --needs-coulomb \\ --needs-dispersion Export without dispersion: # Model without DFTD3 correction aimnet export weights.pt model_no_d3.pt \\ --model config_no_d3.yaml \\ --sae sae.yaml","title":"Examples"},{"location":"cli/#aimnet-convert","text":"Convert legacy .jpt (JIT) models to new .pt format.","title":"aimnet convert"},{"location":"cli/#basic-usage_2","text":"aimnet convert model.jpt config.yaml output.pt","title":"Basic Usage"},{"location":"cli/#options_2","text":"aimnet convert INPUT CONFIG OUTPUT Positional Arguments: Argument Description INPUT Legacy .jpt model file CONFIG Original model configuration YAML OUTPUT Output .pt model file","title":"Options"},{"location":"cli/#conversion-process","text":"Loads legacy JIT model Extracts weights from state dict Strips embedded LR modules Adds SRCoulomb if needed Converts atomic_shift to float64 Generates metadata Saves as v2 format","title":"Conversion Process"},{"location":"cli/#example","text":"# Convert legacy model aimnet convert \\ legacy/aimnet2_old.jpt \\ configs/aimnet2.yaml \\ models/aimnet2_new.pt # Verify conversion python -c \" from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator('models/aimnet2_new.pt') print(f'Cutoff: {calc.cutoff}') print(f'Has external Coulomb: {calc.has_external_coulomb}') \" See model_format.md for detailed migration guide.","title":"Example"},{"location":"cli/#aimnet-calc_sae","text":"Calculate self-atomic energies (SAE) from a dataset.","title":"aimnet calc_sae"},{"location":"cli/#basic-usage_3","text":"aimnet calc_sae dataset.h5 output_sae.yaml","title":"Basic Usage"},{"location":"cli/#options_3","text":"aimnet calc_sae INPUT OUTPUT [OPTIONS] Positional Arguments: Argument Description INPUT HDF5 dataset with single-atom energies OUTPUT Output YAML file for SAE values Options: Option Description --elements LIST Comma-separated atomic numbers (e.g., \"1,6,7,8\")","title":"Options"},{"location":"cli/#sae-format","text":"Output YAML format: # Self-atomic energies in eV 1: -13.587 # Hydrogen 6: -1027.592 # Carbon 7: -1483.525 # Nitrogen 8: -2039.734 # Oxygen","title":"SAE Format"},{"location":"cli/#example_1","text":"# Calculate SAE for H, C, N, O aimnet calc_sae \\ data/single_atoms.h5 \\ configs/sae.yaml \\ --elements \"1,6,7,8\" # Use in training aimnet train \\ --config train_config.yaml \\ --model model.yaml # SAE loaded from train_config","title":"Example"},{"location":"cli/#creating-single-atom-dataset","text":"SAE calculation requires single-atom reference calculations: import h5py import numpy as np # Single-atom energies from reference calculations (e.g., DFT) sae_data = { 1: -13.587, # H atom energy 6: -1027.592, # C atom energy # ... more elements } # Create HDF5 dataset with h5py.File(\"single_atoms.h5\", \"w\") as f: for z, energy in sae_data.items(): grp = f.create_group(f\"atom_{z}\") grp[\"energy\"] = energy grp[\"numbers\"] = [z]","title":"Creating Single-Atom Dataset"},{"location":"cli/#common-workflows","text":"","title":"Common Workflows"},{"location":"cli/#complete-training-workflow","text":"# 1. Calculate SAE aimnet calc_sae single_atoms.h5 sae.yaml # 2. Train model aimnet train \\ --config config.yaml \\ --model aimnet2.yaml # 3. Export best checkpoint aimnet export \\ checkpoints/best.pt \\ production_model.pt \\ --model aimnet2.yaml \\ --sae sae.yaml # 4. Validate python validate_model.py production_model.pt","title":"Complete Training Workflow"},{"location":"cli/#legacy-migration-workflow","text":"# 1. Convert .jpt to .pt aimnet convert \\ old_model.jpt \\ original_config.yaml \\ new_model.pt # 2. Test equivalence python test_equivalence.py old_model.jpt new_model.pt # 3. Update inference code # Replace: calc = AIMNet2Calculator(\"old_model.jpt\") # With: calc = AIMNet2Calculator(\"new_model.pt\")","title":"Legacy Migration Workflow"},{"location":"cli/#environment-variables","text":"Variable Description Default AIMNET_CACHE_DIR Model cache directory ~/.cache/aimnet/ CUDA_VISIBLE_DEVICES GPU device selection All available","title":"Environment Variables"},{"location":"cli/#exit-codes","text":"Code Meaning 0 Success 1 General error 2 Invalid arguments 3 File not found 4 Configuration error","title":"Exit Codes"},{"location":"cli/#getting-help","text":"# General help aimnet --help # Command-specific help aimnet train --help aimnet export --help aimnet convert --help aimnet calc_sae --help","title":"Getting Help"},{"location":"cli/#see-also","text":"Training Guide - Detailed training documentation Model Format - Model file specifications Calculator API - Python inference API","title":"See Also"},{"location":"getting_started/","text":"Getting Started with AIMNet2 \u00b6 This guide will help you get up and running with AIMNet2 for molecular simulations. Prerequisites \u00b6 Python : Version 3.11 or 3.12 pip : Package installer (usually included with Python) Optional : CUDA-capable GPU for faster inference Installation \u00b6 Basic Installation \u00b6 Install AIMNet2 from PyPI: pip install aimnet With ASE Integration \u00b6 For molecular dynamics and geometry optimization with ASE: pip install \"aimnet[ase]\" GPU Support \u00b6 AIMNet2 works on CPU by default. For GPU acceleration, install PyTorch with CUDA: # For CUDA 12.4 pip install torch --index-url https://download.pytorch.org/whl/cu124 Check pytorch.org for other CUDA versions. Your First Calculation \u00b6 Let's compute the energy and forces for a water molecule: import torch from aimnet.calculators import AIMNet2Calculator # Create calculator with default model calc = AIMNet2Calculator(\"aimnet2\") # Water molecule coordinates (Angstrom) coords = torch.tensor([ [0.0000, 0.0000, 0.1173], # O [0.0000, 0.7572, -0.4692], # H [0.0000, -0.7572, -0.4692], # H ]) # Run calculation result = calc({ \"coord\": coords, \"numbers\": torch.tensor([8, 1, 1]), # O, H, H \"charge\": 0.0, }, forces=True) print(f\"Energy: {result['energy'].item():.4f} eV\") print(f\"Forces shape: {result['forces'].shape}\") Understanding the Output \u00b6 The calculator returns a dictionary with: Key Shape Description Units energy () or (B,) Total energy eV charges (N,) or (B, N) Atomic partial charges e forces (N, 3) or (B, N, 3) Atomic forces (if requested) eV/\u00c5 stress (3, 3) or (B, 3, 3) Stress tensor (if requested with PBC) eV/\u00c5\u00b3 hessian (N, 3, N, 3) Hessian matrix (if requested, single molecule) eV/\u00c5\u00b2 Common Tasks \u00b6 Batch Processing \u00b6 Process multiple molecules at once. For molecules with different atom counts, use flat coordinates with mol_idx to indicate which molecule each atom belongs to: # Water (3 atoms) and ammonia cation (5 atoms) # Use flat coordinates with mol_idx for different-sized molecules coords = torch.tensor([ # Water: O at origin, two H atoms [0.0, 0.0, 0.0], [0.96, 0.0, 0.0], [-0.24, 0.93, 0.0], # Ammonia cation: N at origin, four H atoms (tetrahedral) [0.0, 0.0, 0.0], [0.59, 0.59, 0.59], [0.59, -0.59, -0.59], [-0.59, 0.59, -0.59], [-0.59, -0.59, 0.59], ]) result = calc({ \"coord\": coords, # (8, 3) flat \"numbers\": torch.tensor([8, 1, 1, 7, 1, 1, 1, 1]), # O, H, H, N, H, H, H, H \"charge\": torch.tensor([0.0, 1.0]), # Water: 0, NH4+: +1 \"mol_idx\": torch.tensor([0, 0, 0, 1, 1, 1, 1, 1]), # Which molecule each atom belongs to }, forces=True) # result[\"energy\"] has shape (2,) - one energy per molecule # result[\"forces\"] has shape (8, 3) - forces for all atoms Periodic Systems \u00b6 For systems with periodic boundary conditions: # Bulk silicon cell cell = torch.tensor([ [5.43, 0.00, 0.00], [0.00, 5.43, 0.00], [0.00, 0.00, 5.43], ]) result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True, stress=True) # Access stress tensor stress = result[\"stress\"] # (3, 3) For periodic systems, configure the Coulomb method: # Use DSF for periodic systems (recommended) calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) Charged Systems \u00b6 AIMNet2 handles charged molecules: # Hydroxide ion (OH-) result = calc({ \"coord\": coords, \"numbers\": torch.tensor([8, 1]), # O, H \"charge\": -1.0, # Net charge }, forces=True) Using Different Models \u00b6 Choose a specific model for your chemistry: # For palladium-containing systems calc_pd = AIMNet2Calculator(\"aimnet2pd\") # For open-shell systems calc_nse = AIMNet2Calculator(\"aimnet2nse\") # Ensemble averaging (recommended for production) calcs = [AIMNet2Calculator(f\"aimnet2_{i}\") for i in range(4)] energies = [calc(data)[\"energy\"] for calc in calcs] avg_energy = sum(energies) / len(energies) ASE Integration \u00b6 Use AIMNet2 with ASE for optimization and molecular dynamics: from ase.io import read from ase.optimize import BFGS from aimnet.calculators import AIMNet2ASE # Load structure atoms = read(\"molecule.xyz\") # Attach calculator atoms.calc = AIMNet2ASE(\"aimnet2\") # Optimize geometry opt = BFGS(atoms) opt.run(fmax=0.01) # Converge to 0.01 eV/Angstrom # Get final energy final_energy = atoms.get_potential_energy() Next Steps \u00b6 Now that you're familiar with the basics, explore: Calculator API - Complete reference for all calculator features Long Range Methods - Choosing Coulomb methods for your system Model Format - Understanding model files and metadata Training Guide - Training custom models on your data Performance Tips \u00b6 Use GPU : Install CUDA-enabled PyTorch for 10-50x speedup Batch molecules : Process similar-sized molecules together Compile mode : Use compile_model=True for MD Adjust nb_threshold : Lower values use less memory, higher values are faster on GPU # For molecular dynamics with compilation calc = AIMNet2Calculator(\"aimnet2\", compile_model=True) # Force specific device calc = AIMNet2Calculator(\"aimnet2\", device=\"cuda:0\") Getting Help \u00b6 Documentation : You're reading it! Check the sidebar for more topics Issues : GitHub Issues Discussions : GitHub Discussions","title":"Getting Started"},{"location":"getting_started/#getting-started-with-aimnet2","text":"This guide will help you get up and running with AIMNet2 for molecular simulations.","title":"Getting Started with AIMNet2"},{"location":"getting_started/#prerequisites","text":"Python : Version 3.11 or 3.12 pip : Package installer (usually included with Python) Optional : CUDA-capable GPU for faster inference","title":"Prerequisites"},{"location":"getting_started/#installation","text":"","title":"Installation"},{"location":"getting_started/#basic-installation","text":"Install AIMNet2 from PyPI: pip install aimnet","title":"Basic Installation"},{"location":"getting_started/#with-ase-integration","text":"For molecular dynamics and geometry optimization with ASE: pip install \"aimnet[ase]\"","title":"With ASE Integration"},{"location":"getting_started/#gpu-support","text":"AIMNet2 works on CPU by default. For GPU acceleration, install PyTorch with CUDA: # For CUDA 12.4 pip install torch --index-url https://download.pytorch.org/whl/cu124 Check pytorch.org for other CUDA versions.","title":"GPU Support"},{"location":"getting_started/#your-first-calculation","text":"Let's compute the energy and forces for a water molecule: import torch from aimnet.calculators import AIMNet2Calculator # Create calculator with default model calc = AIMNet2Calculator(\"aimnet2\") # Water molecule coordinates (Angstrom) coords = torch.tensor([ [0.0000, 0.0000, 0.1173], # O [0.0000, 0.7572, -0.4692], # H [0.0000, -0.7572, -0.4692], # H ]) # Run calculation result = calc({ \"coord\": coords, \"numbers\": torch.tensor([8, 1, 1]), # O, H, H \"charge\": 0.0, }, forces=True) print(f\"Energy: {result['energy'].item():.4f} eV\") print(f\"Forces shape: {result['forces'].shape}\")","title":"Your First Calculation"},{"location":"getting_started/#understanding-the-output","text":"The calculator returns a dictionary with: Key Shape Description Units energy () or (B,) Total energy eV charges (N,) or (B, N) Atomic partial charges e forces (N, 3) or (B, N, 3) Atomic forces (if requested) eV/\u00c5 stress (3, 3) or (B, 3, 3) Stress tensor (if requested with PBC) eV/\u00c5\u00b3 hessian (N, 3, N, 3) Hessian matrix (if requested, single molecule) eV/\u00c5\u00b2","title":"Understanding the Output"},{"location":"getting_started/#common-tasks","text":"","title":"Common Tasks"},{"location":"getting_started/#batch-processing","text":"Process multiple molecules at once. For molecules with different atom counts, use flat coordinates with mol_idx to indicate which molecule each atom belongs to: # Water (3 atoms) and ammonia cation (5 atoms) # Use flat coordinates with mol_idx for different-sized molecules coords = torch.tensor([ # Water: O at origin, two H atoms [0.0, 0.0, 0.0], [0.96, 0.0, 0.0], [-0.24, 0.93, 0.0], # Ammonia cation: N at origin, four H atoms (tetrahedral) [0.0, 0.0, 0.0], [0.59, 0.59, 0.59], [0.59, -0.59, -0.59], [-0.59, 0.59, -0.59], [-0.59, -0.59, 0.59], ]) result = calc({ \"coord\": coords, # (8, 3) flat \"numbers\": torch.tensor([8, 1, 1, 7, 1, 1, 1, 1]), # O, H, H, N, H, H, H, H \"charge\": torch.tensor([0.0, 1.0]), # Water: 0, NH4+: +1 \"mol_idx\": torch.tensor([0, 0, 0, 1, 1, 1, 1, 1]), # Which molecule each atom belongs to }, forces=True) # result[\"energy\"] has shape (2,) - one energy per molecule # result[\"forces\"] has shape (8, 3) - forces for all atoms","title":"Batch Processing"},{"location":"getting_started/#periodic-systems","text":"For systems with periodic boundary conditions: # Bulk silicon cell cell = torch.tensor([ [5.43, 0.00, 0.00], [0.00, 5.43, 0.00], [0.00, 0.00, 5.43], ]) result = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True, stress=True) # Access stress tensor stress = result[\"stress\"] # (3, 3) For periodic systems, configure the Coulomb method: # Use DSF for periodic systems (recommended) calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0)","title":"Periodic Systems"},{"location":"getting_started/#charged-systems","text":"AIMNet2 handles charged molecules: # Hydroxide ion (OH-) result = calc({ \"coord\": coords, \"numbers\": torch.tensor([8, 1]), # O, H \"charge\": -1.0, # Net charge }, forces=True)","title":"Charged Systems"},{"location":"getting_started/#using-different-models","text":"Choose a specific model for your chemistry: # For palladium-containing systems calc_pd = AIMNet2Calculator(\"aimnet2pd\") # For open-shell systems calc_nse = AIMNet2Calculator(\"aimnet2nse\") # Ensemble averaging (recommended for production) calcs = [AIMNet2Calculator(f\"aimnet2_{i}\") for i in range(4)] energies = [calc(data)[\"energy\"] for calc in calcs] avg_energy = sum(energies) / len(energies)","title":"Using Different Models"},{"location":"getting_started/#ase-integration","text":"Use AIMNet2 with ASE for optimization and molecular dynamics: from ase.io import read from ase.optimize import BFGS from aimnet.calculators import AIMNet2ASE # Load structure atoms = read(\"molecule.xyz\") # Attach calculator atoms.calc = AIMNet2ASE(\"aimnet2\") # Optimize geometry opt = BFGS(atoms) opt.run(fmax=0.01) # Converge to 0.01 eV/Angstrom # Get final energy final_energy = atoms.get_potential_energy()","title":"ASE Integration"},{"location":"getting_started/#next-steps","text":"Now that you're familiar with the basics, explore: Calculator API - Complete reference for all calculator features Long Range Methods - Choosing Coulomb methods for your system Model Format - Understanding model files and metadata Training Guide - Training custom models on your data","title":"Next Steps"},{"location":"getting_started/#performance-tips","text":"Use GPU : Install CUDA-enabled PyTorch for 10-50x speedup Batch molecules : Process similar-sized molecules together Compile mode : Use compile_model=True for MD Adjust nb_threshold : Lower values use less memory, higher values are faster on GPU # For molecular dynamics with compilation calc = AIMNet2Calculator(\"aimnet2\", compile_model=True) # Force specific device calc = AIMNet2Calculator(\"aimnet2\", device=\"cuda:0\")","title":"Performance Tips"},{"location":"getting_started/#getting-help","text":"Documentation : You're reading it! Check the sidebar for more topics Issues : GitHub Issues Discussions : GitHub Discussions","title":"Getting Help"},{"location":"long_range/","text":"Long-Range Modules \u00b6 This page documents the long-range (LR) modules implemented in aimnet/modules/lr.py . All modules operate on the shared data dictionary and add their contributions to data[key_out] (usually energy ). Choosing a Coulomb Method \u00b6 Select the appropriate method based on your system and accuracy requirements. Simple (All-Pairs Pairwise Coulomb) \u00b6 Only for non-periodic systems. The calculator automatically switches to DSF if PBC is detected. When to use: Small non-periodic systems (< 100 atoms) Quick calculations where exact Coulomb is acceptable Non-production exploratory work When NOT to use: Periodic systems (NOT SUPPORTED - auto-switches to DSF) Large systems (O(N\u00b2) fully connected becomes prohibitive) Production MD (inefficient for repeated evaluation) Configuration: calc.set_lrcoulomb_method(\"simple\") # No cutoff - all pairs evaluated # WARNING: Will auto-switch to DSF if PBC (cell) is provided Characteristics: Exact pairwise 1/r Coulomb sum for non-periodic systems All atom pairs evaluated (fully connected) O(N\u00b2) complexity Not applicable to periodic boundary conditions DSF (Damped Shifted Force) \u00b6 When to use: Periodic boundary conditions (recommended) Large non-periodic systems (> 200 atoms) Production molecular dynamics When computational efficiency matters When NOT to use: When highest accuracy is required (use Ewald instead) Very small systems where Simple is faster Configuration: calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) Parameters: Parameter Typical Range Default Notes cutoff 12-20 \u00c5 15.0 \u00c5 Larger = more accurate, more expensive dsf_alpha 0.1-0.3 0.2 Damping strength; 0.2 works well for most systems Tuning guidelines: Start with cutoff=15.0 \u00c5, alpha=0.2 (default) Dense systems: reduce cutoff to 12 \u00c5 Dilute/surface systems: increase cutoff to 18-20 \u00c5 Validate: energies should converge within ~0.1 kcal/mol as cutoff increases Characteristics: Smooth truncation at cutoff with shifted force Maintains charge neutrality O(N) scaling with neighbor lists Energy and forces continuous at cutoff Based on Wolf summation method Ewald Summation \u00b6 When to use: Research-grade accuracy required Benchmarking and validation studies Systems where electrostatics dominate behavior When computational cost is acceptable When NOT to use: Long MD trajectories (slower than DSF) When DSF accuracy is sufficient Very large systems (reciprocal space cost increases) Configuration: # Default accuracy (1e-8) calc.set_lrcoulomb_method(\"ewald\") # Custom accuracy (higher precision, more computation) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-10) # Lower accuracy (faster, but less precise) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-6) Accuracy Parameter: The ewald_accuracy parameter controls the real-space and reciprocal-space cutoffs. Lower values give higher precision but require more computation. The cutoffs are computed automatically based on system geometry: [ \\eta = \\frac{(V^2 / N)^{1/6}}{\\sqrt{2\\pi}} ] [ r {\\text{cutoff}} = \\sqrt{-2 \\ln \\varepsilon} \\cdot \\eta, \\quad k {\\text{cutoff}} = \\frac{\\sqrt{-2 \\ln \\varepsilon}}{\\eta} ] Where (\\varepsilon) is the accuracy parameter, (V) is the cell volume, and (N) is the number of atoms. Characteristics: Splits Coulomb into real-space + reciprocal-space + self-energy terms Configurable accuracy target (default 1e-8) Automatically determines k-space vectors based on accuracy O(N log N) to O(N^1.5) complexity depending on implementation Most accurate method for periodic systems When Ewald matters: Computing precise thermodynamic properties Benchmark comparisons against QM calculations Validation of other Coulomb methods Systems with significant long-range charge ordering Method Comparison \u00b6 Method Complexity PBC Support Typical Use Case Notes Simple O(N\u00b2) fully connected No Small molecules, quick tests Auto-switches for PBC DSF O(N) with neighbor lists Yes Production MD, large systems Recommended for PBC Ewald O(N log N) to O(N^1.5) Yes High-accuracy benchmarks Research-grade precision Accuracy hierarchy: Ewald > DSF > Simple (for PBC) Speed hierarchy: Simple (small N) > DSF > Ewald Recommendation: Use DSF for periodic systems unless you need Ewald's precision. Common Data and Neighbor-List Handling \u00b6 Neighbor-list keys and suffix fallback Coulomb modules prefer nbmat_coulomb and fall back to nbmat_lr . Dispersion modules ( DFTD3 , D3TS ) prefer nbmat_dftd3 and fall back to nbmat_lr . This fallback behavior is implemented via nbops.resolve_suffix , and distance calculation is lazily computed with ops.lazy_calc_dij . Distance and masking Distances use d_ij{suffix} derived from coord (and shifts{suffix} when PBC is present). Padding/diagonal pairs are masked via mask_ij{suffix} . For DSF, pairs beyond Rc are also masked. LRCoulomb \u00b6 LRCoulomb computes a long-range Coulomb contribution, optionally subtracting the short-range (SR) part to avoid double counting. Inputs charges (default key_in ) coord , cell (for Ewald) Neighbor lists as described above Methods Simple (full pairwise Coulomb) Pair energy: e_ij = q_i q_j / r_ij Total energy: E = factor * sum_i sum_j e_ij (accumulated in float64) If subtract_sr=True , subtracts the SR energy described below. DSF (damped shifted force) Uses ops.coulomb_matrix_dsf : J(r) = erfc(alpha r)/r - erfc(alpha Rc)/Rc + (r - Rc) * (erfc(alpha Rc)/Rc^2 + 2 alpha exp(-(alpha Rc)^2) / (Rc sqrt(pi))) Pairs with r > Rc or masked entries are zeroed. Energy is: E = factor * sum_i sum_j q_i q_j J(r_ij) If subtract_sr=True , the SR term is subtracted. Ewald Uses ops.coulomb_matrix_ewald , which implements real-space + reciprocal-space + self terms with fixed accuracy ( 1e-8 ). This path requires a single molecule with coord.ndim == 2 and cell.ndim == 2 . If subtract_sr=True , the SR term is subtracted. SR subtraction (shared by all methods) The SR term uses an envelope cutoff: exp : fc(d) = exp(-1 / (1 - (d/rc)^2)) / 0.36787944117144233 cosine : fc(d) = 0.5 * (cos(pi * d / rc) + 1) SR pair energy: e_ij = fc(r_ij) * q_i q_j / r_ij The SR contribution is summed per molecule and subtracted from key_out when subtract_sr=True . SRCoulomb \u00b6 SRCoulomb subtracts the SR Coulomb contribution from key_out . It uses the same SR formula as LRCoulomb (envelope + cutoff) and is typically embedded in models trained with SR Coulomb so that external LR methods can add the full Coulomb energy without double counting. DispParam \u00b6 DispParam produces per-atom dispersion parameters ( c6 , alpha ) from a reference table. Reference is loaded from a .pt file or provided as ref_c6 / ref_alpha . Per-atom scaling uses disp_param_mult = exp(clamp(disp_param, -4, 4)) . Output disp_param has shape (N, 2) with columns (c6, alpha) . D3TS \u00b6 D3TS implements a DFT-D3-like pairwise dispersion with the TS combination rule. Inputs disp_param (from DispParam ) coord , numbers Neighbor lists with _dftd3 or _lr suffix Key equations TS combination rule: c6_ij = 2 c6_i c6_j / (c6_i * alpha_j / alpha_i + c6_j * alpha_i / alpha_j) Let rr = r4r2[numbers] and rr_ij = 3 * rr_i * rr_j . The BJ-like radius term is: r0_ij = a1 * sqrt(rr_ij) + a2 Distances are converted to Bohr: r = d_ij * Bohr_inv . Energy per pair: e_ij = c6_ij * (s6 / (r^6 + r0_ij^6) + s8 * rr_ij / (r^8 + r0_ij^8)) Total energy is summed per molecule and multiplied by -half_Hartree . DFTD3 \u00b6 DFTD3 computes DFT-D3 dispersion correction using the BJ damping function with C6/C8 terms. Uses the dftd3_energy custom autograd op from aimnet.modules.ops . No 3-body term (Axilrod-Teller-Muto) is included. Smoothing Window \u00b6 Dispersion interactions are smoothly damped to zero near the cutoff to ensure continuous energy and forces. The smoothing window is defined by: smoothing_on = cutoff * (1 - smoothing_fraction) smoothing_off = cutoff Parameters: Parameter Typical Value Default Effect cutoff 15-20 \u00c5 15.0 \u00c5 Interaction cutoff distance smoothing_fraction 0.1-0.3 0.2 Width of smoothing region as fraction of cutoff Example: With cutoff=15.0 \u00c5 and smoothing_fraction=0.2: Full dispersion energy for r < 12.0 \u00c5 (smoothing_on) Smoothly interpolated for 12.0 \u00c5 < r < 15.0 \u00c5 Zero contribution for r > 15.0 \u00c5 Tuning DFTD3 Parameters \u00b6 Adjusting cutoff: # Default: 15.0 \u00c5 calc.set_dftd3_cutoff(cutoff=15.0, smoothing_fraction=0.2) # For dense systems: shorter cutoff calc.set_dftd3_cutoff(cutoff=12.0, smoothing_fraction=0.2) # For surface/interface: longer cutoff calc.set_dftd3_cutoff(cutoff=20.0, smoothing_fraction=0.15) Smoothing fraction guidelines: Smaller (0.1): Sharper transition, may need tighter convergence Default (0.2): Good balance for most systems Larger (0.3): Smoother transition, more conservative Validation: Test energy convergence by varying cutoff. Dispersion energy should change by < 0.05 kcal/mol when cutoff increases by 2 \u00c5. Forces \u00b6 If compute_forces=True and coordinates require grad, forces are automatically computed as -grad(energy) and added to data[\"forces\"] . D3 Parameters \u00b6 DFTD3 requires functional-specific parameters stored in model metadata: d3_params = { \"s6\": 1.0, # C6 scaling \"s8\": 0.3908, # C8 scaling (functional-dependent) \"a1\": 0.5660, # BJ damping parameter \"a2\": 3.1280, # BJ damping parameter } These are set during model training/export and should not be modified for inference. Complete Examples \u00b6 DSF for Periodic System \u00b6 from aimnet.calculators import AIMNet2Calculator import torch # Create calculator calc = AIMNet2Calculator(\"aimnet2\") # Configure DSF method calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) # Periodic system cell = torch.tensor([ [10.0, 0.0, 0.0], [0.0, 10.0, 0.0], [0.0, 0.0, 10.0], ]) result = calc({ \"coord\": coords, # (N, 3) \"numbers\": numbers, # (N,) \"charge\": 0.0, \"cell\": cell, }, forces=True, stress=True) print(f\"Energy: {result['energy'].item():.4f} eV\") print(f\"Stress: {result['stress']}\") # (3, 3) Ewald for High Accuracy \u00b6 # Configure Ewald method with default accuracy (1e-8) calc.set_lrcoulomb_method(\"ewald\") # Same periodic system as above result_ewald = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True) # Compare with DSF calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True) energy_diff = abs(result_ewald[\"energy\"] - result_dsf[\"energy\"]) print(f\"DSF vs Ewald energy difference: {energy_diff.item():.4f} eV\") # Typically < 0.01 eV for well-converged cutoffs Changing Methods at Runtime \u00b6 calc = AIMNet2Calculator(\"aimnet2\") # Start with simple calc.set_lrcoulomb_method(\"simple\") result_simple = calc(data) # Switch to DSF calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc(data) # Switch to Ewald calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) result_ewald = calc(data) # Compare energies print(f\"Simple: {result_simple['energy'].item():.4f} eV\") print(f\"DSF: {result_dsf['energy'].item():.4f} eV\") print(f\"Ewald: {result_ewald['energy'].item():.4f} eV\") Separate Coulomb and DFTD3 Cutoffs \u00b6 # Set different cutoffs for Coulomb and DFTD3 calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0) # Coulomb cutoff calc.set_dftd3_cutoff(cutoff=15.0, smoothing_fraction=0.2) # DFTD3 cutoff # Calculator will use separate neighbor lists result = calc(data, forces=True) # Check cutoffs print(f\"Coulomb cutoff: {calc.coulomb_cutoff} \u00c5\") print(f\"DFTD3 cutoff: {calc.dftd3_cutoff} \u00c5\") Calculator Integration (External Modules) \u00b6 AIMNet2Calculator attaches external LR modules based on model metadata: External LRCoulomb is created when needs_coulomb=True . If coulomb_mode=\"sr_embedded\" , the model already subtracts SR Coulomb, so the external module adds the full Coulomb energy. External DFTD3 is created when needs_dispersion=True and d3_params are present. See calculator.md for attachment logic and runtime configuration methods.","title":"Long Range"},{"location":"long_range/#long-range-modules","text":"This page documents the long-range (LR) modules implemented in aimnet/modules/lr.py . All modules operate on the shared data dictionary and add their contributions to data[key_out] (usually energy ).","title":"Long-Range Modules"},{"location":"long_range/#choosing-a-coulomb-method","text":"Select the appropriate method based on your system and accuracy requirements.","title":"Choosing a Coulomb Method"},{"location":"long_range/#simple-all-pairs-pairwise-coulomb","text":"Only for non-periodic systems. The calculator automatically switches to DSF if PBC is detected. When to use: Small non-periodic systems (< 100 atoms) Quick calculations where exact Coulomb is acceptable Non-production exploratory work When NOT to use: Periodic systems (NOT SUPPORTED - auto-switches to DSF) Large systems (O(N\u00b2) fully connected becomes prohibitive) Production MD (inefficient for repeated evaluation) Configuration: calc.set_lrcoulomb_method(\"simple\") # No cutoff - all pairs evaluated # WARNING: Will auto-switch to DSF if PBC (cell) is provided Characteristics: Exact pairwise 1/r Coulomb sum for non-periodic systems All atom pairs evaluated (fully connected) O(N\u00b2) complexity Not applicable to periodic boundary conditions","title":"Simple (All-Pairs Pairwise Coulomb)"},{"location":"long_range/#dsf-damped-shifted-force","text":"When to use: Periodic boundary conditions (recommended) Large non-periodic systems (> 200 atoms) Production molecular dynamics When computational efficiency matters When NOT to use: When highest accuracy is required (use Ewald instead) Very small systems where Simple is faster Configuration: calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) Parameters: Parameter Typical Range Default Notes cutoff 12-20 \u00c5 15.0 \u00c5 Larger = more accurate, more expensive dsf_alpha 0.1-0.3 0.2 Damping strength; 0.2 works well for most systems Tuning guidelines: Start with cutoff=15.0 \u00c5, alpha=0.2 (default) Dense systems: reduce cutoff to 12 \u00c5 Dilute/surface systems: increase cutoff to 18-20 \u00c5 Validate: energies should converge within ~0.1 kcal/mol as cutoff increases Characteristics: Smooth truncation at cutoff with shifted force Maintains charge neutrality O(N) scaling with neighbor lists Energy and forces continuous at cutoff Based on Wolf summation method","title":"DSF (Damped Shifted Force)"},{"location":"long_range/#ewald-summation","text":"When to use: Research-grade accuracy required Benchmarking and validation studies Systems where electrostatics dominate behavior When computational cost is acceptable When NOT to use: Long MD trajectories (slower than DSF) When DSF accuracy is sufficient Very large systems (reciprocal space cost increases) Configuration: # Default accuracy (1e-8) calc.set_lrcoulomb_method(\"ewald\") # Custom accuracy (higher precision, more computation) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-10) # Lower accuracy (faster, but less precise) calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-6) Accuracy Parameter: The ewald_accuracy parameter controls the real-space and reciprocal-space cutoffs. Lower values give higher precision but require more computation. The cutoffs are computed automatically based on system geometry: [ \\eta = \\frac{(V^2 / N)^{1/6}}{\\sqrt{2\\pi}} ] [ r {\\text{cutoff}} = \\sqrt{-2 \\ln \\varepsilon} \\cdot \\eta, \\quad k {\\text{cutoff}} = \\frac{\\sqrt{-2 \\ln \\varepsilon}}{\\eta} ] Where (\\varepsilon) is the accuracy parameter, (V) is the cell volume, and (N) is the number of atoms. Characteristics: Splits Coulomb into real-space + reciprocal-space + self-energy terms Configurable accuracy target (default 1e-8) Automatically determines k-space vectors based on accuracy O(N log N) to O(N^1.5) complexity depending on implementation Most accurate method for periodic systems When Ewald matters: Computing precise thermodynamic properties Benchmark comparisons against QM calculations Validation of other Coulomb methods Systems with significant long-range charge ordering","title":"Ewald Summation"},{"location":"long_range/#method-comparison","text":"Method Complexity PBC Support Typical Use Case Notes Simple O(N\u00b2) fully connected No Small molecules, quick tests Auto-switches for PBC DSF O(N) with neighbor lists Yes Production MD, large systems Recommended for PBC Ewald O(N log N) to O(N^1.5) Yes High-accuracy benchmarks Research-grade precision Accuracy hierarchy: Ewald > DSF > Simple (for PBC) Speed hierarchy: Simple (small N) > DSF > Ewald Recommendation: Use DSF for periodic systems unless you need Ewald's precision.","title":"Method Comparison"},{"location":"long_range/#common-data-and-neighbor-list-handling","text":"Neighbor-list keys and suffix fallback Coulomb modules prefer nbmat_coulomb and fall back to nbmat_lr . Dispersion modules ( DFTD3 , D3TS ) prefer nbmat_dftd3 and fall back to nbmat_lr . This fallback behavior is implemented via nbops.resolve_suffix , and distance calculation is lazily computed with ops.lazy_calc_dij . Distance and masking Distances use d_ij{suffix} derived from coord (and shifts{suffix} when PBC is present). Padding/diagonal pairs are masked via mask_ij{suffix} . For DSF, pairs beyond Rc are also masked.","title":"Common Data and Neighbor-List Handling"},{"location":"long_range/#lrcoulomb","text":"LRCoulomb computes a long-range Coulomb contribution, optionally subtracting the short-range (SR) part to avoid double counting. Inputs charges (default key_in ) coord , cell (for Ewald) Neighbor lists as described above Methods Simple (full pairwise Coulomb) Pair energy: e_ij = q_i q_j / r_ij Total energy: E = factor * sum_i sum_j e_ij (accumulated in float64) If subtract_sr=True , subtracts the SR energy described below. DSF (damped shifted force) Uses ops.coulomb_matrix_dsf : J(r) = erfc(alpha r)/r - erfc(alpha Rc)/Rc + (r - Rc) * (erfc(alpha Rc)/Rc^2 + 2 alpha exp(-(alpha Rc)^2) / (Rc sqrt(pi))) Pairs with r > Rc or masked entries are zeroed. Energy is: E = factor * sum_i sum_j q_i q_j J(r_ij) If subtract_sr=True , the SR term is subtracted. Ewald Uses ops.coulomb_matrix_ewald , which implements real-space + reciprocal-space + self terms with fixed accuracy ( 1e-8 ). This path requires a single molecule with coord.ndim == 2 and cell.ndim == 2 . If subtract_sr=True , the SR term is subtracted. SR subtraction (shared by all methods) The SR term uses an envelope cutoff: exp : fc(d) = exp(-1 / (1 - (d/rc)^2)) / 0.36787944117144233 cosine : fc(d) = 0.5 * (cos(pi * d / rc) + 1) SR pair energy: e_ij = fc(r_ij) * q_i q_j / r_ij The SR contribution is summed per molecule and subtracted from key_out when subtract_sr=True .","title":"LRCoulomb"},{"location":"long_range/#srcoulomb","text":"SRCoulomb subtracts the SR Coulomb contribution from key_out . It uses the same SR formula as LRCoulomb (envelope + cutoff) and is typically embedded in models trained with SR Coulomb so that external LR methods can add the full Coulomb energy without double counting.","title":"SRCoulomb"},{"location":"long_range/#dispparam","text":"DispParam produces per-atom dispersion parameters ( c6 , alpha ) from a reference table. Reference is loaded from a .pt file or provided as ref_c6 / ref_alpha . Per-atom scaling uses disp_param_mult = exp(clamp(disp_param, -4, 4)) . Output disp_param has shape (N, 2) with columns (c6, alpha) .","title":"DispParam"},{"location":"long_range/#d3ts","text":"D3TS implements a DFT-D3-like pairwise dispersion with the TS combination rule. Inputs disp_param (from DispParam ) coord , numbers Neighbor lists with _dftd3 or _lr suffix Key equations TS combination rule: c6_ij = 2 c6_i c6_j / (c6_i * alpha_j / alpha_i + c6_j * alpha_i / alpha_j) Let rr = r4r2[numbers] and rr_ij = 3 * rr_i * rr_j . The BJ-like radius term is: r0_ij = a1 * sqrt(rr_ij) + a2 Distances are converted to Bohr: r = d_ij * Bohr_inv . Energy per pair: e_ij = c6_ij * (s6 / (r^6 + r0_ij^6) + s8 * rr_ij / (r^8 + r0_ij^8)) Total energy is summed per molecule and multiplied by -half_Hartree .","title":"D3TS"},{"location":"long_range/#dftd3","text":"DFTD3 computes DFT-D3 dispersion correction using the BJ damping function with C6/C8 terms. Uses the dftd3_energy custom autograd op from aimnet.modules.ops . No 3-body term (Axilrod-Teller-Muto) is included.","title":"DFTD3"},{"location":"long_range/#smoothing-window","text":"Dispersion interactions are smoothly damped to zero near the cutoff to ensure continuous energy and forces. The smoothing window is defined by: smoothing_on = cutoff * (1 - smoothing_fraction) smoothing_off = cutoff Parameters: Parameter Typical Value Default Effect cutoff 15-20 \u00c5 15.0 \u00c5 Interaction cutoff distance smoothing_fraction 0.1-0.3 0.2 Width of smoothing region as fraction of cutoff Example: With cutoff=15.0 \u00c5 and smoothing_fraction=0.2: Full dispersion energy for r < 12.0 \u00c5 (smoothing_on) Smoothly interpolated for 12.0 \u00c5 < r < 15.0 \u00c5 Zero contribution for r > 15.0 \u00c5","title":"Smoothing Window"},{"location":"long_range/#tuning-dftd3-parameters","text":"Adjusting cutoff: # Default: 15.0 \u00c5 calc.set_dftd3_cutoff(cutoff=15.0, smoothing_fraction=0.2) # For dense systems: shorter cutoff calc.set_dftd3_cutoff(cutoff=12.0, smoothing_fraction=0.2) # For surface/interface: longer cutoff calc.set_dftd3_cutoff(cutoff=20.0, smoothing_fraction=0.15) Smoothing fraction guidelines: Smaller (0.1): Sharper transition, may need tighter convergence Default (0.2): Good balance for most systems Larger (0.3): Smoother transition, more conservative Validation: Test energy convergence by varying cutoff. Dispersion energy should change by < 0.05 kcal/mol when cutoff increases by 2 \u00c5.","title":"Tuning DFTD3 Parameters"},{"location":"long_range/#forces","text":"If compute_forces=True and coordinates require grad, forces are automatically computed as -grad(energy) and added to data[\"forces\"] .","title":"Forces"},{"location":"long_range/#d3-parameters","text":"DFTD3 requires functional-specific parameters stored in model metadata: d3_params = { \"s6\": 1.0, # C6 scaling \"s8\": 0.3908, # C8 scaling (functional-dependent) \"a1\": 0.5660, # BJ damping parameter \"a2\": 3.1280, # BJ damping parameter } These are set during model training/export and should not be modified for inference.","title":"D3 Parameters"},{"location":"long_range/#complete-examples","text":"","title":"Complete Examples"},{"location":"long_range/#dsf-for-periodic-system","text":"from aimnet.calculators import AIMNet2Calculator import torch # Create calculator calc = AIMNet2Calculator(\"aimnet2\") # Configure DSF method calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0, dsf_alpha=0.2) # Periodic system cell = torch.tensor([ [10.0, 0.0, 0.0], [0.0, 10.0, 0.0], [0.0, 0.0, 10.0], ]) result = calc({ \"coord\": coords, # (N, 3) \"numbers\": numbers, # (N,) \"charge\": 0.0, \"cell\": cell, }, forces=True, stress=True) print(f\"Energy: {result['energy'].item():.4f} eV\") print(f\"Stress: {result['stress']}\") # (3, 3)","title":"DSF for Periodic System"},{"location":"long_range/#ewald-for-high-accuracy","text":"# Configure Ewald method with default accuracy (1e-8) calc.set_lrcoulomb_method(\"ewald\") # Same periodic system as above result_ewald = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True) # Compare with DSF calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc({ \"coord\": coords, \"numbers\": numbers, \"charge\": 0.0, \"cell\": cell, }, forces=True) energy_diff = abs(result_ewald[\"energy\"] - result_dsf[\"energy\"]) print(f\"DSF vs Ewald energy difference: {energy_diff.item():.4f} eV\") # Typically < 0.01 eV for well-converged cutoffs","title":"Ewald for High Accuracy"},{"location":"long_range/#changing-methods-at-runtime","text":"calc = AIMNet2Calculator(\"aimnet2\") # Start with simple calc.set_lrcoulomb_method(\"simple\") result_simple = calc(data) # Switch to DSF calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc(data) # Switch to Ewald calc.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) result_ewald = calc(data) # Compare energies print(f\"Simple: {result_simple['energy'].item():.4f} eV\") print(f\"DSF: {result_dsf['energy'].item():.4f} eV\") print(f\"Ewald: {result_ewald['energy'].item():.4f} eV\")","title":"Changing Methods at Runtime"},{"location":"long_range/#separate-coulomb-and-dftd3-cutoffs","text":"# Set different cutoffs for Coulomb and DFTD3 calc.set_lrcoulomb_method(\"dsf\", cutoff=12.0) # Coulomb cutoff calc.set_dftd3_cutoff(cutoff=15.0, smoothing_fraction=0.2) # DFTD3 cutoff # Calculator will use separate neighbor lists result = calc(data, forces=True) # Check cutoffs print(f\"Coulomb cutoff: {calc.coulomb_cutoff} \u00c5\") print(f\"DFTD3 cutoff: {calc.dftd3_cutoff} \u00c5\")","title":"Separate Coulomb and DFTD3 Cutoffs"},{"location":"long_range/#calculator-integration-external-modules","text":"AIMNet2Calculator attaches external LR modules based on model metadata: External LRCoulomb is created when needs_coulomb=True . If coulomb_mode=\"sr_embedded\" , the model already subtracts SR Coulomb, so the external module adds the full Coulomb energy. External DFTD3 is created when needs_dispersion=True and d3_params are present. See calculator.md for attachment logic and runtime configuration methods.","title":"Calculator Integration (External Modules)"},{"location":"model_format/","text":"Model Format and Conversion \u00b6 This document describes the AIMNet2 model format, metadata structure, and conversion between legacy and new formats. It reflects the current implementation in aimnet.models.base , aimnet.models.utils , and aimnet.calculators.calculator . Model Formats \u00b6 AIMNet2 supports two model formats: Format Extension Version Description Legacy .jpt 1 TorchScript JIT-compiled model with embedded LR modules New .pt 2 State dict with embedded YAML config and metadata Format Detection \u00b6 When loading a model via load_model() , the format is automatically detected: New format : Dictionary containing \"model_yaml\" key Legacy format : torch.jit.ScriptModule instance Metadata Structure \u00b6 Model metadata is returned by load_model() as a ModelMetadata TypedDict. For early v2 bundles that predate format_version , load_model() defaults to format_version=2 . Core Fields \u00b6 Field Type Description format_version int 1 = legacy JIT, 2 = new format (default for early v2 bundles) cutoff float Model short-range cutoff radius (\u00c5) implemented_species list[int] Supported atomic numbers Coulomb Configuration \u00b6 | Field | Type | Description | | --------------------- | ------ | ---------------------------------------------------------------- | -------------------------------------------------------- | | needs_coulomb | bool | If True , calculator should add external Coulomb | | coulomb_mode | str | What's embedded: \"sr_embedded\" , \"full_embedded\" , or \"none\" | | coulomb_sr_rc | float | None | SR Coulomb cutoff (only if coulomb_mode=\"sr_embedded\" ) | | coulomb_sr_envelope | str | None | Envelope function: \"exp\" (mollifier) or \"cosine\" | Dispersion Configuration \u00b6 | Field | Type | Description | | ------------------ | ------ | ----------------------------------------------- | --------------------------------- | | needs_dispersion | bool | If True , calculator should add external DFTD3 | | d3_params | dict | None | D3 parameters: {s6, s8, a1, a2} | Which Format Should I Use? \u00b6 Decision Matrix \u00b6 Scenario Format Model Type Notes Training new model v2 (.pt) Export after training Flexible, modern Need runtime Coulomb control v2 (.pt) Convert from v1 if needed Switch simple/DSF/Ewald Production inference v2 (.pt) Preferred Smaller, more flexible Legacy deployment v1 (.jpt) Keep as-is If compatibility required Experimenting with methods v2 (.pt) Required Runtime reconfiguration Fixed pipeline Either Use what works No strong preference Quick Selection Guide \u00b6 Use v2 (.pt) if: Training new models Need to try different Coulomb methods Want runtime flexibility Prefer modern PyTorch features Keep v1 (.jpt) if: Existing deployment works Don't need to change methods Legacy compatibility required No issues with current setup Coulomb Modes \u00b6 The coulomb_mode field describes what Coulomb treatment is embedded in the model. Coulomb Mode Comparison \u00b6 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 sr_embedded (v2 format - RECOMMENDED) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN - E_SR (SR Coulomb subtracted) \u2502 \u2502 Calculator: + E_full (adds full Coulomb externally) \u2502 \u2502 Total: E_NN + E_LR (SR cancels out) \u2502 \u2502 \u2502 \u2502 Runtime control: \u2713 Can switch simple/DSF/Ewald \u2502 \u2502 File size: Smaller (no LR modules embedded) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 full_embedded (v1 legacy format) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN + E_Coulomb (full Coulomb embedded in JIT) \u2502 \u2502 Calculator: (nothing) \u2502 \u2502 Total: E_NN + E_Coulomb \u2502 \u2502 \u2502 \u2502 Runtime control: \u2717 Fixed method, warning only \u2502 \u2502 File size: Larger (modules in JIT) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 none (no Coulomb) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN only \u2502 \u2502 Calculator: (nothing) \u2502 \u2502 Total: E_NN \u2502 \u2502 \u2502 \u2502 Runtime control: N/A \u2502 \u2502 Use case: Models without electrostatics \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \"sr_embedded\" \u00b6 Model has SRCoulomb (short-range) embedded Model outputs: E_NN - E_SR Calculator adds full Coulomb externally: E_total = (E_NN - E_SR) + E_full = E_NN + E_LR Uses coulomb_sr_rc and coulomb_sr_envelope from metadata User can switch Coulomb method (simple/DSF/Ewald) at runtime via set_lrcoulomb_method() SR Coulomb Cutoff ( coulomb_sr_rc ) \u00b6 The short-range Coulomb cutoff defines the distance within which SR Coulomb interactions are computed by the embedded SRCoulomb module. Constraint: coulomb_sr_rc <= model cutoff The SR cutoff must be less than or equal to the model's short-range cutoff ( cutoff ) because: SRCoulomb uses the same neighbor list as the neural network Atom pairs beyond the model cutoff are not visible to SRCoulomb Typical value: 4.6 \u00c5 (with model cutoff of 5.0 \u00c5) SR Envelope ( coulomb_sr_envelope ) \u00b6 The envelope function defines how the SR interaction decays at the cutoff: \"exp\" : Smooth mollifier-based decay (default) \"cosine\" : Cosine-based decay \"full_embedded\" \u00b6 Legacy JIT model with full Coulomb embedded Model outputs: E_NN + E_Coulomb directly No external Coulomb needed ( needs_coulomb=False ) Coulomb method cannot be changed at runtime \"none\" \u00b6 No Coulomb treatment in model needs_coulomb=False Model outputs: E_NN only Dispersion Modes \u00b6 External DFTD3 ( needs_dispersion=True ) \u00b6 DFTD3/D3BJ module removed from model during export D3 parameters ( s6 , s8 , a1 , a2 ) stored in d3_params metadata Calculator creates external DFTD3 module Cutoff can be configured via set_dftd3_cutoff() for external DFTD3 only Note: DFTD3 cutoff/smoothing values are not currently stored in metadata. External DFTD3 defaults to 15.0 \u00c5 cutoff and 0.8 smoothing fraction unless overridden at runtime. Embedded D3TS \u00b6 D3TS (learned parameters) remains embedded in model needs_dispersion=False for D3TS models Cannot be modified at runtime No Dispersion \u00b6 needs_dispersion=False and no D3TS Model outputs energy without dispersion correction File Structure \u00b6 New Format (.pt) \u00b6 { \"format_version\": 2, # Default for early v2 bundles may be omitted \"model_yaml\": str, # Core model YAML config (no LR modules) \"cutoff\": float, \"needs_coulomb\": bool, \"needs_dispersion\": bool, \"coulomb_mode\": str, \"coulomb_sr_rc\": float | None, \"coulomb_sr_envelope\": str | None, \"d3_params\": dict | None, # DFTD3 params for external use \"implemented_species\": list[int], \"state_dict\": dict, # Model weights (SAE baked in) } Legacy Format (.jpt) \u00b6 TorchScript module with attributes: cutoff : Model cutoff cutoff_lr : Long-range cutoff (if applicable) LRCoulomb and DFTD3/D3BJ modules embedded Exporting Models \u00b6 Use the aimnet export CLI command: aimnet export weights.pt model_v2.pt --model config.yaml --sae sae.yaml Export Process \u00b6 Load model YAML config, SAE (self-atomic energies), and weights Strip LRCoulomb/DFTD3 modules from config Add SRCoulomb if LRCoulomb was present (requires determinable rc ) Build core model from modified config Load weights (with strict=False for module changes) Bake SAE into atomic_shift.shifts.weight as float64 Mask unimplemented species (set NaN in afv.weight ) Save with metadata Export Options \u00b6 aimnet export weights.pt model.pt \\ --model config.yaml \\ --sae sae.yaml \\ --needs-coulomb # Override: force external Coulomb --needs-dispersion # Override: force external DFTD3 Explicit flags override auto-detection from config. Converting Legacy Models \u00b6 Use the aimnet convert CLI command: aimnet convert model.jpt config.yaml model_v2.pt Conversion Process \u00b6 Load legacy JIT model and YAML config Extract cutoff from model attribute Extract implemented_species from afv.weight (non-NaN entries) Strip LR modules from config, add SRCoulomb if needed (requires determinable rc ) Build core model from modified config Load weights from JIT state dict Validate keys (filter expected missing/unexpected) Convert atomic_shift to float64 Save with metadata Key Changes During Conversion \u00b6 Legacy New outputs.lrcoulomb.* Removed outputs.dftd3.* Removed outputs.d3bj.* Removed (none) outputs.srcoulomb.* added Loading Models \u00b6 from aimnet.models.base import load_model model, metadata = load_model(\"model.pt\", device=\"cuda\") # Access metadata print(metadata[\"cutoff\"]) print(metadata[\"needs_coulomb\"]) print(metadata[\"coulomb_mode\"]) Loading Behavior \u00b6 New format: Parses YAML, builds model, loads state dict Legacy format: Returns JIT model directly Metadata always returned as ModelMetadata dict atomic_shift converted to float64 after loading (precision) Metadata Behavior Summary \u00b6 Model Type needs_coulomb coulomb_mode Calculator Behavior New with Coulomb True \"sr_embedded\" Adds external LRCoulomb New without Coulomb False \"none\" No external Coulomb Legacy JIT False \"full_embedded\" Coulomb embedded in JIT Model Type needs_dispersion Calculator Behavior New with DFTD3/D3BJ True Adds external DFTD3 New with D3TS False D3TS embedded New without dispersion False No dispersion Legacy with DFTD3 False Embedded in JIT (d3_params extracted for diagnostics) API Reference \u00b6 load_model(path, device=\"cpu\") \u00b6 Load model from file with automatic format detection. Parameters: path ( str ): Path to model file ( .pt or .jpt ) device ( str ): Device to load model on Returns: model ( nn.Module ): Loaded model metadata ( ModelMetadata ): Metadata dictionary ModelMetadata (TypedDict) \u00b6 See Metadata Structure for field definitions. Migration Guide \u00b6 Why Migrate to v2 Format? \u00b6 Benefits of v2 (.pt) over v1 (.jpt): Runtime flexibility : Change Coulomb method (simple/DSF/Ewald) without retraining Smaller files : Separate external modules reduce file size Better debugging : Access model structure and weights directly Modern workflow : Compatible with latest PyTorch features Metadata : Rich metadata for validation and documentation When to convert: You have legacy .jpt models and want runtime Coulomb control You're training new models (use v2 from the start) You need to modify model architecture post-training When to keep v1: Legacy compatibility required Model works fine and no new features needed Deployment pipeline expects JIT models Step-by-Step Migration \u00b6 1. Prepare Required Files \u00b6 You'll need: model.jpt - Your legacy JIT model config.yaml - Original model configuration # If you don't have config.yaml, you may need to reconstruct it # from training logs or model inspection 2. Run Conversion \u00b6 aimnet convert model.jpt config.yaml model_v2.pt What happens during conversion: Extracts model weights from JIT state dict Strips embedded LRCoulomb/DFTD3 modules Adds SRCoulomb if LRCoulomb was present Preserves atomic shifts (SAE) as float64 Detects implemented species from weights Generates metadata dictionary 3. Validate Conversion \u00b6 from aimnet.calculators import AIMNet2Calculator import torch # Load both models calc_v1 = AIMNet2Calculator(\"model.jpt\") calc_v2 = AIMNet2Calculator(\"model_v2.pt\") # Test data data = { \"coord\": torch.randn(10, 3), \"numbers\": torch.randint(1, 9, (10,)), \"charge\": 0.0, } # Compare energies (should match within tolerance) result_v1 = calc_v1(data, forces=True) result_v2 = calc_v2(data, forces=True) energy_diff = (result_v1[\"energy\"] - result_v2[\"energy\"]).abs() force_diff = (result_v1[\"forces\"] - result_v2[\"forces\"]).abs().max() print(f\"Energy difference: {energy_diff:.2e} eV\") print(f\"Max force difference: {force_diff:.2e} eV/\u00c5\") assert energy_diff < 1e-5, \"Energy mismatch!\" assert force_diff < 1e-4, \"Force mismatch!\" Expected differences: Energies: < 1e-5 eV (numerical precision) Forces: < 1e-4 eV/\u00c5 (gradient precision) 4. Test Runtime Flexibility \u00b6 # v2 models support runtime method changes calc_v2.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc_v2(data) calc_v2.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) result_ewald = calc_v2(data) # v1 models show warning but don't change calc_v1.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # Warning: Cannot change method for legacy models Common Conversion Issues \u00b6 Issue: Missing config.yaml \u00b6 Problem: You have a .jpt model but no configuration file. Solution: Inspect the model to reconstruct config: import torch model = torch.jit.load(\"model.jpt\") # Inspect attributes print(f\"Cutoff: {model.cutoff}\") print(f\"Cutoff LR: {model.cutoff_lr}\") # May need to manually create config based on model structure Issue: Weight Mismatch \u00b6 Problem: Conversion completes but validation shows large differences. Solution: Check for module name mismatches: # Use verbose mode to see what's happening aimnet convert model.jpt config.yaml model_v2.pt --verbose # Check for unexpected missing keys # Some modules may have been renamed Issue: Implemented Species Mismatch \u00b6 Problem: Converted model has wrong implemented_species . Solution: Species are auto-detected from non-NaN entries in afv.weight . Verify: from aimnet.models.base import load_model model, metadata = load_model(\"model_v2.pt\") print(metadata[\"implemented_species\"]) # If wrong, may need to fix config before conversion Exporting New Models \u00b6 For newly trained models, export directly to v2: aimnet export weights.pt model_v2.pt \\ --model config.yaml \\ --sae sae.yaml Optional flags: # Override auto-detection --needs-coulomb # Force external Coulomb --needs-dispersion # Force external DFTD3 CLI Commands \u00b6 # Export trained model aimnet export weights.pt output.pt --model config.yaml --sae sae.yaml # Convert legacy JIT model aimnet convert model.jpt config.yaml output.pt # Calculate SAE from dataset aimnet calc_sae dataset.h5 sae.yaml","title":"Model Format"},{"location":"model_format/#model-format-and-conversion","text":"This document describes the AIMNet2 model format, metadata structure, and conversion between legacy and new formats. It reflects the current implementation in aimnet.models.base , aimnet.models.utils , and aimnet.calculators.calculator .","title":"Model Format and Conversion"},{"location":"model_format/#model-formats","text":"AIMNet2 supports two model formats: Format Extension Version Description Legacy .jpt 1 TorchScript JIT-compiled model with embedded LR modules New .pt 2 State dict with embedded YAML config and metadata","title":"Model Formats"},{"location":"model_format/#format-detection","text":"When loading a model via load_model() , the format is automatically detected: New format : Dictionary containing \"model_yaml\" key Legacy format : torch.jit.ScriptModule instance","title":"Format Detection"},{"location":"model_format/#metadata-structure","text":"Model metadata is returned by load_model() as a ModelMetadata TypedDict. For early v2 bundles that predate format_version , load_model() defaults to format_version=2 .","title":"Metadata Structure"},{"location":"model_format/#core-fields","text":"Field Type Description format_version int 1 = legacy JIT, 2 = new format (default for early v2 bundles) cutoff float Model short-range cutoff radius (\u00c5) implemented_species list[int] Supported atomic numbers","title":"Core Fields"},{"location":"model_format/#coulomb-configuration","text":"| Field | Type | Description | | --------------------- | ------ | ---------------------------------------------------------------- | -------------------------------------------------------- | | needs_coulomb | bool | If True , calculator should add external Coulomb | | coulomb_mode | str | What's embedded: \"sr_embedded\" , \"full_embedded\" , or \"none\" | | coulomb_sr_rc | float | None | SR Coulomb cutoff (only if coulomb_mode=\"sr_embedded\" ) | | coulomb_sr_envelope | str | None | Envelope function: \"exp\" (mollifier) or \"cosine\" |","title":"Coulomb Configuration"},{"location":"model_format/#dispersion-configuration","text":"| Field | Type | Description | | ------------------ | ------ | ----------------------------------------------- | --------------------------------- | | needs_dispersion | bool | If True , calculator should add external DFTD3 | | d3_params | dict | None | D3 parameters: {s6, s8, a1, a2} |","title":"Dispersion Configuration"},{"location":"model_format/#which-format-should-i-use","text":"","title":"Which Format Should I Use?"},{"location":"model_format/#decision-matrix","text":"Scenario Format Model Type Notes Training new model v2 (.pt) Export after training Flexible, modern Need runtime Coulomb control v2 (.pt) Convert from v1 if needed Switch simple/DSF/Ewald Production inference v2 (.pt) Preferred Smaller, more flexible Legacy deployment v1 (.jpt) Keep as-is If compatibility required Experimenting with methods v2 (.pt) Required Runtime reconfiguration Fixed pipeline Either Use what works No strong preference","title":"Decision Matrix"},{"location":"model_format/#quick-selection-guide","text":"Use v2 (.pt) if: Training new models Need to try different Coulomb methods Want runtime flexibility Prefer modern PyTorch features Keep v1 (.jpt) if: Existing deployment works Don't need to change methods Legacy compatibility required No issues with current setup","title":"Quick Selection Guide"},{"location":"model_format/#coulomb-modes","text":"The coulomb_mode field describes what Coulomb treatment is embedded in the model.","title":"Coulomb Modes"},{"location":"model_format/#coulomb-mode-comparison","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 sr_embedded (v2 format - RECOMMENDED) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN - E_SR (SR Coulomb subtracted) \u2502 \u2502 Calculator: + E_full (adds full Coulomb externally) \u2502 \u2502 Total: E_NN + E_LR (SR cancels out) \u2502 \u2502 \u2502 \u2502 Runtime control: \u2713 Can switch simple/DSF/Ewald \u2502 \u2502 File size: Smaller (no LR modules embedded) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 full_embedded (v1 legacy format) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN + E_Coulomb (full Coulomb embedded in JIT) \u2502 \u2502 Calculator: (nothing) \u2502 \u2502 Total: E_NN + E_Coulomb \u2502 \u2502 \u2502 \u2502 Runtime control: \u2717 Fixed method, warning only \u2502 \u2502 File size: Larger (modules in JIT) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 none (no Coulomb) \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Model: E_NN only \u2502 \u2502 Calculator: (nothing) \u2502 \u2502 Total: E_NN \u2502 \u2502 \u2502 \u2502 Runtime control: N/A \u2502 \u2502 Use case: Models without electrostatics \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Coulomb Mode Comparison"},{"location":"model_format/#sr_embedded","text":"Model has SRCoulomb (short-range) embedded Model outputs: E_NN - E_SR Calculator adds full Coulomb externally: E_total = (E_NN - E_SR) + E_full = E_NN + E_LR Uses coulomb_sr_rc and coulomb_sr_envelope from metadata User can switch Coulomb method (simple/DSF/Ewald) at runtime via set_lrcoulomb_method()","title":"\"sr_embedded\""},{"location":"model_format/#sr-coulomb-cutoff-coulomb_sr_rc","text":"The short-range Coulomb cutoff defines the distance within which SR Coulomb interactions are computed by the embedded SRCoulomb module. Constraint: coulomb_sr_rc <= model cutoff The SR cutoff must be less than or equal to the model's short-range cutoff ( cutoff ) because: SRCoulomb uses the same neighbor list as the neural network Atom pairs beyond the model cutoff are not visible to SRCoulomb Typical value: 4.6 \u00c5 (with model cutoff of 5.0 \u00c5)","title":"SR Coulomb Cutoff (coulomb_sr_rc)"},{"location":"model_format/#sr-envelope-coulomb_sr_envelope","text":"The envelope function defines how the SR interaction decays at the cutoff: \"exp\" : Smooth mollifier-based decay (default) \"cosine\" : Cosine-based decay","title":"SR Envelope (coulomb_sr_envelope)"},{"location":"model_format/#full_embedded","text":"Legacy JIT model with full Coulomb embedded Model outputs: E_NN + E_Coulomb directly No external Coulomb needed ( needs_coulomb=False ) Coulomb method cannot be changed at runtime","title":"\"full_embedded\""},{"location":"model_format/#none","text":"No Coulomb treatment in model needs_coulomb=False Model outputs: E_NN only","title":"\"none\""},{"location":"model_format/#dispersion-modes","text":"","title":"Dispersion Modes"},{"location":"model_format/#external-dftd3-needs_dispersiontrue","text":"DFTD3/D3BJ module removed from model during export D3 parameters ( s6 , s8 , a1 , a2 ) stored in d3_params metadata Calculator creates external DFTD3 module Cutoff can be configured via set_dftd3_cutoff() for external DFTD3 only Note: DFTD3 cutoff/smoothing values are not currently stored in metadata. External DFTD3 defaults to 15.0 \u00c5 cutoff and 0.8 smoothing fraction unless overridden at runtime.","title":"External DFTD3 (needs_dispersion=True)"},{"location":"model_format/#embedded-d3ts","text":"D3TS (learned parameters) remains embedded in model needs_dispersion=False for D3TS models Cannot be modified at runtime","title":"Embedded D3TS"},{"location":"model_format/#no-dispersion","text":"needs_dispersion=False and no D3TS Model outputs energy without dispersion correction","title":"No Dispersion"},{"location":"model_format/#file-structure","text":"","title":"File Structure"},{"location":"model_format/#new-format-pt","text":"{ \"format_version\": 2, # Default for early v2 bundles may be omitted \"model_yaml\": str, # Core model YAML config (no LR modules) \"cutoff\": float, \"needs_coulomb\": bool, \"needs_dispersion\": bool, \"coulomb_mode\": str, \"coulomb_sr_rc\": float | None, \"coulomb_sr_envelope\": str | None, \"d3_params\": dict | None, # DFTD3 params for external use \"implemented_species\": list[int], \"state_dict\": dict, # Model weights (SAE baked in) }","title":"New Format (.pt)"},{"location":"model_format/#legacy-format-jpt","text":"TorchScript module with attributes: cutoff : Model cutoff cutoff_lr : Long-range cutoff (if applicable) LRCoulomb and DFTD3/D3BJ modules embedded","title":"Legacy Format (.jpt)"},{"location":"model_format/#exporting-models","text":"Use the aimnet export CLI command: aimnet export weights.pt model_v2.pt --model config.yaml --sae sae.yaml","title":"Exporting Models"},{"location":"model_format/#export-process","text":"Load model YAML config, SAE (self-atomic energies), and weights Strip LRCoulomb/DFTD3 modules from config Add SRCoulomb if LRCoulomb was present (requires determinable rc ) Build core model from modified config Load weights (with strict=False for module changes) Bake SAE into atomic_shift.shifts.weight as float64 Mask unimplemented species (set NaN in afv.weight ) Save with metadata","title":"Export Process"},{"location":"model_format/#export-options","text":"aimnet export weights.pt model.pt \\ --model config.yaml \\ --sae sae.yaml \\ --needs-coulomb # Override: force external Coulomb --needs-dispersion # Override: force external DFTD3 Explicit flags override auto-detection from config.","title":"Export Options"},{"location":"model_format/#converting-legacy-models","text":"Use the aimnet convert CLI command: aimnet convert model.jpt config.yaml model_v2.pt","title":"Converting Legacy Models"},{"location":"model_format/#conversion-process","text":"Load legacy JIT model and YAML config Extract cutoff from model attribute Extract implemented_species from afv.weight (non-NaN entries) Strip LR modules from config, add SRCoulomb if needed (requires determinable rc ) Build core model from modified config Load weights from JIT state dict Validate keys (filter expected missing/unexpected) Convert atomic_shift to float64 Save with metadata","title":"Conversion Process"},{"location":"model_format/#key-changes-during-conversion","text":"Legacy New outputs.lrcoulomb.* Removed outputs.dftd3.* Removed outputs.d3bj.* Removed (none) outputs.srcoulomb.* added","title":"Key Changes During Conversion"},{"location":"model_format/#loading-models","text":"from aimnet.models.base import load_model model, metadata = load_model(\"model.pt\", device=\"cuda\") # Access metadata print(metadata[\"cutoff\"]) print(metadata[\"needs_coulomb\"]) print(metadata[\"coulomb_mode\"])","title":"Loading Models"},{"location":"model_format/#loading-behavior","text":"New format: Parses YAML, builds model, loads state dict Legacy format: Returns JIT model directly Metadata always returned as ModelMetadata dict atomic_shift converted to float64 after loading (precision)","title":"Loading Behavior"},{"location":"model_format/#metadata-behavior-summary","text":"Model Type needs_coulomb coulomb_mode Calculator Behavior New with Coulomb True \"sr_embedded\" Adds external LRCoulomb New without Coulomb False \"none\" No external Coulomb Legacy JIT False \"full_embedded\" Coulomb embedded in JIT Model Type needs_dispersion Calculator Behavior New with DFTD3/D3BJ True Adds external DFTD3 New with D3TS False D3TS embedded New without dispersion False No dispersion Legacy with DFTD3 False Embedded in JIT (d3_params extracted for diagnostics)","title":"Metadata Behavior Summary"},{"location":"model_format/#api-reference","text":"","title":"API Reference"},{"location":"model_format/#load_modelpath-devicecpu","text":"Load model from file with automatic format detection. Parameters: path ( str ): Path to model file ( .pt or .jpt ) device ( str ): Device to load model on Returns: model ( nn.Module ): Loaded model metadata ( ModelMetadata ): Metadata dictionary","title":"load_model(path, device=\"cpu\")"},{"location":"model_format/#modelmetadata-typeddict","text":"See Metadata Structure for field definitions.","title":"ModelMetadata (TypedDict)"},{"location":"model_format/#migration-guide","text":"","title":"Migration Guide"},{"location":"model_format/#why-migrate-to-v2-format","text":"Benefits of v2 (.pt) over v1 (.jpt): Runtime flexibility : Change Coulomb method (simple/DSF/Ewald) without retraining Smaller files : Separate external modules reduce file size Better debugging : Access model structure and weights directly Modern workflow : Compatible with latest PyTorch features Metadata : Rich metadata for validation and documentation When to convert: You have legacy .jpt models and want runtime Coulomb control You're training new models (use v2 from the start) You need to modify model architecture post-training When to keep v1: Legacy compatibility required Model works fine and no new features needed Deployment pipeline expects JIT models","title":"Why Migrate to v2 Format?"},{"location":"model_format/#step-by-step-migration","text":"","title":"Step-by-Step Migration"},{"location":"model_format/#1-prepare-required-files","text":"You'll need: model.jpt - Your legacy JIT model config.yaml - Original model configuration # If you don't have config.yaml, you may need to reconstruct it # from training logs or model inspection","title":"1. Prepare Required Files"},{"location":"model_format/#2-run-conversion","text":"aimnet convert model.jpt config.yaml model_v2.pt What happens during conversion: Extracts model weights from JIT state dict Strips embedded LRCoulomb/DFTD3 modules Adds SRCoulomb if LRCoulomb was present Preserves atomic shifts (SAE) as float64 Detects implemented species from weights Generates metadata dictionary","title":"2. Run Conversion"},{"location":"model_format/#3-validate-conversion","text":"from aimnet.calculators import AIMNet2Calculator import torch # Load both models calc_v1 = AIMNet2Calculator(\"model.jpt\") calc_v2 = AIMNet2Calculator(\"model_v2.pt\") # Test data data = { \"coord\": torch.randn(10, 3), \"numbers\": torch.randint(1, 9, (10,)), \"charge\": 0.0, } # Compare energies (should match within tolerance) result_v1 = calc_v1(data, forces=True) result_v2 = calc_v2(data, forces=True) energy_diff = (result_v1[\"energy\"] - result_v2[\"energy\"]).abs() force_diff = (result_v1[\"forces\"] - result_v2[\"forces\"]).abs().max() print(f\"Energy difference: {energy_diff:.2e} eV\") print(f\"Max force difference: {force_diff:.2e} eV/\u00c5\") assert energy_diff < 1e-5, \"Energy mismatch!\" assert force_diff < 1e-4, \"Force mismatch!\" Expected differences: Energies: < 1e-5 eV (numerical precision) Forces: < 1e-4 eV/\u00c5 (gradient precision)","title":"3. Validate Conversion"},{"location":"model_format/#4-test-runtime-flexibility","text":"# v2 models support runtime method changes calc_v2.set_lrcoulomb_method(\"dsf\", cutoff=15.0) result_dsf = calc_v2(data) calc_v2.set_lrcoulomb_method(\"ewald\", ewald_accuracy=1e-8) result_ewald = calc_v2(data) # v1 models show warning but don't change calc_v1.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # Warning: Cannot change method for legacy models","title":"4. Test Runtime Flexibility"},{"location":"model_format/#common-conversion-issues","text":"","title":"Common Conversion Issues"},{"location":"model_format/#issue-missing-configyaml","text":"Problem: You have a .jpt model but no configuration file. Solution: Inspect the model to reconstruct config: import torch model = torch.jit.load(\"model.jpt\") # Inspect attributes print(f\"Cutoff: {model.cutoff}\") print(f\"Cutoff LR: {model.cutoff_lr}\") # May need to manually create config based on model structure","title":"Issue: Missing config.yaml"},{"location":"model_format/#issue-weight-mismatch","text":"Problem: Conversion completes but validation shows large differences. Solution: Check for module name mismatches: # Use verbose mode to see what's happening aimnet convert model.jpt config.yaml model_v2.pt --verbose # Check for unexpected missing keys # Some modules may have been renamed","title":"Issue: Weight Mismatch"},{"location":"model_format/#issue-implemented-species-mismatch","text":"Problem: Converted model has wrong implemented_species . Solution: Species are auto-detected from non-NaN entries in afv.weight . Verify: from aimnet.models.base import load_model model, metadata = load_model(\"model_v2.pt\") print(metadata[\"implemented_species\"]) # If wrong, may need to fix config before conversion","title":"Issue: Implemented Species Mismatch"},{"location":"model_format/#exporting-new-models","text":"For newly trained models, export directly to v2: aimnet export weights.pt model_v2.pt \\ --model config.yaml \\ --sae sae.yaml Optional flags: # Override auto-detection --needs-coulomb # Force external Coulomb --needs-dispersion # Force external DFTD3","title":"Exporting New Models"},{"location":"model_format/#cli-commands","text":"# Export trained model aimnet export weights.pt output.pt --model config.yaml --sae sae.yaml # Convert legacy JIT model aimnet convert model.jpt config.yaml output.pt # Calculate SAE from dataset aimnet calc_sae dataset.h5 sae.yaml","title":"CLI Commands"},{"location":"pr-35-analysis/","text":"Deep Analysis: PR #35 \u2014 Integrate nvalchemi-toolkit-ops and new model format \u00b6 Author: Roman Zubatyuk (@zubatyuk) Scope: +11,272 / -1,498 lines across 51 files Branch: feature/alchemi-nblist-external-lr \u2192 main Executive Summary \u00b6 This PR is a major architectural overhaul of AIMNet2 that: Replaces the custom Numba neighbor list with nvalchemi-toolkit-ops (GPU-accelerated neighbor lists and DFT-D3) Introduces NVIDIA Warp kernels for conv_sv_2d_sp sparse convolutions (~5x speedup potential) Adds a new model format ( .pt with embedded YAML) replacing legacy JIT .jpt Externalizes long-range modules (LRCoulomb, DFTD3) for runtime configuration Enables batched PBC with stress tensor support for cell optimization and NPT 1. Architecture Changes \u00b6 1.1 Neighbor List: Numba \u2192 nvalchemiops \u00b6 Aspect Before After Implementation nbmat.py + nb_kernel_cpu.py + nb_kernel_cuda.py (Numba) nvalchemiops.neighborlist.neighbor_list Overflow handling TooManyNeighborsError + manual max_density scaling NeighborOverflowError + AdaptiveNeighborList with hysteresis PBC support Single-cell only Batched cells via cell (B, 3, 3) , mol_idx for atom\u2192cell mapping Buffer sizing Fixed calc_max_nb(cutoff, density) Dynamic ~75% utilization, 16-aligned Removed files: nbmat.py , nb_kernel_cpu.py , nb_kernel_cuda.py (659 lines total) New: AdaptiveNeighborList in calculator.py wraps nvalchemiops with: _round_to_16() for memory alignment Retry loop on NeighborOverflowError (1.5x buffer increase) Shrink when utilization < 2/3 of target (hysteresis to avoid thrashing) 1.2 Warp Kernels for conv_sv_2d_sp \u00b6 New: aimnet/kernels/conv_sv_2d_sp_wp.py (478 lines) Custom CUDA kernels via NVIDIA Warp for sparse 2D convolution PyTorch custom ops: aimnet::conv_sv_2d_sp_fwd , _bwd , _bwd_bwd Critical fix: Kernel dimensions use B-1 to exclude padding row (gradient correctness) CPU fallback for d2features when Warp unavailable weights_only=True in torch.load for security (model loading) 1.3 Model Format: .jpt \u2192 .pt \u00b6 Format Structure Loading Legacy .jpt JIT-compiled TorchScript torch.jit.load() New .pt {state_dict, config_yaml, metadata} load_model() auto-detection New modules: aimnet/models/utils.py \u2014 load_model() , ModelMetadata TypedDict, inspection helpers aimnet/models/convert.py \u2014 JIT \u2192 v2 conversion aimnet/train/export_model.py \u2014 Export trained models Registry: All model URLs updated to aimnet2v2/ path. 2. External Long-Range Modules \u00b6 2.1 Decoupling \u00b6 LRCoulomb and DFTD3 moved from embedded model components to attachable calculator modules Metadata drives attachment: needs_coulomb , needs_dispersion , d3_params , coulomb_mode set_lrcoulomb_method() now updates external module; legacy embedded Coulomb gets a warning 2.2 Separate Neighbor Lists \u00b6 When Coulomb and DFTD3 cutoffs differ by >20%, separate AdaptiveNeighborList instances: _nblist_dftd3 , _nblist_coulomb (or shared _nblist_lr ) Data keys: nbmat_lr , nbmat_coulomb , nbmat_dftd3 , shifts_* 2.3 DFTD3 via nvalchemiops \u00b6 aimnet/modules/lr.py : New DFTD3 class wrapping nvalchemiops.interactions.dispersion.dftd3 _DFTD3Function autograd wrapper with conditional smoothing resolve_suffix() for neighbor list lookup (supports _dftd3 , _coulomb , etc.) 3. Batched PBC and Stress \u00b6 3.1 move_coord_to_cell \u00b6 Extended for batched cells: cell (3, 3) + coord (N, 3) or (B, N, 3) \u2014 existing behavior cell (B, 3, 3) + flat coord (N_total, 3) \u2014 requires mol_idx for atom\u2192cell mapping 3.2 Stress Tensor \u00b6 get_derivatives() : Volume computation supports batched cells (B, 3, 3) volume = torch.linalg.det(cell).abs().unsqueeze(-1).unsqueeze(-1) for batched 3.3 PBC + Multiple Molecules \u00b6 Previous: NotImplementedError for PBC with multiple molecules Current: Removed; PBC with mol_idx and batched cells is supported 4. Dependencies \u00b6 Package Version Purpose nvalchemi-toolkit-ops \u22650.2 Neighbor lists, DFT-D3 warp-lang \u22651.11 CUDA kernels for conv_sv_2d_sp numba \u2014 Removed from core deps numpy \u2014 Constraint <3.0 removed (lock shows unconstrained) ase 3.22.1 \u2192 3.27.0 Bumped in lock Note: nvalchemi-toolkit-ops depends on warp-lang ; both add ~120MB+ to install. Warp has platform-specific wheels (Linux x86_64, ARM64, macOS ARM64, Windows). 5. API Changes \u00b6 5.1 AIMNet2Calculator \u00b6 New params: needs_coulomb , needs_dispersion , device , compile_model , compile_kwargs , train Changed: nb_threshold default 320 \u2192 120 New methods: set_lr_cutoff() , set_dftd3_cutoff() New properties: has_external_coulomb , has_external_dftd3 , coulomb_method , coulomb_cutoff , dftd3_cutoff set_lrcoulomb_method: Added ewald_accuracy (default 1e-8) 5.2 prepare_input \u00b6 Skips make_nbmat if nbmat already in data (user-provided neighbor list) PBC: Always flattens when cell present (for correct neighbor list with shifts) 5.3 Base Keys \u00b6 _optional_keys extended: shifts_lr added _optional_keys_dtype updated with comments 6. Test Coverage \u00b6 New / Extended Tests \u00b6 test_conv_sv_2d_sp.py \u2014 Warp kernel forward, backward, double-backward, shapes test_dftd3.py \u2014 DFTD3 energy, gradients, smoothing test_pbc.py \u2014 DSF/Ewald with CIF crystals, stress, torch.compile test_model.py \u2014 load_model() , metadata, conversion test_calculator.py \u2014 External modules, set_lrcoulomb_method , set_dftd3_cutoff test_ops.py \u2014 resolve_suffix() , get_i() , batched PBC distances Removed \u00b6 test_nbmat.py (136 lines) \u2014 Replaced by nvalchemiops-based flow Fixtures \u00b6 conftest.py : pbc_crystal_small , pbc_crystal_large from CIF New CIF files: 1100172.cif , 2000054.cif 7. Risks and Considerations \u00b6 7.1 Breaking Changes \u00b6 Model registry URLs \u2014 All point to aimnet2v2/ ; legacy .jpt URLs no longer used. Users with cached .jpt must re-download or convert. nb_threshold \u2014 Default 320 \u2192 120 changes when flattening kicks in; may affect performance for medium-sized systems. numba removed \u2014 Any code depending on aimnet.calculators.nbmat or nb_kernel_* will break. 7.2 Compatibility \u00b6 CPU-only: Warp and nvalchemiops have CPU fallbacks where implemented; verify CPU path for neighbor lists and DFTD3. Windows: warp-lang has win_amd64 wheel; nvalchemiops availability on Windows should be confirmed. Legacy models: load_model() supports both formats; embedded Coulomb/D3 models still work but set_lrcoulomb_method only affects external modules. 7.3 Security \u00b6 weights_only=True in torch.load for v2 models (good practice) DispParam: ptfile stripped during export; validation hook checks buffer values after load 7.4 Performance \u00b6 Warp kernels: ~5x speedup for conv_sv_2d_sp on GPU (per PR description) Adaptive neighbor list: Hysteresis may cause occasional buffer resizing in MD; 75% target balances memory vs. recomputation Batched PBC: More complex move_coord_to_cell and stress; benchmark on representative workloads 8. Documentation \u00b6 New: docs/calculator.md , docs/cli.md , docs/getting_started.md , docs/long_range.md , docs/model_format.md Updated: docs/index.md , docs/api/calculators.md , docs/train.md Removed: docs/reference.md (empty) README: Technical details on batching, AdaptiveNeighborList, buffer management 9. Recommendations for Review \u00b6 Verify nvalchemiops API \u2014 Confirm neighbor_list and dftd3 signatures match usage; check error handling for NeighborOverflowError . Warp kernel correctness \u2014 B-1 padding exclusion is critical; validate on edge cases (single atom, max neighbors). Model conversion \u2014 Test aimnet convert and aimnet export on real trained models; ensure metadata round-trip. PBC + batched cells \u2014 Test mol_idx mapping with multiple cells; validate stress tensor for NPT. CI/CD \u2014 Ensure nvalchemi-toolkit-ops and warp-lang install cleanly on all supported platforms (Linux, Windows, macOS). Backward compatibility \u2014 Run existing examples and ASE integration with both legacy and new model formats. 10. Code Review Agent Dispatch \u00b6 To trigger the Claude Code Review workflow manually: Via GitHub UI: Actions \u2192 \"Claude Code Review\" \u2192 \"Run workflow\" (after adding workflow_dispatch ) Via gh CLI: gh workflow run \"Claude Code Review\" -f pr_number=35 Via PR comment: Post @claude please review this PR to trigger the Claude workflow (if configured)","title":"Deep Analysis: PR #35 \u2014 Integrate nvalchemi-toolkit-ops and new model format"},{"location":"pr-35-analysis/#deep-analysis-pr-35-integrate-nvalchemi-toolkit-ops-and-new-model-format","text":"Author: Roman Zubatyuk (@zubatyuk) Scope: +11,272 / -1,498 lines across 51 files Branch: feature/alchemi-nblist-external-lr \u2192 main","title":"Deep Analysis: PR #35 \u2014 Integrate nvalchemi-toolkit-ops and new model format"},{"location":"pr-35-analysis/#executive-summary","text":"This PR is a major architectural overhaul of AIMNet2 that: Replaces the custom Numba neighbor list with nvalchemi-toolkit-ops (GPU-accelerated neighbor lists and DFT-D3) Introduces NVIDIA Warp kernels for conv_sv_2d_sp sparse convolutions (~5x speedup potential) Adds a new model format ( .pt with embedded YAML) replacing legacy JIT .jpt Externalizes long-range modules (LRCoulomb, DFTD3) for runtime configuration Enables batched PBC with stress tensor support for cell optimization and NPT","title":"Executive Summary"},{"location":"pr-35-analysis/#1-architecture-changes","text":"","title":"1. Architecture Changes"},{"location":"pr-35-analysis/#11-neighbor-list-numba-nvalchemiops","text":"Aspect Before After Implementation nbmat.py + nb_kernel_cpu.py + nb_kernel_cuda.py (Numba) nvalchemiops.neighborlist.neighbor_list Overflow handling TooManyNeighborsError + manual max_density scaling NeighborOverflowError + AdaptiveNeighborList with hysteresis PBC support Single-cell only Batched cells via cell (B, 3, 3) , mol_idx for atom\u2192cell mapping Buffer sizing Fixed calc_max_nb(cutoff, density) Dynamic ~75% utilization, 16-aligned Removed files: nbmat.py , nb_kernel_cpu.py , nb_kernel_cuda.py (659 lines total) New: AdaptiveNeighborList in calculator.py wraps nvalchemiops with: _round_to_16() for memory alignment Retry loop on NeighborOverflowError (1.5x buffer increase) Shrink when utilization < 2/3 of target (hysteresis to avoid thrashing)","title":"1.1 Neighbor List: Numba \u2192 nvalchemiops"},{"location":"pr-35-analysis/#12-warp-kernels-for-conv_sv_2d_sp","text":"New: aimnet/kernels/conv_sv_2d_sp_wp.py (478 lines) Custom CUDA kernels via NVIDIA Warp for sparse 2D convolution PyTorch custom ops: aimnet::conv_sv_2d_sp_fwd , _bwd , _bwd_bwd Critical fix: Kernel dimensions use B-1 to exclude padding row (gradient correctness) CPU fallback for d2features when Warp unavailable weights_only=True in torch.load for security (model loading)","title":"1.2 Warp Kernels for conv_sv_2d_sp"},{"location":"pr-35-analysis/#13-model-format-jpt-pt","text":"Format Structure Loading Legacy .jpt JIT-compiled TorchScript torch.jit.load() New .pt {state_dict, config_yaml, metadata} load_model() auto-detection New modules: aimnet/models/utils.py \u2014 load_model() , ModelMetadata TypedDict, inspection helpers aimnet/models/convert.py \u2014 JIT \u2192 v2 conversion aimnet/train/export_model.py \u2014 Export trained models Registry: All model URLs updated to aimnet2v2/ path.","title":"1.3 Model Format: .jpt \u2192 .pt"},{"location":"pr-35-analysis/#2-external-long-range-modules","text":"","title":"2. External Long-Range Modules"},{"location":"pr-35-analysis/#21-decoupling","text":"LRCoulomb and DFTD3 moved from embedded model components to attachable calculator modules Metadata drives attachment: needs_coulomb , needs_dispersion , d3_params , coulomb_mode set_lrcoulomb_method() now updates external module; legacy embedded Coulomb gets a warning","title":"2.1 Decoupling"},{"location":"pr-35-analysis/#22-separate-neighbor-lists","text":"When Coulomb and DFTD3 cutoffs differ by >20%, separate AdaptiveNeighborList instances: _nblist_dftd3 , _nblist_coulomb (or shared _nblist_lr ) Data keys: nbmat_lr , nbmat_coulomb , nbmat_dftd3 , shifts_*","title":"2.2 Separate Neighbor Lists"},{"location":"pr-35-analysis/#23-dftd3-via-nvalchemiops","text":"aimnet/modules/lr.py : New DFTD3 class wrapping nvalchemiops.interactions.dispersion.dftd3 _DFTD3Function autograd wrapper with conditional smoothing resolve_suffix() for neighbor list lookup (supports _dftd3 , _coulomb , etc.)","title":"2.3 DFTD3 via nvalchemiops"},{"location":"pr-35-analysis/#3-batched-pbc-and-stress","text":"","title":"3. Batched PBC and Stress"},{"location":"pr-35-analysis/#31-move_coord_to_cell","text":"Extended for batched cells: cell (3, 3) + coord (N, 3) or (B, N, 3) \u2014 existing behavior cell (B, 3, 3) + flat coord (N_total, 3) \u2014 requires mol_idx for atom\u2192cell mapping","title":"3.1 move_coord_to_cell"},{"location":"pr-35-analysis/#32-stress-tensor","text":"get_derivatives() : Volume computation supports batched cells (B, 3, 3) volume = torch.linalg.det(cell).abs().unsqueeze(-1).unsqueeze(-1) for batched","title":"3.2 Stress Tensor"},{"location":"pr-35-analysis/#33-pbc-multiple-molecules","text":"Previous: NotImplementedError for PBC with multiple molecules Current: Removed; PBC with mol_idx and batched cells is supported","title":"3.3 PBC + Multiple Molecules"},{"location":"pr-35-analysis/#4-dependencies","text":"Package Version Purpose nvalchemi-toolkit-ops \u22650.2 Neighbor lists, DFT-D3 warp-lang \u22651.11 CUDA kernels for conv_sv_2d_sp numba \u2014 Removed from core deps numpy \u2014 Constraint <3.0 removed (lock shows unconstrained) ase 3.22.1 \u2192 3.27.0 Bumped in lock Note: nvalchemi-toolkit-ops depends on warp-lang ; both add ~120MB+ to install. Warp has platform-specific wheels (Linux x86_64, ARM64, macOS ARM64, Windows).","title":"4. Dependencies"},{"location":"pr-35-analysis/#5-api-changes","text":"","title":"5. API Changes"},{"location":"pr-35-analysis/#51-aimnet2calculator","text":"New params: needs_coulomb , needs_dispersion , device , compile_model , compile_kwargs , train Changed: nb_threshold default 320 \u2192 120 New methods: set_lr_cutoff() , set_dftd3_cutoff() New properties: has_external_coulomb , has_external_dftd3 , coulomb_method , coulomb_cutoff , dftd3_cutoff set_lrcoulomb_method: Added ewald_accuracy (default 1e-8)","title":"5.1 AIMNet2Calculator"},{"location":"pr-35-analysis/#52-prepare_input","text":"Skips make_nbmat if nbmat already in data (user-provided neighbor list) PBC: Always flattens when cell present (for correct neighbor list with shifts)","title":"5.2 prepare_input"},{"location":"pr-35-analysis/#53-base-keys","text":"_optional_keys extended: shifts_lr added _optional_keys_dtype updated with comments","title":"5.3 Base Keys"},{"location":"pr-35-analysis/#6-test-coverage","text":"","title":"6. Test Coverage"},{"location":"pr-35-analysis/#new-extended-tests","text":"test_conv_sv_2d_sp.py \u2014 Warp kernel forward, backward, double-backward, shapes test_dftd3.py \u2014 DFTD3 energy, gradients, smoothing test_pbc.py \u2014 DSF/Ewald with CIF crystals, stress, torch.compile test_model.py \u2014 load_model() , metadata, conversion test_calculator.py \u2014 External modules, set_lrcoulomb_method , set_dftd3_cutoff test_ops.py \u2014 resolve_suffix() , get_i() , batched PBC distances","title":"New / Extended Tests"},{"location":"pr-35-analysis/#removed","text":"test_nbmat.py (136 lines) \u2014 Replaced by nvalchemiops-based flow","title":"Removed"},{"location":"pr-35-analysis/#fixtures","text":"conftest.py : pbc_crystal_small , pbc_crystal_large from CIF New CIF files: 1100172.cif , 2000054.cif","title":"Fixtures"},{"location":"pr-35-analysis/#7-risks-and-considerations","text":"","title":"7. Risks and Considerations"},{"location":"pr-35-analysis/#71-breaking-changes","text":"Model registry URLs \u2014 All point to aimnet2v2/ ; legacy .jpt URLs no longer used. Users with cached .jpt must re-download or convert. nb_threshold \u2014 Default 320 \u2192 120 changes when flattening kicks in; may affect performance for medium-sized systems. numba removed \u2014 Any code depending on aimnet.calculators.nbmat or nb_kernel_* will break.","title":"7.1 Breaking Changes"},{"location":"pr-35-analysis/#72-compatibility","text":"CPU-only: Warp and nvalchemiops have CPU fallbacks where implemented; verify CPU path for neighbor lists and DFTD3. Windows: warp-lang has win_amd64 wheel; nvalchemiops availability on Windows should be confirmed. Legacy models: load_model() supports both formats; embedded Coulomb/D3 models still work but set_lrcoulomb_method only affects external modules.","title":"7.2 Compatibility"},{"location":"pr-35-analysis/#73-security","text":"weights_only=True in torch.load for v2 models (good practice) DispParam: ptfile stripped during export; validation hook checks buffer values after load","title":"7.3 Security"},{"location":"pr-35-analysis/#74-performance","text":"Warp kernels: ~5x speedup for conv_sv_2d_sp on GPU (per PR description) Adaptive neighbor list: Hysteresis may cause occasional buffer resizing in MD; 75% target balances memory vs. recomputation Batched PBC: More complex move_coord_to_cell and stress; benchmark on representative workloads","title":"7.4 Performance"},{"location":"pr-35-analysis/#8-documentation","text":"New: docs/calculator.md , docs/cli.md , docs/getting_started.md , docs/long_range.md , docs/model_format.md Updated: docs/index.md , docs/api/calculators.md , docs/train.md Removed: docs/reference.md (empty) README: Technical details on batching, AdaptiveNeighborList, buffer management","title":"8. Documentation"},{"location":"pr-35-analysis/#9-recommendations-for-review","text":"Verify nvalchemiops API \u2014 Confirm neighbor_list and dftd3 signatures match usage; check error handling for NeighborOverflowError . Warp kernel correctness \u2014 B-1 padding exclusion is critical; validate on edge cases (single atom, max neighbors). Model conversion \u2014 Test aimnet convert and aimnet export on real trained models; ensure metadata round-trip. PBC + batched cells \u2014 Test mol_idx mapping with multiple cells; validate stress tensor for NPT. CI/CD \u2014 Ensure nvalchemi-toolkit-ops and warp-lang install cleanly on all supported platforms (Linux, Windows, macOS). Backward compatibility \u2014 Run existing examples and ASE integration with both legacy and new model formats.","title":"9. Recommendations for Review"},{"location":"pr-35-analysis/#10-code-review-agent-dispatch","text":"To trigger the Claude Code Review workflow manually: Via GitHub UI: Actions \u2192 \"Claude Code Review\" \u2192 \"Run workflow\" (after adding workflow_dispatch ) Via gh CLI: gh workflow run \"Claude Code Review\" -f pr_number=35 Via PR comment: Post @claude please review this PR to trigger the Claude workflow (if configured)","title":"10. Code Review Agent Dispatch"},{"location":"train/","text":"AIMNet2 training examples. \u00b6 General workflow \u00b6 Dataset preparation \u00b6 The training dataset must be formatted as an HDF5 file, with groups containing molecules of uniform size. For example, the dataset below contains 25,768 molecules with 28 atoms and 19,404 molecules with 29 atoms. $ h5ls -r dataset.h5 /028 Group /028/charge Dataset {25768} /028/charges Dataset {25768, 28} /028/coord Dataset {25768, 28, 3} /028/energy Dataset {25768} /028/forces Dataset {25768, 28, 3} /028/numbers Dataset {25768, 28} /029 Group /029/charge Dataset {19404} /029/charges Dataset {19404, 29} /029/coord Dataset {19404, 29, 3} /029/energy Dataset {19404} /029/forces Dataset {19404, 29, 3} /029/numbers Dataset {19404, 29} Units should be based on Angstrom, electron-volt, and electron charge. Training Configuration \u00b6 To access available options for the training script execute the following command: $ aimnet train --help Key components for initiating training include: Training Configuration: The base configuration file aimnet/train/default_train.yaml can be customized using command-line options or a separate YAML configuration file, which will override or extend default values. It is crucial to, at minimum, define the run_name and data.train . Model Definition: By default, the model defined in aimnet/models/aimnet2.yaml is used. Self-Atomic Energies File: This file can be generated using the following command: $ aimnet calc_sae dataset.h5 dataset_sae.yaml Weights & Biases (W&B) Logging \u00b6 The training script integrates with Weights & Biases (W&B), a platform for experiment tracking (free for personal and academic use). To monitor training progress, either a W&B account or a local Docker-based W&B server is necessary. By default, W&B operates in offline mode. Setting Up W&B Online Account: $ wandb login Project and Entity Configuration: Create a configuration file (e.g., extra_conf.yaml ) with your W&B project and entity details: wandb: init: mode: online entity: your_username project: your_project_name Pass this configuration to the aimnet train command using the --config parameter. Launching Training \u00b6 For optimal data loader performance, it is recommended to disable numpy multithreading: $ export OMP_NUM_THREADS=1 By default, training will utilize all available GPUs in a single-node, distributed data-parallel mode. To restrict training to a specific GPU (e.g., GPU 0): $ export CUDA_VISIBLE_DEVICES=0 Finally, initiate the training script with default parameters and the specified run_name : $ aimnet train data.train=dataset.h5 data.sae.energy.file=dataset_sae.yaml run_name=firstrun Model Export for Distribution \u00b6 To export a trained model for distribution and use with AIMNet calculators: $ aimnet export weights.pt model.pt --model config.yaml --sae model.sae Arguments: weights.pt : Raw PyTorch weights file from training model.pt : Output model file --model : Path to model YAML configuration file --sae : Path to self-atomic energies file The export command creates a self-contained .pt file with: Model architecture configuration Trained weights with SAE baked into atomic shifts Metadata for Coulomb and dispersion handling Model Format The new model format separates the core neural network from long-range corrections: Core model computes NN energy minus short-range Coulomb Long-range Coulomb (LRCoulomb) is applied externally by the calculator DFTD3 dispersion is applied externally by the calculator This allows switching Coulomb methods (simple/DSF/Ewald) at inference time without re-exporting. Metadata Schema The v2 model format includes the following metadata fields: Field Type Description format_version int 2 for new format cutoff float Model cutoff radius needs_coulomb bool True if calculator should add external Coulomb needs_dispersion bool True if calculator should add external DFTD3 coulomb_mode str \"sr_embedded\" (has SRCoulomb) or \"none\" coulomb_sr_rc float? SR Coulomb cutoff (if coulomb_mode=\"sr_embedded\") coulomb_sr_envelope str? \"exp\" or \"cosine\" (if coulomb_mode=\"sr_embedded\") d3_params dict? D3 parameters {s6, s8, a1, a2} if needs_dispersion=True implemented_species list[int] Supported atomic numbers Runtime Configuration For new-format models, the calculator provides methods to configure external modules: from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator(\"model.pt\") # Switch Coulomb method (only if model uses external Coulomb) if calc.has_external_coulomb: calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # For PBC systems # Adjust DFTD3 cutoff (only if model uses external dispersion) if calc.has_external_dftd3: calc.set_dftd3_cutoff(20.0, smoothing_fraction=0.8) Backward Compatibility The calculator automatically detects and loads both formats: New .pt files with embedded metadata (format version 2) Legacy JIT-compiled .jpt files (format version 1) For legacy models, Coulomb and dispersion modules remain embedded in the model. Converting Legacy JIT Models \u00b6 To convert existing .jpt models to the new format: $ aimnet convert model.jpt config.yaml model_new.pt Arguments: model.jpt : Legacy JIT-compiled model file config.yaml : Model YAML configuration file model_new.pt : Output file in new format The conversion: Extracts model cutoff and D3 parameters from the JIT model Rebuilds the architecture from YAML with SRCoulomb embedded Loads weights from the JIT model Creates a new-format bundle with all necessary metadata Registry Migration Workflow \u00b6 For maintainers migrating the model registry from legacy .jpt to new .pt format: Convert each model: bash aimnet convert aimnet2_wb97m_d3_0.jpt aimnet/models/aimnet2_dftd3_wb97m.yaml aimnet2_wb97m_d3_0.pt Validate conversion: bash python scripts/validate_conversion.py aimnet2_wb97m_d3_0.pt aimnet2_wb97m_d3_0.jpt \\ --structure tests/data/caffeine.xyz The validation script compares energies and forces between formats and reports any discrepancies. Upload to GCS: bash gsutil cp aimnet2_wb97m_d3_0.pt gs://aimnetcentral/AIMNet2/aimnet2_wb97m_d3_0.pt Update model_registry.yaml: yaml models: aimnet2_wb97m_d3_0: file: aimnet2_wb97m_d3_0.pt url: https://storage.googleapis.com/aimnetcentral/AIMNet2/aimnet2_wb97m_d3_0.pt","title":"Train"},{"location":"train/#aimnet2-training-examples","text":"","title":"AIMNet2 training examples."},{"location":"train/#general-workflow","text":"","title":"General workflow"},{"location":"train/#dataset-preparation","text":"The training dataset must be formatted as an HDF5 file, with groups containing molecules of uniform size. For example, the dataset below contains 25,768 molecules with 28 atoms and 19,404 molecules with 29 atoms. $ h5ls -r dataset.h5 /028 Group /028/charge Dataset {25768} /028/charges Dataset {25768, 28} /028/coord Dataset {25768, 28, 3} /028/energy Dataset {25768} /028/forces Dataset {25768, 28, 3} /028/numbers Dataset {25768, 28} /029 Group /029/charge Dataset {19404} /029/charges Dataset {19404, 29} /029/coord Dataset {19404, 29, 3} /029/energy Dataset {19404} /029/forces Dataset {19404, 29, 3} /029/numbers Dataset {19404, 29} Units should be based on Angstrom, electron-volt, and electron charge.","title":"Dataset preparation"},{"location":"train/#training-configuration","text":"To access available options for the training script execute the following command: $ aimnet train --help Key components for initiating training include: Training Configuration: The base configuration file aimnet/train/default_train.yaml can be customized using command-line options or a separate YAML configuration file, which will override or extend default values. It is crucial to, at minimum, define the run_name and data.train . Model Definition: By default, the model defined in aimnet/models/aimnet2.yaml is used. Self-Atomic Energies File: This file can be generated using the following command: $ aimnet calc_sae dataset.h5 dataset_sae.yaml","title":"Training Configuration"},{"location":"train/#weights-biases-wb-logging","text":"The training script integrates with Weights & Biases (W&B), a platform for experiment tracking (free for personal and academic use). To monitor training progress, either a W&B account or a local Docker-based W&B server is necessary. By default, W&B operates in offline mode. Setting Up W&B Online Account: $ wandb login Project and Entity Configuration: Create a configuration file (e.g., extra_conf.yaml ) with your W&B project and entity details: wandb: init: mode: online entity: your_username project: your_project_name Pass this configuration to the aimnet train command using the --config parameter.","title":"Weights &amp; Biases (W&amp;B) Logging"},{"location":"train/#launching-training","text":"For optimal data loader performance, it is recommended to disable numpy multithreading: $ export OMP_NUM_THREADS=1 By default, training will utilize all available GPUs in a single-node, distributed data-parallel mode. To restrict training to a specific GPU (e.g., GPU 0): $ export CUDA_VISIBLE_DEVICES=0 Finally, initiate the training script with default parameters and the specified run_name : $ aimnet train data.train=dataset.h5 data.sae.energy.file=dataset_sae.yaml run_name=firstrun","title":"Launching Training"},{"location":"train/#model-export-for-distribution","text":"To export a trained model for distribution and use with AIMNet calculators: $ aimnet export weights.pt model.pt --model config.yaml --sae model.sae Arguments: weights.pt : Raw PyTorch weights file from training model.pt : Output model file --model : Path to model YAML configuration file --sae : Path to self-atomic energies file The export command creates a self-contained .pt file with: Model architecture configuration Trained weights with SAE baked into atomic shifts Metadata for Coulomb and dispersion handling Model Format The new model format separates the core neural network from long-range corrections: Core model computes NN energy minus short-range Coulomb Long-range Coulomb (LRCoulomb) is applied externally by the calculator DFTD3 dispersion is applied externally by the calculator This allows switching Coulomb methods (simple/DSF/Ewald) at inference time without re-exporting. Metadata Schema The v2 model format includes the following metadata fields: Field Type Description format_version int 2 for new format cutoff float Model cutoff radius needs_coulomb bool True if calculator should add external Coulomb needs_dispersion bool True if calculator should add external DFTD3 coulomb_mode str \"sr_embedded\" (has SRCoulomb) or \"none\" coulomb_sr_rc float? SR Coulomb cutoff (if coulomb_mode=\"sr_embedded\") coulomb_sr_envelope str? \"exp\" or \"cosine\" (if coulomb_mode=\"sr_embedded\") d3_params dict? D3 parameters {s6, s8, a1, a2} if needs_dispersion=True implemented_species list[int] Supported atomic numbers Runtime Configuration For new-format models, the calculator provides methods to configure external modules: from aimnet.calculators import AIMNet2Calculator calc = AIMNet2Calculator(\"model.pt\") # Switch Coulomb method (only if model uses external Coulomb) if calc.has_external_coulomb: calc.set_lrcoulomb_method(\"dsf\", cutoff=15.0) # For PBC systems # Adjust DFTD3 cutoff (only if model uses external dispersion) if calc.has_external_dftd3: calc.set_dftd3_cutoff(20.0, smoothing_fraction=0.8) Backward Compatibility The calculator automatically detects and loads both formats: New .pt files with embedded metadata (format version 2) Legacy JIT-compiled .jpt files (format version 1) For legacy models, Coulomb and dispersion modules remain embedded in the model.","title":"Model Export for Distribution"},{"location":"train/#converting-legacy-jit-models","text":"To convert existing .jpt models to the new format: $ aimnet convert model.jpt config.yaml model_new.pt Arguments: model.jpt : Legacy JIT-compiled model file config.yaml : Model YAML configuration file model_new.pt : Output file in new format The conversion: Extracts model cutoff and D3 parameters from the JIT model Rebuilds the architecture from YAML with SRCoulomb embedded Loads weights from the JIT model Creates a new-format bundle with all necessary metadata","title":"Converting Legacy JIT Models"},{"location":"train/#registry-migration-workflow","text":"For maintainers migrating the model registry from legacy .jpt to new .pt format: Convert each model: bash aimnet convert aimnet2_wb97m_d3_0.jpt aimnet/models/aimnet2_dftd3_wb97m.yaml aimnet2_wb97m_d3_0.pt Validate conversion: bash python scripts/validate_conversion.py aimnet2_wb97m_d3_0.pt aimnet2_wb97m_d3_0.jpt \\ --structure tests/data/caffeine.xyz The validation script compares energies and forces between formats and reports any discrepancies. Upload to GCS: bash gsutil cp aimnet2_wb97m_d3_0.pt gs://aimnetcentral/AIMNet2/aimnet2_wb97m_d3_0.pt Update model_registry.yaml: yaml models: aimnet2_wb97m_d3_0: file: aimnet2_wb97m_d3_0.pt url: https://storage.googleapis.com/aimnetcentral/AIMNet2/aimnet2_wb97m_d3_0.pt","title":"Registry Migration Workflow"},{"location":"api/","text":"API Reference \u00b6 This section contains the complete API reference for AIMNet2. Package Structure \u00b6 Calculators - Calculator interfaces for molecular simulations Modules - Neural network modules and model components Data - Dataset handling and data loading utilities Config - Configuration and model building utilities Quick Links \u00b6 Calculators \u00b6 The main entry points for using AIMNet2: AIMNet2Calculator - Core calculator for inference AIMNet2ASE - ASE calculator interface (requires aimnet[ase] ) AIMNet2Pysis - PySisyphus calculator interface (requires aimnet[pysis] ) Command Line Interface \u00b6 aimnet --help","title":"Overview"},{"location":"api/#api-reference","text":"This section contains the complete API reference for AIMNet2.","title":"API Reference"},{"location":"api/#package-structure","text":"Calculators - Calculator interfaces for molecular simulations Modules - Neural network modules and model components Data - Dataset handling and data loading utilities Config - Configuration and model building utilities","title":"Package Structure"},{"location":"api/#quick-links","text":"","title":"Quick Links"},{"location":"api/#calculators","text":"The main entry points for using AIMNet2: AIMNet2Calculator - Core calculator for inference AIMNet2ASE - ASE calculator interface (requires aimnet[ase] ) AIMNet2Pysis - PySisyphus calculator interface (requires aimnet[pysis] )","title":"Calculators"},{"location":"api/#command-line-interface","text":"aimnet --help","title":"Command Line Interface"},{"location":"api/calculators/","text":"Calculators \u00b6 Calculator interfaces for molecular simulations using AIMNet2. AIMNet2Calculator \u00b6 The core calculator for running AIMNet2 inference. It handles model loading, device management, and application of long-range interactions (Coulomb and Dispersion). Key Features \u00b6 Format Support : Loads both legacy .jpt models and new .pt format. Long-Range Interactions : Automatically attaches LRCoulomb and DFTD3 modules based on model metadata. Overrides : You can force specific long-range behavior using needs_coulomb and needs_dispersion arguments. Batching : Automatically batches large molecules/systems based on nb_threshold . AIMNet2Calculator ( model = 'aimnet2' , nb_threshold = 120 , needs_coulomb = None , needs_dispersion = None , device = None , compile_model = False , compile_kwargs = None , train = False ) \u00b6 Generic AIMNet2 calculator. A helper class to load AIMNet2 models and perform inference. Parameters \u00b6 model : str | nn.Module Model name (from registry), path to model file, or nn.Module instance. nb_threshold : int Threshold for neighbor list batching. Molecules larger than this use flattened processing. Default is 120. needs_coulomb : bool | None Whether to add external Coulomb module. If None (default), determined from model metadata. If True/False, overrides metadata. needs_dispersion : bool | None Whether to add external DFTD3 module. If None (default), determined from model metadata. If True/False, overrides metadata. device : str | None Device to run the model on (\"cuda\", \"cpu\", or specific like \"cuda:0\"). If None (default), auto-detects CUDA availability. compile_model : bool Whether to compile the model with torch.compile(). Default is False. compile_kwargs : dict | None Additional keyword arguments to pass to torch.compile(). Default is None. train : bool Whether to enable training mode. Default is False (inference mode). When False, all model parameters have requires_grad=False, which improves torch.compile compatibility and reduces memory usage. Set to True only when training the model. Attributes \u00b6 model : nn.Module The loaded AIMNet2 model. device : str Device the model is running on (\"cuda\" or \"cpu\"). cutoff : float Short-range cutoff distance in Angstroms. cutoff_lr : float | None Long-range cutoff distance, or None if no LR modules. external_coulomb : LRCoulomb | None External Coulomb module if attached. external_dftd3 : DFTD3 | None External DFTD3 module if attached. Notes \u00b6 External LR module behavior: For file-loaded models (str): metadata is loaded from file For nn.Module: metadata is read from model.metadata attribute if available Explicit flags (needs_coulomb, needs_dispersion) override metadata If no metadata and no explicit flags, no external LR modules are added Source code in aimnet/calculators/calculator.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def __init__ ( self , model : str | nn . Module = \"aimnet2\" , nb_threshold : int = 120 , needs_coulomb : bool | None = None , needs_dispersion : bool | None = None , device : str | None = None , compile_model : bool = False , compile_kwargs : dict | None = None , train : bool = False , ): # Device selection: use provided or auto-detect if device is not None : self . device = device else : self . device = \"cuda\" if torch . cuda . is_available () else \"cpu\" self . external_coulomb : LRCoulomb | None = None self . external_dftd3 : DFTD3 | None = None # Default cutoffs for LR modules self . _default_dsf_cutoff = 15.0 self . _default_dftd3_cutoff = 15.0 self . _default_dftd3_smoothing = 0.2 # Load model and get metadata metadata : dict | None = None if isinstance ( model , str ): p = get_model_path ( model ) self . model , metadata = load_model ( p , device = self . device ) self . cutoff = metadata [ \"cutoff\" ] elif isinstance ( model , nn . Module ): self . model = model . to ( self . device ) self . cutoff = getattr ( self . model , \"cutoff\" , 5.0 ) metadata = getattr ( self . model , \"_metadata\" , None ) else : raise TypeError ( \"Invalid model type/name.\" ) # Compile model if requested if compile_model : kwargs = compile_kwargs or {} self . model = torch . compile ( self . model , ** kwargs ) # Resolve final flags (explicit overrides metadata) final_needs_coulomb = ( needs_coulomb if needs_coulomb is not None else ( metadata . get ( \"needs_coulomb\" , False ) if metadata is not None else False ) ) final_needs_dispersion = ( needs_dispersion if needs_dispersion is not None else ( metadata . get ( \"needs_dispersion\" , False ) if metadata is not None else False ) ) # Set up external Coulomb if needed if final_needs_coulomb : sr_embedded = metadata . get ( \"coulomb_mode\" ) == \"sr_embedded\" if metadata is not None else False # For PBC, user can switch to DSF/Ewald via set_lrcoulomb_method() # When sr_embedded=True: model has SRCoulomb which subtracts SR, so external # should compute FULL (subtract_sr=False) to give: (NN - SR) + FULL = NN + LR # When sr_embedded=False: model has no SR embedded, so external should compute # LR only (subtract_sr=True) to avoid double-counting self . external_coulomb = LRCoulomb ( key_in = \"charges\" , key_out = \"energy\" , method = \"simple\" , rc = metadata . get ( \"coulomb_sr_rc\" , 4.6 ) if metadata is not None else 4.6 , envelope = metadata . get ( \"coulomb_sr_envelope\" , \"exp\" ) if metadata is not None else \"exp\" , subtract_sr = not sr_embedded , ) self . external_coulomb = self . external_coulomb . to ( self . device ) # Set up external DFTD3 if needed if final_needs_dispersion : d3_params = metadata . get ( \"d3_params\" ) if metadata else None if d3_params is None : raise ValueError ( \"needs_dispersion=True but d3_params not found in metadata. \" \"Provide d3_params in model metadata or set needs_dispersion=False.\" ) self . external_dftd3 = DFTD3 ( s8 = d3_params [ \"s8\" ], a1 = d3_params [ \"a1\" ], a2 = d3_params [ \"a2\" ], s6 = d3_params . get ( \"s6\" , 1.0 ), ) self . external_dftd3 = self . external_dftd3 . to ( self . device ) # Determine if model has long-range modules (embedded or external) has_embedded_lr = metadata . get ( \"has_embedded_lr\" , False ) if metadata is not None else False self . lr = ( hasattr ( self . model , \"cutoff_lr\" ) or self . external_coulomb is not None or self . external_dftd3 is not None or has_embedded_lr ) # Set cutoff_lr based on model attribute or external modules if hasattr ( self . model , \"cutoff_lr\" ): self . cutoff_lr = getattr ( self . model , \"cutoff_lr\" , float ( \"inf\" )) elif self . external_coulomb is not None : # For \"simple\" method, use inf (all pairs). For DSF, use dsf_cutoff. if self . external_coulomb . method == \"simple\" : self . cutoff_lr = float ( \"inf\" ) else : self . cutoff_lr = self . _default_dsf_cutoff elif self . external_dftd3 is not None : self . cutoff_lr = self . _default_dftd3_cutoff elif has_embedded_lr : # Embedded LR modules (D3TS, SRCoulomb) need nbmat_lr self . cutoff_lr = self . _default_dftd3_cutoff else : self . cutoff_lr = None self . nb_threshold = nb_threshold # Create adaptive neighbor list instances self . _nblist = AdaptiveNeighborList ( cutoff = self . cutoff ) # Track separate cutoffs for LR modules self . _coulomb_cutoff : float | None = None self . _dftd3_cutoff : float = self . _default_dftd3_cutoff if self . external_coulomb is not None : if self . external_coulomb . method == \"simple\" : self . _coulomb_cutoff = float ( \"inf\" ) elif self . external_coulomb . method == \"ewald\" : self . _coulomb_cutoff = None # Ewald manages its own cutoff else : self . _coulomb_cutoff = self . external_coulomb . dsf_rc if self . external_dftd3 is not None : self . _dftd3_cutoff = self . external_dftd3 . smoothing_off # Create long-range neighbor list(s) if LR modules present self . _nblist_lr : AdaptiveNeighborList | None = None self . _nblist_dftd3 : AdaptiveNeighborList | None = None self . _nblist_coulomb : AdaptiveNeighborList | None = None self . _update_lr_nblists () # indicator if input was flattened self . _batch = None self . _max_mol_size : int = 0 # placeholder for tensors that require grad self . _saved_for_grad = {} # set flag of current Coulomb method self . _coulomb_method : str | None = None if self . external_coulomb is not None : self . _coulomb_method = self . external_coulomb . method elif self . _has_embedded_coulomb (): # Legacy models have embedded Coulomb with \"simple\" method self . _coulomb_method = \"simple\" # Set training mode (default False for inference) self . _train = train self . model . train ( train ) if not train : # Disable gradients on all parameters for inference mode for param in self . model . parameters (): param . requires_grad_ ( False ) if self . external_coulomb is not None : for param in self . external_coulomb . parameters (): param . requires_grad_ ( False ) if self . external_dftd3 is not None : for param in self . external_dftd3 . parameters (): param . requires_grad_ ( False ) coulomb_cutoff property \u00b6 Get the current Coulomb cutoff distance. Returns \u00b6 float | None The cutoff distance for Coulomb calculations, or None if not applicable. For \"simple\" method, this is inf. For \"ewald\", this is None. Use set_lrcoulomb_method() to change. coulomb_method property \u00b6 Get the current Coulomb method. Returns \u00b6 str | None One of \"simple\", \"dsf\", \"ewald\", or None if no external Coulomb. For legacy models with embedded Coulomb, returns None. dftd3_cutoff property \u00b6 Get the current DFTD3 cutoff distance. Returns \u00b6 float The cutoff distance for DFTD3 calculations in Angstroms. has_external_coulomb property \u00b6 Check if calculator has external Coulomb module attached. Returns True for new-format models that were trained with Coulomb and have it externalized. For legacy models, Coulomb is embedded in the model itself, so this returns False. has_external_dftd3 property \u00b6 Check if calculator has external DFTD3 module attached. Returns True for new-format models that were trained with DFTD3/D3BJ dispersion and have it externalized. For legacy models or D3TS models, dispersion is embedded in the model itself, so this returns False. mol_flatten ( data ) \u00b6 Flatten the input data for multiple molecules. Will not flatten for batched input and molecule size below threshold. Source code in aimnet/calculators/calculator.py 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 def mol_flatten ( self , data : dict [ str , Tensor ]) -> dict [ str , Tensor ]: \"\"\"Flatten the input data for multiple molecules. Will not flatten for batched input and molecule size below threshold. \"\"\" ndim = data [ \"coord\" ] . ndim if ndim == 2 : self . _batch = None if \"mol_idx\" not in data : data [ \"mol_idx\" ] = torch . zeros ( data [ \"coord\" ] . shape [ 0 ], dtype = torch . long , device = self . device ) self . _max_mol_size = data [ \"coord\" ] . shape [ 0 ] elif data [ \"mol_idx\" ][ - 1 ] == 0 : self . _max_mol_size = len ( data [ \"mol_idx\" ]) else : self . _max_mol_size = data [ \"mol_idx\" ] . unique ( return_counts = True )[ 1 ] . max () . item () elif ndim == 3 : B , N = data [ \"coord\" ] . shape [: 2 ] # Force flattening for PBC (cell present) to ensure make_nbmat computes proper neighbor lists with shifts if self . nb_threshold < N or self . device == \"cpu\" or data . get ( \"cell\" ) is not None : self . _batch = B data [ \"mol_idx\" ] = torch . repeat_interleave ( torch . arange ( 0 , B , device = self . device ), torch . full (( B ,), N , device = self . device ) ) for k , v in data . items (): if k in self . atom_feature_keys : data [ k ] = v . flatten ( 0 , 1 ) else : self . _batch = None self . _max_mol_size = N return data set_dftd3_cutoff ( cutoff = None , smoothing_fraction = None ) \u00b6 Set DFTD3 cutoff and smoothing. Parameters \u00b6 cutoff : float | None Cutoff distance in Angstroms for DFTD3 calculation. Default is _default_dftd3_cutoff (15.0). smoothing_fraction : float | None Fraction of cutoff used as smoothing width. Default is _default_dftd3_smoothing (0.2). Notes \u00b6 This method only affects external DFTD3 modules attached to new-format models. For legacy models with embedded DFTD3, the smoothing is fixed. Updates _dftd3_cutoff and rebuilds neighbor lists. Source code in aimnet/calculators/calculator.py 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 def set_dftd3_cutoff ( self , cutoff : float | None = None , smoothing_fraction : float | None = None ) -> None : \"\"\"Set DFTD3 cutoff and smoothing. Parameters ---------- cutoff : float | None Cutoff distance in Angstroms for DFTD3 calculation. Default is _default_dftd3_cutoff (15.0). smoothing_fraction : float | None Fraction of cutoff used as smoothing width. Default is _default_dftd3_smoothing (0.2). Notes ----- This method only affects external DFTD3 modules attached to new-format models. For legacy models with embedded DFTD3, the smoothing is fixed. Updates _dftd3_cutoff and rebuilds neighbor lists. \"\"\" if cutoff is None : cutoff = self . _default_dftd3_cutoff if smoothing_fraction is None : smoothing_fraction = self . _default_dftd3_smoothing self . _dftd3_cutoff = cutoff if self . external_dftd3 is not None : self . external_dftd3 . set_smoothing ( cutoff , smoothing_fraction ) self . _update_lr_nblists () set_lr_cutoff ( cutoff ) \u00b6 Set the unified long-range cutoff for all LR modules. Parameters \u00b6 cutoff : float Cutoff distance in Angstroms for LR neighbor lists. Notes \u00b6 This updates both _coulomb_cutoff and _dftd3_cutoff. Ewald uses its own internal neighbor list and ignores this cutoff. Source code in aimnet/calculators/calculator.py 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 def set_lr_cutoff ( self , cutoff : float ) -> None : \"\"\"Set the unified long-range cutoff for all LR modules. Parameters ---------- cutoff : float Cutoff distance in Angstroms for LR neighbor lists. Notes ----- This updates both _coulomb_cutoff and _dftd3_cutoff. Ewald uses its own internal neighbor list and ignores this cutoff. \"\"\" # Update both cutoffs (but not for ewald which manages its own) if self . _coulomb_method != \"ewald\" : self . _coulomb_cutoff = cutoff self . _dftd3_cutoff = cutoff self . cutoff_lr = cutoff self . _update_lr_nblists () set_lrcoulomb_method ( method , cutoff = 15.0 , dsf_alpha = 0.2 , ewald_accuracy = 1e-08 ) \u00b6 Set the long-range Coulomb method. Parameters \u00b6 method : str One of \"simple\", \"dsf\", or \"ewald\". cutoff : float Cutoff distance for DSF neighbor list. Default is 15.0. Not used for Ewald (which computes cutoffs from accuracy). dsf_alpha : float Alpha parameter for DSF method. Default is 0.2. ewald_accuracy : float Target accuracy for Ewald summation. Controls the real-space and reciprocal-space cutoffs. Lower values give higher accuracy but require more computation. Default is 1e-8. The Ewald cutoffs are computed as: - eta = (V^2 / N)^(1/6) / sqrt(2*pi) - cutoff_real = sqrt(-2 * ln(accuracy)) * eta - cutoff_recip = sqrt(-2 * ln(accuracy)) / eta Notes \u00b6 For new-format models with external Coulomb, this updates the external module. For legacy models with embedded Coulomb, a warning is issued as those modules cannot be modified at runtime. Source code in aimnet/calculators/calculator.py 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 def set_lrcoulomb_method ( self , method : Literal [ \"simple\" , \"dsf\" , \"ewald\" ], cutoff : float = 15.0 , dsf_alpha : float = 0.2 , ewald_accuracy : float = 1e-8 , ): \"\"\"Set the long-range Coulomb method. Parameters ---------- method : str One of \"simple\", \"dsf\", or \"ewald\". cutoff : float Cutoff distance for DSF neighbor list. Default is 15.0. Not used for Ewald (which computes cutoffs from accuracy). dsf_alpha : float Alpha parameter for DSF method. Default is 0.2. ewald_accuracy : float Target accuracy for Ewald summation. Controls the real-space and reciprocal-space cutoffs. Lower values give higher accuracy but require more computation. Default is 1e-8. The Ewald cutoffs are computed as: - eta = (V^2 / N)^(1/6) / sqrt(2*pi) - cutoff_real = sqrt(-2 * ln(accuracy)) * eta - cutoff_recip = sqrt(-2 * ln(accuracy)) / eta Notes ----- For new-format models with external Coulomb, this updates the external module. For legacy models with embedded Coulomb, a warning is issued as those modules cannot be modified at runtime. \"\"\" if method not in ( \"simple\" , \"dsf\" , \"ewald\" ): raise ValueError ( f \"Invalid method: { method } \" ) # Warn if model has embedded Coulomb (legacy models) if self . _has_embedded_coulomb () and self . external_coulomb is None : warnings . warn ( \"Model has embedded Coulomb module (legacy format). \" \"set_lrcoulomb_method() only affects external Coulomb modules. \" \"For legacy models, the Coulomb method cannot be changed at runtime.\" , stacklevel = 2 , ) # Update external LRCoulomb module if present if self . external_coulomb is not None : self . external_coulomb . method = method if method == \"dsf\" : self . external_coulomb . dsf_alpha = dsf_alpha self . external_coulomb . dsf_rc = cutoff elif method == \"ewald\" : self . external_coulomb . ewald_accuracy = ewald_accuracy # Update _coulomb_cutoff based on method if method == \"simple\" : self . _coulomb_cutoff = float ( \"inf\" ) elif method == \"dsf\" : self . _coulomb_cutoff = cutoff elif method == \"ewald\" : self . _coulomb_cutoff = None # Ewald manages its own real-space cutoff # Update cutoff_lr for backward compatibility if self . _coulomb_cutoff is not None : self . cutoff_lr = self . _coulomb_cutoff else : # Ewald - use DFTD3 cutoff if available, else None self . cutoff_lr = self . _dftd3_cutoff if self . external_dftd3 is not None else None self . _coulomb_method = method self . _update_lr_nblists () options: show_root_heading: true show_source: true AIMNet2ASE \u00b6 ASE (Atomic Simulation Environment) calculator interface. !!! note \"Installation\" Requires the ase extra: pip install aimnet[ase] This calculator integrates with ASE's Atoms object, supporting energy, forces, stress, and dipole moment calculations. It operates in eV and Angstrom . Usage Example \u00b6 from ase.io import read from aimnet.calculators import AIMNet2ASE atoms = read(\"molecule.xyz\") atoms.calc = AIMNet2ASE(\"aimnet2\") print(atoms.get_potential_energy()) print(atoms.get_forces()) AIMNet2ASE ( base_calc = 'aimnet2' , charge = 0 , mult = 1 ) \u00b6 Bases: Calculator Source code in aimnet/calculators/aimnet2ase.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , base_calc : AIMNet2Calculator | str = \"aimnet2\" , charge = 0 , mult = 1 ): super () . __init__ () if isinstance ( base_calc , str ): base_calc = AIMNet2Calculator ( base_calc ) self . base_calc = base_calc self . reset () self . charge = charge self . mult = mult self . update_tensors () # list of implemented species if hasattr ( base_calc , \"implemented_species\" ): self . implemented_species = base_calc . implemented_species . cpu () . numpy () # type: ignore else : self . implemented_species = None options: show_root_heading: true show_source: true AIMNet2Pysis \u00b6 PySisyphus calculator interface. !!! note \"Installation\" Requires the pysis extra: pip install aimnet[pysis] This interface adapts AIMNet2 for use with PySisyphus optimizers. It handles unit conversion automatically: Input : Converts Angstrom (PySisyphus) to Angstrom (AIMNet2). Output : Converts eV/Angstrom (AIMNet2) to Hartree/Bohr (PySisyphus). AIMNet2Pysis ( model = 'aimnet2' , charge = 0 , mult = 1 , ** kwargs ) \u00b6 Bases: Calculator Source code in aimnet/calculators/aimnet2pysis.py 21 22 23 24 25 def __init__ ( self , model : AIMNet2Calculator | str = \"aimnet2\" , charge = 0 , mult = 1 , ** kwargs ): super () . __init__ ( charge = charge , mult = mult , ** kwargs ) if isinstance ( model , str ): model = AIMNet2Calculator ( model ) self . model = model options: show_root_heading: true show_source: true Model Registry \u00b6 Utilities for loading pre-trained models. Models are automatically downloaded from the remote repository to a local cache ( aimnet/calculators/assets/ ) upon first use. CLI Command \u00b6 You can clear the local model cache using the CLI: aimnet clear_model_cache model_registry \u00b6 options: show_root_heading: true show_source: true","title":"Calculators"},{"location":"api/calculators/#calculators","text":"Calculator interfaces for molecular simulations using AIMNet2.","title":"Calculators"},{"location":"api/calculators/#aimnet2calculator","text":"The core calculator for running AIMNet2 inference. It handles model loading, device management, and application of long-range interactions (Coulomb and Dispersion).","title":"AIMNet2Calculator"},{"location":"api/calculators/#key-features","text":"Format Support : Loads both legacy .jpt models and new .pt format. Long-Range Interactions : Automatically attaches LRCoulomb and DFTD3 modules based on model metadata. Overrides : You can force specific long-range behavior using needs_coulomb and needs_dispersion arguments. Batching : Automatically batches large molecules/systems based on nb_threshold .","title":"Key Features"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator","text":"Generic AIMNet2 calculator. A helper class to load AIMNet2 models and perform inference.","title":"AIMNet2Calculator"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator--parameters","text":"model : str | nn.Module Model name (from registry), path to model file, or nn.Module instance. nb_threshold : int Threshold for neighbor list batching. Molecules larger than this use flattened processing. Default is 120. needs_coulomb : bool | None Whether to add external Coulomb module. If None (default), determined from model metadata. If True/False, overrides metadata. needs_dispersion : bool | None Whether to add external DFTD3 module. If None (default), determined from model metadata. If True/False, overrides metadata. device : str | None Device to run the model on (\"cuda\", \"cpu\", or specific like \"cuda:0\"). If None (default), auto-detects CUDA availability. compile_model : bool Whether to compile the model with torch.compile(). Default is False. compile_kwargs : dict | None Additional keyword arguments to pass to torch.compile(). Default is None. train : bool Whether to enable training mode. Default is False (inference mode). When False, all model parameters have requires_grad=False, which improves torch.compile compatibility and reduces memory usage. Set to True only when training the model.","title":"Parameters"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator--attributes","text":"model : nn.Module The loaded AIMNet2 model. device : str Device the model is running on (\"cuda\" or \"cpu\"). cutoff : float Short-range cutoff distance in Angstroms. cutoff_lr : float | None Long-range cutoff distance, or None if no LR modules. external_coulomb : LRCoulomb | None External Coulomb module if attached. external_dftd3 : DFTD3 | None External DFTD3 module if attached.","title":"Attributes"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator--notes","text":"External LR module behavior: For file-loaded models (str): metadata is loaded from file For nn.Module: metadata is read from model.metadata attribute if available Explicit flags (needs_coulomb, needs_dispersion) override metadata If no metadata and no explicit flags, no external LR modules are added Source code in aimnet/calculators/calculator.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def __init__ ( self , model : str | nn . Module = \"aimnet2\" , nb_threshold : int = 120 , needs_coulomb : bool | None = None , needs_dispersion : bool | None = None , device : str | None = None , compile_model : bool = False , compile_kwargs : dict | None = None , train : bool = False , ): # Device selection: use provided or auto-detect if device is not None : self . device = device else : self . device = \"cuda\" if torch . cuda . is_available () else \"cpu\" self . external_coulomb : LRCoulomb | None = None self . external_dftd3 : DFTD3 | None = None # Default cutoffs for LR modules self . _default_dsf_cutoff = 15.0 self . _default_dftd3_cutoff = 15.0 self . _default_dftd3_smoothing = 0.2 # Load model and get metadata metadata : dict | None = None if isinstance ( model , str ): p = get_model_path ( model ) self . model , metadata = load_model ( p , device = self . device ) self . cutoff = metadata [ \"cutoff\" ] elif isinstance ( model , nn . Module ): self . model = model . to ( self . device ) self . cutoff = getattr ( self . model , \"cutoff\" , 5.0 ) metadata = getattr ( self . model , \"_metadata\" , None ) else : raise TypeError ( \"Invalid model type/name.\" ) # Compile model if requested if compile_model : kwargs = compile_kwargs or {} self . model = torch . compile ( self . model , ** kwargs ) # Resolve final flags (explicit overrides metadata) final_needs_coulomb = ( needs_coulomb if needs_coulomb is not None else ( metadata . get ( \"needs_coulomb\" , False ) if metadata is not None else False ) ) final_needs_dispersion = ( needs_dispersion if needs_dispersion is not None else ( metadata . get ( \"needs_dispersion\" , False ) if metadata is not None else False ) ) # Set up external Coulomb if needed if final_needs_coulomb : sr_embedded = metadata . get ( \"coulomb_mode\" ) == \"sr_embedded\" if metadata is not None else False # For PBC, user can switch to DSF/Ewald via set_lrcoulomb_method() # When sr_embedded=True: model has SRCoulomb which subtracts SR, so external # should compute FULL (subtract_sr=False) to give: (NN - SR) + FULL = NN + LR # When sr_embedded=False: model has no SR embedded, so external should compute # LR only (subtract_sr=True) to avoid double-counting self . external_coulomb = LRCoulomb ( key_in = \"charges\" , key_out = \"energy\" , method = \"simple\" , rc = metadata . get ( \"coulomb_sr_rc\" , 4.6 ) if metadata is not None else 4.6 , envelope = metadata . get ( \"coulomb_sr_envelope\" , \"exp\" ) if metadata is not None else \"exp\" , subtract_sr = not sr_embedded , ) self . external_coulomb = self . external_coulomb . to ( self . device ) # Set up external DFTD3 if needed if final_needs_dispersion : d3_params = metadata . get ( \"d3_params\" ) if metadata else None if d3_params is None : raise ValueError ( \"needs_dispersion=True but d3_params not found in metadata. \" \"Provide d3_params in model metadata or set needs_dispersion=False.\" ) self . external_dftd3 = DFTD3 ( s8 = d3_params [ \"s8\" ], a1 = d3_params [ \"a1\" ], a2 = d3_params [ \"a2\" ], s6 = d3_params . get ( \"s6\" , 1.0 ), ) self . external_dftd3 = self . external_dftd3 . to ( self . device ) # Determine if model has long-range modules (embedded or external) has_embedded_lr = metadata . get ( \"has_embedded_lr\" , False ) if metadata is not None else False self . lr = ( hasattr ( self . model , \"cutoff_lr\" ) or self . external_coulomb is not None or self . external_dftd3 is not None or has_embedded_lr ) # Set cutoff_lr based on model attribute or external modules if hasattr ( self . model , \"cutoff_lr\" ): self . cutoff_lr = getattr ( self . model , \"cutoff_lr\" , float ( \"inf\" )) elif self . external_coulomb is not None : # For \"simple\" method, use inf (all pairs). For DSF, use dsf_cutoff. if self . external_coulomb . method == \"simple\" : self . cutoff_lr = float ( \"inf\" ) else : self . cutoff_lr = self . _default_dsf_cutoff elif self . external_dftd3 is not None : self . cutoff_lr = self . _default_dftd3_cutoff elif has_embedded_lr : # Embedded LR modules (D3TS, SRCoulomb) need nbmat_lr self . cutoff_lr = self . _default_dftd3_cutoff else : self . cutoff_lr = None self . nb_threshold = nb_threshold # Create adaptive neighbor list instances self . _nblist = AdaptiveNeighborList ( cutoff = self . cutoff ) # Track separate cutoffs for LR modules self . _coulomb_cutoff : float | None = None self . _dftd3_cutoff : float = self . _default_dftd3_cutoff if self . external_coulomb is not None : if self . external_coulomb . method == \"simple\" : self . _coulomb_cutoff = float ( \"inf\" ) elif self . external_coulomb . method == \"ewald\" : self . _coulomb_cutoff = None # Ewald manages its own cutoff else : self . _coulomb_cutoff = self . external_coulomb . dsf_rc if self . external_dftd3 is not None : self . _dftd3_cutoff = self . external_dftd3 . smoothing_off # Create long-range neighbor list(s) if LR modules present self . _nblist_lr : AdaptiveNeighborList | None = None self . _nblist_dftd3 : AdaptiveNeighborList | None = None self . _nblist_coulomb : AdaptiveNeighborList | None = None self . _update_lr_nblists () # indicator if input was flattened self . _batch = None self . _max_mol_size : int = 0 # placeholder for tensors that require grad self . _saved_for_grad = {} # set flag of current Coulomb method self . _coulomb_method : str | None = None if self . external_coulomb is not None : self . _coulomb_method = self . external_coulomb . method elif self . _has_embedded_coulomb (): # Legacy models have embedded Coulomb with \"simple\" method self . _coulomb_method = \"simple\" # Set training mode (default False for inference) self . _train = train self . model . train ( train ) if not train : # Disable gradients on all parameters for inference mode for param in self . model . parameters (): param . requires_grad_ ( False ) if self . external_coulomb is not None : for param in self . external_coulomb . parameters (): param . requires_grad_ ( False ) if self . external_dftd3 is not None : for param in self . external_dftd3 . parameters (): param . requires_grad_ ( False )","title":"Notes"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.coulomb_cutoff","text":"Get the current Coulomb cutoff distance.","title":"coulomb_cutoff"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.coulomb_cutoff--returns","text":"float | None The cutoff distance for Coulomb calculations, or None if not applicable. For \"simple\" method, this is inf. For \"ewald\", this is None. Use set_lrcoulomb_method() to change.","title":"Returns"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.coulomb_method","text":"Get the current Coulomb method.","title":"coulomb_method"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.coulomb_method--returns","text":"str | None One of \"simple\", \"dsf\", \"ewald\", or None if no external Coulomb. For legacy models with embedded Coulomb, returns None.","title":"Returns"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.dftd3_cutoff","text":"Get the current DFTD3 cutoff distance.","title":"dftd3_cutoff"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.dftd3_cutoff--returns","text":"float The cutoff distance for DFTD3 calculations in Angstroms.","title":"Returns"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.has_external_coulomb","text":"Check if calculator has external Coulomb module attached. Returns True for new-format models that were trained with Coulomb and have it externalized. For legacy models, Coulomb is embedded in the model itself, so this returns False.","title":"has_external_coulomb"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.has_external_dftd3","text":"Check if calculator has external DFTD3 module attached. Returns True for new-format models that were trained with DFTD3/D3BJ dispersion and have it externalized. For legacy models or D3TS models, dispersion is embedded in the model itself, so this returns False.","title":"has_external_dftd3"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.mol_flatten","text":"Flatten the input data for multiple molecules. Will not flatten for batched input and molecule size below threshold. Source code in aimnet/calculators/calculator.py 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 def mol_flatten ( self , data : dict [ str , Tensor ]) -> dict [ str , Tensor ]: \"\"\"Flatten the input data for multiple molecules. Will not flatten for batched input and molecule size below threshold. \"\"\" ndim = data [ \"coord\" ] . ndim if ndim == 2 : self . _batch = None if \"mol_idx\" not in data : data [ \"mol_idx\" ] = torch . zeros ( data [ \"coord\" ] . shape [ 0 ], dtype = torch . long , device = self . device ) self . _max_mol_size = data [ \"coord\" ] . shape [ 0 ] elif data [ \"mol_idx\" ][ - 1 ] == 0 : self . _max_mol_size = len ( data [ \"mol_idx\" ]) else : self . _max_mol_size = data [ \"mol_idx\" ] . unique ( return_counts = True )[ 1 ] . max () . item () elif ndim == 3 : B , N = data [ \"coord\" ] . shape [: 2 ] # Force flattening for PBC (cell present) to ensure make_nbmat computes proper neighbor lists with shifts if self . nb_threshold < N or self . device == \"cpu\" or data . get ( \"cell\" ) is not None : self . _batch = B data [ \"mol_idx\" ] = torch . repeat_interleave ( torch . arange ( 0 , B , device = self . device ), torch . full (( B ,), N , device = self . device ) ) for k , v in data . items (): if k in self . atom_feature_keys : data [ k ] = v . flatten ( 0 , 1 ) else : self . _batch = None self . _max_mol_size = N return data","title":"mol_flatten"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_dftd3_cutoff","text":"Set DFTD3 cutoff and smoothing.","title":"set_dftd3_cutoff"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_dftd3_cutoff--parameters","text":"cutoff : float | None Cutoff distance in Angstroms for DFTD3 calculation. Default is _default_dftd3_cutoff (15.0). smoothing_fraction : float | None Fraction of cutoff used as smoothing width. Default is _default_dftd3_smoothing (0.2).","title":"Parameters"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_dftd3_cutoff--notes","text":"This method only affects external DFTD3 modules attached to new-format models. For legacy models with embedded DFTD3, the smoothing is fixed. Updates _dftd3_cutoff and rebuilds neighbor lists. Source code in aimnet/calculators/calculator.py 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 def set_dftd3_cutoff ( self , cutoff : float | None = None , smoothing_fraction : float | None = None ) -> None : \"\"\"Set DFTD3 cutoff and smoothing. Parameters ---------- cutoff : float | None Cutoff distance in Angstroms for DFTD3 calculation. Default is _default_dftd3_cutoff (15.0). smoothing_fraction : float | None Fraction of cutoff used as smoothing width. Default is _default_dftd3_smoothing (0.2). Notes ----- This method only affects external DFTD3 modules attached to new-format models. For legacy models with embedded DFTD3, the smoothing is fixed. Updates _dftd3_cutoff and rebuilds neighbor lists. \"\"\" if cutoff is None : cutoff = self . _default_dftd3_cutoff if smoothing_fraction is None : smoothing_fraction = self . _default_dftd3_smoothing self . _dftd3_cutoff = cutoff if self . external_dftd3 is not None : self . external_dftd3 . set_smoothing ( cutoff , smoothing_fraction ) self . _update_lr_nblists ()","title":"Notes"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lr_cutoff","text":"Set the unified long-range cutoff for all LR modules.","title":"set_lr_cutoff"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lr_cutoff--parameters","text":"cutoff : float Cutoff distance in Angstroms for LR neighbor lists.","title":"Parameters"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lr_cutoff--notes","text":"This updates both _coulomb_cutoff and _dftd3_cutoff. Ewald uses its own internal neighbor list and ignores this cutoff. Source code in aimnet/calculators/calculator.py 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 def set_lr_cutoff ( self , cutoff : float ) -> None : \"\"\"Set the unified long-range cutoff for all LR modules. Parameters ---------- cutoff : float Cutoff distance in Angstroms for LR neighbor lists. Notes ----- This updates both _coulomb_cutoff and _dftd3_cutoff. Ewald uses its own internal neighbor list and ignores this cutoff. \"\"\" # Update both cutoffs (but not for ewald which manages its own) if self . _coulomb_method != \"ewald\" : self . _coulomb_cutoff = cutoff self . _dftd3_cutoff = cutoff self . cutoff_lr = cutoff self . _update_lr_nblists ()","title":"Notes"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lrcoulomb_method","text":"Set the long-range Coulomb method.","title":"set_lrcoulomb_method"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lrcoulomb_method--parameters","text":"method : str One of \"simple\", \"dsf\", or \"ewald\". cutoff : float Cutoff distance for DSF neighbor list. Default is 15.0. Not used for Ewald (which computes cutoffs from accuracy). dsf_alpha : float Alpha parameter for DSF method. Default is 0.2. ewald_accuracy : float Target accuracy for Ewald summation. Controls the real-space and reciprocal-space cutoffs. Lower values give higher accuracy but require more computation. Default is 1e-8. The Ewald cutoffs are computed as: - eta = (V^2 / N)^(1/6) / sqrt(2*pi) - cutoff_real = sqrt(-2 * ln(accuracy)) * eta - cutoff_recip = sqrt(-2 * ln(accuracy)) / eta","title":"Parameters"},{"location":"api/calculators/#aimnet.calculators.AIMNet2Calculator.set_lrcoulomb_method--notes","text":"For new-format models with external Coulomb, this updates the external module. For legacy models with embedded Coulomb, a warning is issued as those modules cannot be modified at runtime. Source code in aimnet/calculators/calculator.py 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 def set_lrcoulomb_method ( self , method : Literal [ \"simple\" , \"dsf\" , \"ewald\" ], cutoff : float = 15.0 , dsf_alpha : float = 0.2 , ewald_accuracy : float = 1e-8 , ): \"\"\"Set the long-range Coulomb method. Parameters ---------- method : str One of \"simple\", \"dsf\", or \"ewald\". cutoff : float Cutoff distance for DSF neighbor list. Default is 15.0. Not used for Ewald (which computes cutoffs from accuracy). dsf_alpha : float Alpha parameter for DSF method. Default is 0.2. ewald_accuracy : float Target accuracy for Ewald summation. Controls the real-space and reciprocal-space cutoffs. Lower values give higher accuracy but require more computation. Default is 1e-8. The Ewald cutoffs are computed as: - eta = (V^2 / N)^(1/6) / sqrt(2*pi) - cutoff_real = sqrt(-2 * ln(accuracy)) * eta - cutoff_recip = sqrt(-2 * ln(accuracy)) / eta Notes ----- For new-format models with external Coulomb, this updates the external module. For legacy models with embedded Coulomb, a warning is issued as those modules cannot be modified at runtime. \"\"\" if method not in ( \"simple\" , \"dsf\" , \"ewald\" ): raise ValueError ( f \"Invalid method: { method } \" ) # Warn if model has embedded Coulomb (legacy models) if self . _has_embedded_coulomb () and self . external_coulomb is None : warnings . warn ( \"Model has embedded Coulomb module (legacy format). \" \"set_lrcoulomb_method() only affects external Coulomb modules. \" \"For legacy models, the Coulomb method cannot be changed at runtime.\" , stacklevel = 2 , ) # Update external LRCoulomb module if present if self . external_coulomb is not None : self . external_coulomb . method = method if method == \"dsf\" : self . external_coulomb . dsf_alpha = dsf_alpha self . external_coulomb . dsf_rc = cutoff elif method == \"ewald\" : self . external_coulomb . ewald_accuracy = ewald_accuracy # Update _coulomb_cutoff based on method if method == \"simple\" : self . _coulomb_cutoff = float ( \"inf\" ) elif method == \"dsf\" : self . _coulomb_cutoff = cutoff elif method == \"ewald\" : self . _coulomb_cutoff = None # Ewald manages its own real-space cutoff # Update cutoff_lr for backward compatibility if self . _coulomb_cutoff is not None : self . cutoff_lr = self . _coulomb_cutoff else : # Ewald - use DFTD3 cutoff if available, else None self . cutoff_lr = self . _dftd3_cutoff if self . external_dftd3 is not None else None self . _coulomb_method = method self . _update_lr_nblists () options: show_root_heading: true show_source: true","title":"Notes"},{"location":"api/calculators/#aimnet2ase","text":"ASE (Atomic Simulation Environment) calculator interface. !!! note \"Installation\" Requires the ase extra: pip install aimnet[ase] This calculator integrates with ASE's Atoms object, supporting energy, forces, stress, and dipole moment calculations. It operates in eV and Angstrom .","title":"AIMNet2ASE"},{"location":"api/calculators/#usage-example","text":"from ase.io import read from aimnet.calculators import AIMNet2ASE atoms = read(\"molecule.xyz\") atoms.calc = AIMNet2ASE(\"aimnet2\") print(atoms.get_potential_energy()) print(atoms.get_forces())","title":"Usage Example"},{"location":"api/calculators/#aimnet.calculators.aimnet2ase.AIMNet2ASE","text":"Bases: Calculator Source code in aimnet/calculators/aimnet2ase.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , base_calc : AIMNet2Calculator | str = \"aimnet2\" , charge = 0 , mult = 1 ): super () . __init__ () if isinstance ( base_calc , str ): base_calc = AIMNet2Calculator ( base_calc ) self . base_calc = base_calc self . reset () self . charge = charge self . mult = mult self . update_tensors () # list of implemented species if hasattr ( base_calc , \"implemented_species\" ): self . implemented_species = base_calc . implemented_species . cpu () . numpy () # type: ignore else : self . implemented_species = None options: show_root_heading: true show_source: true","title":"AIMNet2ASE"},{"location":"api/calculators/#aimnet2pysis","text":"PySisyphus calculator interface. !!! note \"Installation\" Requires the pysis extra: pip install aimnet[pysis] This interface adapts AIMNet2 for use with PySisyphus optimizers. It handles unit conversion automatically: Input : Converts Angstrom (PySisyphus) to Angstrom (AIMNet2). Output : Converts eV/Angstrom (AIMNet2) to Hartree/Bohr (PySisyphus).","title":"AIMNet2Pysis"},{"location":"api/calculators/#aimnet.calculators.aimnet2pysis.AIMNet2Pysis","text":"Bases: Calculator Source code in aimnet/calculators/aimnet2pysis.py 21 22 23 24 25 def __init__ ( self , model : AIMNet2Calculator | str = \"aimnet2\" , charge = 0 , mult = 1 , ** kwargs ): super () . __init__ ( charge = charge , mult = mult , ** kwargs ) if isinstance ( model , str ): model = AIMNet2Calculator ( model ) self . model = model options: show_root_heading: true show_source: true","title":"AIMNet2Pysis"},{"location":"api/calculators/#model-registry","text":"Utilities for loading pre-trained models. Models are automatically downloaded from the remote repository to a local cache ( aimnet/calculators/assets/ ) upon first use.","title":"Model Registry"},{"location":"api/calculators/#cli-command","text":"You can clear the local model cache using the CLI: aimnet clear_model_cache","title":"CLI Command"},{"location":"api/calculators/#aimnet.calculators.model_registry","text":"options: show_root_heading: true show_source: true","title":"model_registry"},{"location":"api/config/","text":"Config \u00b6 Configuration and model building utilities. Build Module \u00b6 build_module ( config , hyperpar = None ) \u00b6 Build a module based on the provided configuration. Every (possibly nested) dictionary with a 'class' key will be replaced by an instance initialized with arguments and keywords provided as 'args' and 'kwargs' keys. Parameters: config ( Union [ str , Dict , List ] ) \u2013 The configuration for building the module. hyperpar ( Union [ str , Dict , None] , default: None ) \u2013 The hyperparameters for the module. Defaults to None. Returns: list | dict | Callable \u2013 Union[List, Dict, Callable]: The built module. Raises: AssertionError \u2013 If hyperpar is provided and is not a dictionary. Source code in aimnet/config.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def build_module ( config : str | dict | list , hyperpar : str | dict | None = None ) -> list | dict | Callable : \"\"\" Build a module based on the provided configuration. Every (possibly nested) dictionary with a 'class' key will be replaced by an instance initialized with arguments and keywords provided as 'args' and 'kwargs' keys. Args: config (Union[str, Dict, List]): The configuration for building the module. hyperpar (Union[str, Dict, None], optional): The hyperparameters for the module. Defaults to None. Returns: Union[List, Dict, Callable]: The built module. Raises: AssertionError: If `hyperpar` is provided and is not a dictionary. \"\"\" if isinstance ( hyperpar , str ): hyperpar = load_yaml ( hyperpar ) # type: ignore[assignment] if hyperpar and not isinstance ( hyperpar , dict ): raise TypeError ( \"Hyperpar must be a dictionary\" ) config = load_yaml ( config , hyperpar ) for d , k , v in _iter_rec_bottomup ( config ): if isinstance ( v , dict ) and \"class\" in v : d [ k ] = get_init_module ( # type: ignore[index] v [ \"class\" ], args = v . get ( \"args\" , []), # type: ignore[assignment] kwargs = v . get ( \"kwargs\" , {}), ) if \"class\" in config : config = get_init_module ( # type: ignore[assignment] config [ \"class\" ], # type: ignore[call-overload] args = config . get ( \"args\" , []), # type: ignore[union-attr] kwargs = config . get ( \"kwargs\" , {}), # type: ignore[union-attr] ) return config # type: ignore[assignment]","title":"Config"},{"location":"api/config/#config","text":"Configuration and model building utilities.","title":"Config"},{"location":"api/config/#build-module","text":"","title":"Build Module"},{"location":"api/config/#aimnet.config.build_module","text":"Build a module based on the provided configuration. Every (possibly nested) dictionary with a 'class' key will be replaced by an instance initialized with arguments and keywords provided as 'args' and 'kwargs' keys. Parameters: config ( Union [ str , Dict , List ] ) \u2013 The configuration for building the module. hyperpar ( Union [ str , Dict , None] , default: None ) \u2013 The hyperparameters for the module. Defaults to None. Returns: list | dict | Callable \u2013 Union[List, Dict, Callable]: The built module. Raises: AssertionError \u2013 If hyperpar is provided and is not a dictionary. Source code in aimnet/config.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def build_module ( config : str | dict | list , hyperpar : str | dict | None = None ) -> list | dict | Callable : \"\"\" Build a module based on the provided configuration. Every (possibly nested) dictionary with a 'class' key will be replaced by an instance initialized with arguments and keywords provided as 'args' and 'kwargs' keys. Args: config (Union[str, Dict, List]): The configuration for building the module. hyperpar (Union[str, Dict, None], optional): The hyperparameters for the module. Defaults to None. Returns: Union[List, Dict, Callable]: The built module. Raises: AssertionError: If `hyperpar` is provided and is not a dictionary. \"\"\" if isinstance ( hyperpar , str ): hyperpar = load_yaml ( hyperpar ) # type: ignore[assignment] if hyperpar and not isinstance ( hyperpar , dict ): raise TypeError ( \"Hyperpar must be a dictionary\" ) config = load_yaml ( config , hyperpar ) for d , k , v in _iter_rec_bottomup ( config ): if isinstance ( v , dict ) and \"class\" in v : d [ k ] = get_init_module ( # type: ignore[index] v [ \"class\" ], args = v . get ( \"args\" , []), # type: ignore[assignment] kwargs = v . get ( \"kwargs\" , {}), ) if \"class\" in config : config = get_init_module ( # type: ignore[assignment] config [ \"class\" ], # type: ignore[call-overload] args = config . get ( \"args\" , []), # type: ignore[union-attr] kwargs = config . get ( \"kwargs\" , {}), # type: ignore[union-attr] ) return config # type: ignore[assignment]","title":"build_module"},{"location":"api/data/","text":"Data \u00b6 Dataset handling and data loading utilities. SizeGroupedDataset \u00b6 SizeGroupedDataset ( data = None , keys = None , shard = None ) \u00b6 Source code in aimnet/data/sgdataset.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def __init__ ( self , data : str | list [ str ] | dict [ int , dict [ str , np . ndarray ]] | dict [ int , DataGroup ] | None = None , keys : list [ str ] | None = None , shard : tuple [ int , int ] | None = None , ): # main containers self . _data : dict [ int , DataGroup ] = {} self . _meta : dict [ str , str ] = {} # load data if isinstance ( data , str ): if os . path . isdir ( data ): self . load_datadir ( data , keys = keys , shard = shard ) else : self . load_h5 ( data , keys = keys , shard = shard ) elif isinstance ( data , ( list , tuple )): self . load_files ( data , shard = shard ) elif isinstance ( data , dict ): self . load_dict ( data ) self . loader_mode = False self . x : list [ str ] = [] self . y : list [ str ] = [] SizeGroupedSampler \u00b6 SizeGroupedSampler ( ds , batch_size , batch_mode = 'molecules' , shuffle = False , batches_per_epoch =- 1 ) \u00b6 Source code in aimnet/data/sgdataset.py 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def __init__ ( self , ds : SizeGroupedDataset , batch_size : int , batch_mode : str = \"molecules\" , shuffle : bool = False , batches_per_epoch : int = - 1 , ): self . ds = ds self . batch_size = batch_size if batch_mode not in [ \"molecules\" , \"atoms\" ]: raise ValueError ( f \"Unknown batch_mode { batch_mode } \" ) self . batch_mode = batch_mode self . shuffle = shuffle self . batches_per_epoch = batches_per_epoch","title":"Data"},{"location":"api/data/#data","text":"Dataset handling and data loading utilities.","title":"Data"},{"location":"api/data/#sizegroupeddataset","text":"","title":"SizeGroupedDataset"},{"location":"api/data/#aimnet.data.sgdataset.SizeGroupedDataset","text":"Source code in aimnet/data/sgdataset.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def __init__ ( self , data : str | list [ str ] | dict [ int , dict [ str , np . ndarray ]] | dict [ int , DataGroup ] | None = None , keys : list [ str ] | None = None , shard : tuple [ int , int ] | None = None , ): # main containers self . _data : dict [ int , DataGroup ] = {} self . _meta : dict [ str , str ] = {} # load data if isinstance ( data , str ): if os . path . isdir ( data ): self . load_datadir ( data , keys = keys , shard = shard ) else : self . load_h5 ( data , keys = keys , shard = shard ) elif isinstance ( data , ( list , tuple )): self . load_files ( data , shard = shard ) elif isinstance ( data , dict ): self . load_dict ( data ) self . loader_mode = False self . x : list [ str ] = [] self . y : list [ str ] = []","title":"SizeGroupedDataset"},{"location":"api/data/#sizegroupedsampler","text":"","title":"SizeGroupedSampler"},{"location":"api/data/#aimnet.data.sgdataset.SizeGroupedSampler","text":"Source code in aimnet/data/sgdataset.py 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def __init__ ( self , ds : SizeGroupedDataset , batch_size : int , batch_mode : str = \"molecules\" , shuffle : bool = False , batches_per_epoch : int = - 1 , ): self . ds = ds self . batch_size = batch_size if batch_mode not in [ \"molecules\" , \"atoms\" ]: raise ValueError ( f \"Unknown batch_mode { batch_mode } \" ) self . batch_mode = batch_mode self . shuffle = shuffle self . batches_per_epoch = batches_per_epoch","title":"SizeGroupedSampler"},{"location":"api/modules/","text":"Modules \u00b6 Neural network modules and model components. Core Modules \u00b6 core \u00b6 SRRep ( key_out = 'e_rep' , cutoff_fn = 'none' , rc = 5.2 , reduce_sum = True ) \u00b6 Bases: Module GFN1-stype short range repulsion function Source code in aimnet/modules/core.py 205 206 207 208 209 210 211 212 213 214 215 216 217 def __init__ ( self , key_out = \"e_rep\" , cutoff_fn = \"none\" , rc = 5.2 , reduce_sum = True ): super () . __init__ () from aimnet.constants import get_gfn1_rep self . key_out = key_out self . cutoff_fn = cutoff_fn self . reduce_sum = reduce_sum self . register_buffer ( \"rc\" , torch . tensor ( rc )) gfn1_repa , gfn1_repb = get_gfn1_rep () weight = torch . stack ([ gfn1_repa , gfn1_repb ], dim =- 1 ) self . params = nn . Embedding ( 87 , 2 , padding_idx = 0 , _weight = weight ) self . params . weight . requires_grad_ ( False ) MLP ( n_in , n_out , hidden = None , activation_fn = 'torch.nn.GELU' , activation_kwargs = None , weight_init_fn = 'torch.nn.init.xavier_normal_' , bias = True , last_linear = True ) \u00b6 Convenience function to build MLP from config Source code in aimnet/modules/core.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def MLP ( n_in : int , n_out : int , hidden : list [ int ] | None = None , activation_fn : Callable | str = \"torch.nn.GELU\" , activation_kwargs : dict [ str , Any ] | None = None , weight_init_fn : Callable | str = \"torch.nn.init.xavier_normal_\" , bias : bool = True , last_linear : bool = True , ): \"\"\"Convenience function to build MLP from config\"\"\" if hidden is None : hidden = [] if activation_kwargs is None : activation_kwargs = {} # hp search hack hidden = [ x for x in hidden if x > 0 ] if isinstance ( activation_fn , str ): activation_fn = get_init_module ( activation_fn , kwargs = activation_kwargs ) if isinstance ( weight_init_fn , str ): weight_init_fn = get_module ( weight_init_fn ) sizes = [ n_in , * hidden , n_out ] layers = [] for i in range ( 1 , len ( sizes )): n_in , n_out = sizes [ i - 1 ], sizes [ i ] layer = nn . Linear ( n_in , n_out , bias = bias ) with torch . no_grad (): weight_init_fn ( layer . weight ) if bias : nn . init . zeros_ ( layer . bias ) layers . append ( layer ) if not ( last_linear and i == len ( sizes ) - 1 ): layers . append ( activation_fn ) return nn . Sequential ( * layers ) AIMNet2 Model \u00b6 aimnet2 \u00b6 Base Classes \u00b6 base \u00b6 AIMNet2Base () \u00b6 Bases: Module Base class for AIMNet2 models. Implements pre-processing data: converting to right dtype and device, setting nb mode, calculating masks. Source code in aimnet/models/base.py 191 192 193 194 def __init__ ( self ): super () . __init__ () # Use object.__setattr__ to avoid TorchScript tracing this attribute object . __setattr__ ( self , \"_metadata\" , None ) metadata property \u00b6 Return model metadata if available. prepare_input ( data ) \u00b6 Common operations for input preparation. Source code in aimnet/models/base.py 210 211 212 213 214 215 216 217 218 219 def prepare_input ( self , data : dict [ str , Tensor ]) -> dict [ str , Tensor ]: \"\"\"Common operations for input preparation.\"\"\" data = self . _prepare_dtype ( data ) data = nbops . set_nb_mode ( data ) data = nbops . calc_masks ( data ) assert data [ \"charge\" ] . ndim == 1 , \"Charge should be 1D tensor.\" if \"mult\" in data : assert data [ \"mult\" ] . ndim == 1 , \"Mult should be 1D tensor.\" return data ModelMetadata \u00b6 Bases: TypedDict Metadata returned by load_model(). This TypedDict documents the structure of the metadata dictionary. load_model ( path , device = 'cpu' ) \u00b6 Load model from file, supporting both new and legacy formats. Automatically detects format: - New format: state dict with embedded YAML config and metadata - Legacy format: JIT-compiled TorchScript model Parameters \u00b6 path : str Path to the model file (.pt or .jpt). device : str Device to load the model on. Default is \"cpu\". Returns \u00b6 model : nn.Module The loaded model with weights. metadata : ModelMetadata Dictionary containing model metadata. See ModelMetadata TypedDict for fields. Notes \u00b6 For legacy JIT models (format_version=1), needs_coulomb and needs_dispersion are False because LR modules are already embedded in the TorchScript model. Source code in aimnet/models/base.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def load_model ( path : str , device : str = \"cpu\" ) -> tuple [ nn . Module , ModelMetadata ]: \"\"\"Load model from file, supporting both new and legacy formats. Automatically detects format: - New format: state dict with embedded YAML config and metadata - Legacy format: JIT-compiled TorchScript model Parameters ---------- path : str Path to the model file (.pt or .jpt). device : str Device to load the model on. Default is \"cpu\". Returns ------- model : nn.Module The loaded model with weights. metadata : ModelMetadata Dictionary containing model metadata. See ModelMetadata TypedDict for fields. Notes ----- For legacy JIT models (format_version=1), `needs_coulomb` and `needs_dispersion` are False because LR modules are already embedded in the TorchScript model. \"\"\" import yaml # torch.load auto-detects TorchScript and dispatches to torch.jit.load with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , \".*looks like a TorchScript archive.*\" ) data = torch . load ( path , map_location = device , weights_only = False ) # Check result type to determine format if isinstance ( data , dict ) and \"model_yaml\" in data : # New state dict format model_config = yaml . safe_load ( data [ \"model_yaml\" ]) model = build_module ( model_config ) # Use strict=False because modules may differ between formats load_result = model . load_state_dict ( data [ \"state_dict\" ], strict = False ) # Check for unexpected missing/extra keys real_missing , real_unexpected = validate_state_dict_keys ( load_result . missing_keys , load_result . unexpected_keys ) if real_missing or real_unexpected : msg_parts = [] if real_missing : msg_parts . append ( f \"Missing keys: { real_missing } \" ) if real_unexpected : msg_parts . append ( f \"Unexpected keys: { real_unexpected } \" ) warnings . warn ( f \"State dict mismatch during model loading. { '; ' . join ( msg_parts ) } \" , stacklevel = 2 ) model = model . to ( device ) # Preserve float64 precision for atomic shifts (SAE values) after device transfer if hasattr ( model , \"outputs\" ) and hasattr ( model . outputs , \"atomic_shift\" ): model . outputs . atomic_shift . shifts = model . outputs . atomic_shift . shifts . double () metadata : ModelMetadata = { \"format_version\" : data . get ( \"format_version\" , 2 ), # Default 2 for early v2 files without version \"cutoff\" : data [ \"cutoff\" ], \"needs_coulomb\" : data . get ( \"needs_coulomb\" , False ), \"needs_dispersion\" : data . get ( \"needs_dispersion\" , False ), \"coulomb_mode\" : data . get ( \"coulomb_mode\" , \"none\" ), \"coulomb_sr_rc\" : data . get ( \"coulomb_sr_rc\" ), \"coulomb_sr_envelope\" : data . get ( \"coulomb_sr_envelope\" ), \"d3_params\" : data . get ( \"d3_params\" ), \"has_embedded_lr\" : data . get ( \"has_embedded_lr\" , False ), \"implemented_species\" : data . get ( \"implemented_species\" , []), } # Attach metadata to model for easy access model . _metadata = metadata return model , metadata elif isinstance ( data , torch . jit . ScriptModule ): # Legacy JIT format - LR modules are already embedded in the TorchScript model model = data metadata : ModelMetadata = { \"format_version\" : 1 , # Legacy .jpt format is v1 \"cutoff\" : float ( model . cutoff ), # Legacy models have LR modules embedded - don't add external ones \"needs_coulomb\" : False , \"needs_dispersion\" : False , \"coulomb_mode\" : \"full_embedded\" , # No coulomb_sr_rc/envelope for legacy (full Coulomb is embedded) \"d3_params\" : extract_d3_params ( model ) if has_externalizable_dftd3 ( model ) else None , \"implemented_species\" : extract_species ( model ), } # Attempt metadata assignment; silently fails for JIT models with contextlib . suppress ( AttributeError , RuntimeError ): model . _metadata = metadata # type: ignore[attr-defined] return model , metadata else : raise ValueError ( f \"Unknown model format: { type ( data ) } \" )","title":"Modules"},{"location":"api/modules/#modules","text":"Neural network modules and model components.","title":"Modules"},{"location":"api/modules/#core-modules","text":"","title":"Core Modules"},{"location":"api/modules/#aimnet.modules.core","text":"","title":"core"},{"location":"api/modules/#aimnet.modules.core.SRRep","text":"Bases: Module GFN1-stype short range repulsion function Source code in aimnet/modules/core.py 205 206 207 208 209 210 211 212 213 214 215 216 217 def __init__ ( self , key_out = \"e_rep\" , cutoff_fn = \"none\" , rc = 5.2 , reduce_sum = True ): super () . __init__ () from aimnet.constants import get_gfn1_rep self . key_out = key_out self . cutoff_fn = cutoff_fn self . reduce_sum = reduce_sum self . register_buffer ( \"rc\" , torch . tensor ( rc )) gfn1_repa , gfn1_repb = get_gfn1_rep () weight = torch . stack ([ gfn1_repa , gfn1_repb ], dim =- 1 ) self . params = nn . Embedding ( 87 , 2 , padding_idx = 0 , _weight = weight ) self . params . weight . requires_grad_ ( False )","title":"SRRep"},{"location":"api/modules/#aimnet.modules.core.MLP","text":"Convenience function to build MLP from config Source code in aimnet/modules/core.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def MLP ( n_in : int , n_out : int , hidden : list [ int ] | None = None , activation_fn : Callable | str = \"torch.nn.GELU\" , activation_kwargs : dict [ str , Any ] | None = None , weight_init_fn : Callable | str = \"torch.nn.init.xavier_normal_\" , bias : bool = True , last_linear : bool = True , ): \"\"\"Convenience function to build MLP from config\"\"\" if hidden is None : hidden = [] if activation_kwargs is None : activation_kwargs = {} # hp search hack hidden = [ x for x in hidden if x > 0 ] if isinstance ( activation_fn , str ): activation_fn = get_init_module ( activation_fn , kwargs = activation_kwargs ) if isinstance ( weight_init_fn , str ): weight_init_fn = get_module ( weight_init_fn ) sizes = [ n_in , * hidden , n_out ] layers = [] for i in range ( 1 , len ( sizes )): n_in , n_out = sizes [ i - 1 ], sizes [ i ] layer = nn . Linear ( n_in , n_out , bias = bias ) with torch . no_grad (): weight_init_fn ( layer . weight ) if bias : nn . init . zeros_ ( layer . bias ) layers . append ( layer ) if not ( last_linear and i == len ( sizes ) - 1 ): layers . append ( activation_fn ) return nn . Sequential ( * layers )","title":"MLP"},{"location":"api/modules/#aimnet2-model","text":"","title":"AIMNet2 Model"},{"location":"api/modules/#aimnet.models.aimnet2","text":"","title":"aimnet2"},{"location":"api/modules/#base-classes","text":"","title":"Base Classes"},{"location":"api/modules/#aimnet.models.base","text":"","title":"base"},{"location":"api/modules/#aimnet.models.base.AIMNet2Base","text":"Bases: Module Base class for AIMNet2 models. Implements pre-processing data: converting to right dtype and device, setting nb mode, calculating masks. Source code in aimnet/models/base.py 191 192 193 194 def __init__ ( self ): super () . __init__ () # Use object.__setattr__ to avoid TorchScript tracing this attribute object . __setattr__ ( self , \"_metadata\" , None )","title":"AIMNet2Base"},{"location":"api/modules/#aimnet.models.base.AIMNet2Base.metadata","text":"Return model metadata if available.","title":"metadata"},{"location":"api/modules/#aimnet.models.base.AIMNet2Base.prepare_input","text":"Common operations for input preparation. Source code in aimnet/models/base.py 210 211 212 213 214 215 216 217 218 219 def prepare_input ( self , data : dict [ str , Tensor ]) -> dict [ str , Tensor ]: \"\"\"Common operations for input preparation.\"\"\" data = self . _prepare_dtype ( data ) data = nbops . set_nb_mode ( data ) data = nbops . calc_masks ( data ) assert data [ \"charge\" ] . ndim == 1 , \"Charge should be 1D tensor.\" if \"mult\" in data : assert data [ \"mult\" ] . ndim == 1 , \"Mult should be 1D tensor.\" return data","title":"prepare_input"},{"location":"api/modules/#aimnet.models.base.ModelMetadata","text":"Bases: TypedDict Metadata returned by load_model(). This TypedDict documents the structure of the metadata dictionary.","title":"ModelMetadata"},{"location":"api/modules/#aimnet.models.base.load_model","text":"Load model from file, supporting both new and legacy formats. Automatically detects format: - New format: state dict with embedded YAML config and metadata - Legacy format: JIT-compiled TorchScript model","title":"load_model"},{"location":"api/modules/#aimnet.models.base.load_model--parameters","text":"path : str Path to the model file (.pt or .jpt). device : str Device to load the model on. Default is \"cpu\".","title":"Parameters"},{"location":"api/modules/#aimnet.models.base.load_model--returns","text":"model : nn.Module The loaded model with weights. metadata : ModelMetadata Dictionary containing model metadata. See ModelMetadata TypedDict for fields.","title":"Returns"},{"location":"api/modules/#aimnet.models.base.load_model--notes","text":"For legacy JIT models (format_version=1), needs_coulomb and needs_dispersion are False because LR modules are already embedded in the TorchScript model. Source code in aimnet/models/base.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def load_model ( path : str , device : str = \"cpu\" ) -> tuple [ nn . Module , ModelMetadata ]: \"\"\"Load model from file, supporting both new and legacy formats. Automatically detects format: - New format: state dict with embedded YAML config and metadata - Legacy format: JIT-compiled TorchScript model Parameters ---------- path : str Path to the model file (.pt or .jpt). device : str Device to load the model on. Default is \"cpu\". Returns ------- model : nn.Module The loaded model with weights. metadata : ModelMetadata Dictionary containing model metadata. See ModelMetadata TypedDict for fields. Notes ----- For legacy JIT models (format_version=1), `needs_coulomb` and `needs_dispersion` are False because LR modules are already embedded in the TorchScript model. \"\"\" import yaml # torch.load auto-detects TorchScript and dispatches to torch.jit.load with warnings . catch_warnings (): warnings . filterwarnings ( \"ignore\" , \".*looks like a TorchScript archive.*\" ) data = torch . load ( path , map_location = device , weights_only = False ) # Check result type to determine format if isinstance ( data , dict ) and \"model_yaml\" in data : # New state dict format model_config = yaml . safe_load ( data [ \"model_yaml\" ]) model = build_module ( model_config ) # Use strict=False because modules may differ between formats load_result = model . load_state_dict ( data [ \"state_dict\" ], strict = False ) # Check for unexpected missing/extra keys real_missing , real_unexpected = validate_state_dict_keys ( load_result . missing_keys , load_result . unexpected_keys ) if real_missing or real_unexpected : msg_parts = [] if real_missing : msg_parts . append ( f \"Missing keys: { real_missing } \" ) if real_unexpected : msg_parts . append ( f \"Unexpected keys: { real_unexpected } \" ) warnings . warn ( f \"State dict mismatch during model loading. { '; ' . join ( msg_parts ) } \" , stacklevel = 2 ) model = model . to ( device ) # Preserve float64 precision for atomic shifts (SAE values) after device transfer if hasattr ( model , \"outputs\" ) and hasattr ( model . outputs , \"atomic_shift\" ): model . outputs . atomic_shift . shifts = model . outputs . atomic_shift . shifts . double () metadata : ModelMetadata = { \"format_version\" : data . get ( \"format_version\" , 2 ), # Default 2 for early v2 files without version \"cutoff\" : data [ \"cutoff\" ], \"needs_coulomb\" : data . get ( \"needs_coulomb\" , False ), \"needs_dispersion\" : data . get ( \"needs_dispersion\" , False ), \"coulomb_mode\" : data . get ( \"coulomb_mode\" , \"none\" ), \"coulomb_sr_rc\" : data . get ( \"coulomb_sr_rc\" ), \"coulomb_sr_envelope\" : data . get ( \"coulomb_sr_envelope\" ), \"d3_params\" : data . get ( \"d3_params\" ), \"has_embedded_lr\" : data . get ( \"has_embedded_lr\" , False ), \"implemented_species\" : data . get ( \"implemented_species\" , []), } # Attach metadata to model for easy access model . _metadata = metadata return model , metadata elif isinstance ( data , torch . jit . ScriptModule ): # Legacy JIT format - LR modules are already embedded in the TorchScript model model = data metadata : ModelMetadata = { \"format_version\" : 1 , # Legacy .jpt format is v1 \"cutoff\" : float ( model . cutoff ), # Legacy models have LR modules embedded - don't add external ones \"needs_coulomb\" : False , \"needs_dispersion\" : False , \"coulomb_mode\" : \"full_embedded\" , # No coulomb_sr_rc/envelope for legacy (full Coulomb is embedded) \"d3_params\" : extract_d3_params ( model ) if has_externalizable_dftd3 ( model ) else None , \"implemented_species\" : extract_species ( model ), } # Attempt metadata assignment; silently fails for JIT models with contextlib . suppress ( AttributeError , RuntimeError ): model . _metadata = metadata # type: ignore[attr-defined] return model , metadata else : raise ValueError ( f \"Unknown model format: { type ( data ) } \" )","title":"Notes"}]}